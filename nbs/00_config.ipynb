{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#default_exp config\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deefplash2 Config\n",
    "\n",
    "> Module for configuration of deepflash2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"Config class for settings.\"\n",
    "\n",
    "    # Project\n",
    "    project_dir:str = '.'\n",
    "\n",
    "    # GT Estimation Settings\n",
    "    # staple_thres:float = 0.5\n",
    "    # staple_fval:int= 1\n",
    "    vote_undec:int = 0\n",
    "\n",
    "    # Train General Settings\n",
    "    n_models:int = 5\n",
    "    max_splits:int=5\n",
    "    random_state:int = 42\n",
    "    use_gpu:bool = True\n",
    "        \n",
    "    # Pytorch Segmentation Model Settings\n",
    "    arch:str = 'Unet'\n",
    "    encoder_name:str = 'tu-convnext_tiny'\n",
    "    encoder_weights:str = 'imagenet'\n",
    "\n",
    "    # Train Data Settings\n",
    "    num_classes:int = 2\n",
    "    tile_shape:int = 512\n",
    "    scale:float = 1.\n",
    "    instance_labels:bool = False\n",
    "\n",
    "    # Train Settings\n",
    "    base_lr:float = 0.001\n",
    "    batch_size:int = 4\n",
    "    weight_decay:float = 0.001\n",
    "    mixed_precision_training:bool = True\n",
    "    optim:str = 'Adam'\n",
    "    loss:str = 'CrossEntropyDiceLoss'\n",
    "    n_epochs:int = 25\n",
    "    sample_mult:int = 0\n",
    "\n",
    "    # Train Data Augmentation\n",
    "    gamma_limit_lower:int = 80\n",
    "    gamma_limit_upper:int = 120\n",
    "    CLAHE_clip_limit:float = 0.0\n",
    "    brightness_limit:float = 0.0\n",
    "    contrast_limit:float = 0.0\n",
    "    flip:bool = True\n",
    "    rot:int = 360\n",
    "    distort_limit:float = 0\n",
    "        \n",
    "    # Loss Settings\n",
    "    mode:str = 'multiclass' #currently only tested for multiclass\n",
    "    loss_alpha:float = 0.5 # Twerksky/Focal loss\n",
    "    loss_beta:float = 0.5 # Twerksy Loss\n",
    "    loss_gamma:float = 2.0 # Focal loss\n",
    "    loss_smooth_factor:float = 0. #SoftCrossEntropyLoss\n",
    "    \n",
    "    # Pred/Val Settings\n",
    "    use_tta:bool = True\n",
    "    max_tile_shift: float = 0.5\n",
    "    border_padding_factor:float = 0.25\n",
    "    use_gaussian: bool = True\n",
    "    gaussian_kernel_sigma_scale: float = 0.125\n",
    "    min_pixel_export:int = 0  \n",
    "\n",
    "    # Instance Segmentation Settings\n",
    "    cellpose_model:str='nuclei'\n",
    "    cellpose_diameter:int=0\n",
    "    cellpose_export_class:int=1\n",
    "    instance_segmentation_metrics:bool=False\n",
    "\n",
    "    # Folder Structure\n",
    "    gt_dir:str = 'GT_Estimation'\n",
    "    train_dir:str = 'Training'\n",
    "    pred_dir:str = 'Prediction'\n",
    "    ens_dir:str = 'models'\n",
    "    val_dir:str = 'valid'\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.set_device()\n",
    "        \n",
    "    def set_device(self, device:str=None):\n",
    "        if device is None:\n",
    "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "    \n",
    "    @property\n",
    "    def albumentation_kwargs(self):\n",
    "        kwargs = ['gamma_limit_lower', 'gamma_limit_upper', 'CLAHE_clip_limit', \n",
    "                  'brightness_limit', 'contrast_limit', 'distort_limit']\n",
    "        return dict(filter(lambda x: x[0] in kwargs, self.__dict__.items()))\n",
    "\n",
    "    @property\n",
    "    def inference_kwargs(self):\n",
    "        inference_kwargs = ['use_tta', 'max_tile_shift', 'use_gaussian', 'scale',\n",
    "                            'gaussian_kernel_sigma_scale', 'border_padding_factor']\n",
    "        return dict(filter(lambda x: x[0] in inference_kwargs, self.__dict__.items()))\n",
    "\n",
    "    def save(self, path):\n",
    "        'Save configuration to path'\n",
    "        path = Path(path).with_suffix('.json')\n",
    "        with open(path, 'w') as config_file:\n",
    "            json.dump(asdict(self), config_file)\n",
    "        print(f'Saved current configuration to {path}.json')\n",
    "        return path\n",
    "\n",
    "    def load(self, path):\n",
    "        'Load configuration from path'\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            with open(path) as config_file: c = json.load(config_file)\n",
    "            if not Path(c['project_dir']).is_dir(): c['project_dir']='deepflash2'\n",
    "            for k,v in c.items(): setattr(self, k, v)\n",
    "            print(f'Successsfully loaded configuration from {path}')\n",
    "        except:\n",
    "            print('Error! Select valid config file (.json)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved current configuration to test_config.json.json\n",
      "Successsfully loaded configuration from test_config.json\n"
     ]
    }
   ],
   "source": [
    "# Test config\n",
    "t1 = Config(n_models=3)\n",
    "path = t1.save('test_config')\n",
    "t2 = Config()\n",
    "t2.load(path)\n",
    "test_eq(t1, t2)\n",
    "path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_learner.ipynb.\n",
      "Converted 04_inference.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted tutorial.ipynb.\n",
      "Converted tutorial_gt.ipynb.\n",
      "Converted tutorial_pred.ipynb.\n",
      "Converted tutorial_train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
