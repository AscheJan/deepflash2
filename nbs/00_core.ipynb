{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepflash2\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Unet2D:\n",
    "\n",
    "    def __init__(self, n_channels=1, n_classes=2, n_levels=4,\n",
    "               n_features=64, n_batch_norm_levels=0, upsample = False,\n",
    "               relu_alpha=0.1, k_init=\"he_normal\"):\n",
    "    \n",
    "        self.n_channels = n_channels\n",
    "        self.n_levels = n_levels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = n_features\n",
    "        self.n_batch_norm_levels = n_batch_norm_levels\n",
    "        self.relu_alpha = relu_alpha\n",
    "        self.k_init = k_init\n",
    "        self.upsample = upsample\n",
    "\n",
    "        self.model = self._createModel()\n",
    "\n",
    "   \n",
    "    def _createModel(self):     \n",
    "        \n",
    "        conf2d = partial(layers.Conv2D, padding=\"valid\", kernel_initializer=self.k_init)\n",
    "        conf2dT = partial(layers.Conv2DTranspose, padding=\"valid\", kernel_initializer=self.k_init)\n",
    "        \n",
    "        data = layers.Input(shape=(None, None, self.n_channels), name=\"data\")               \n",
    "\n",
    "        down_stack = []\n",
    "        # Modules of the analysis path consist of two convolutions and max pooling\n",
    "        for l in range(self.n_levels):\n",
    "            x = conf2d(2**l * self.n_features, 3, name=\"conv_d{}a-b\".format(l))(data if l == 0 else x)\n",
    "            if l > self.n_batch_norm_levels: \n",
    "                x = layers.BatchNormalization(axis=-1)(x)\n",
    "            x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "            x = conf2d(2**l * self.n_features, 3, name=\"conv_d{}b-c\".format(l))(x)\n",
    "            if l > self.n_batch_norm_levels: \n",
    "                x = layers.BatchNormalization(axis=-1)(x)               \n",
    "            x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "            if l >= 2: \n",
    "                x = layers.Dropout(0.5)(x)\n",
    "            down_stack.append(x)\n",
    "            x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        # Deepest layer has two convolutions only\n",
    "        x = conf2d(2**self.n_levels * self.n_features, 3, name=\"conv_d{}a-b\".format(self.n_levels))(x)\n",
    "        if l > self.n_batch_norm_levels: \n",
    "            x = layers.BatchNormalization(axis=-1)(x)\n",
    "        x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "        x = conf2d(2**self.n_levels * self.n_features, 3, name=\"conv_d{}b-c\".format(self.n_levels))(x)\n",
    "        if l > self.n_batch_norm_levels: \n",
    "            x = layers.BatchNormalization(axis=-1)(x)\n",
    "        x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "        pad = 8    \n",
    "        \n",
    "        # Modules in the synthesis path consist of up-convolution,\n",
    "        # concatenation and two convolutions\n",
    "        for l in range(self.n_levels - 1, -1, -1):\n",
    "            name = \"upconv_{}{}{}_u{}a\".format(\n",
    "                *((\"d\", l+1, \"c\", l) if l == self.n_levels - 1 else (\"u\", l+1, \"d\", l)))\n",
    "            if self.upsample:\n",
    "                x = layers.UpSampling2D(size=(2, 2), name=name)(x)\n",
    "            else:\n",
    "                x = conf2dT(2**np.max((l, 1)) * self.n_features, (2, 2), strides=2, name=name)(x)   \n",
    "                x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "            x = layers.Concatenate()([layers.Cropping2D(cropping=int(pad / 2))(down_stack[l]), x])\n",
    "\n",
    "            x = conf2d(2**np.max((l, 1)) * self.n_features, 3, name=\"conv_u{}b-c\".format(l))(x)\n",
    "            if l > self.n_batch_norm_levels: \n",
    "                x = layers.BatchNormalization(axis=-1)(x)       \n",
    "            x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "            x = conf2d(2**np.max((l, 1)) * self.n_features, 3, name=\"conv_u{}c-d\".format(l))(x)\n",
    "            if l > self.n_batch_norm_levels: \n",
    "                x = layers.BatchNormalization(axis=-1)(x)       \n",
    "            x = layers.LeakyReLU(alpha=self.relu_alpha)(x)\n",
    "            pad = 2 * (pad + 8)\n",
    "\n",
    "        score = conf2d(self.n_classes, 1, name=\"conv_u0d-score\")(x)\n",
    "        softmax_score = layers.Softmax(name='softmax')(score)\n",
    "        \n",
    "        model= tf.keras.Model(inputs=data, outputs=[score, softmax_score])\n",
    "        \n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def weighted_softmax_cross_entropy(target_y, predicted_y):\n",
    "    target_y, w = tf.split(target_y, num_or_size_splits=[-1, 1], axis=-1)\n",
    "    w = w[...,0]\n",
    "    return tf.compat.v1.losses.softmax_cross_entropy(onehot_labels = target_y, \n",
    "                                                     logits = predicted_y, \n",
    "                                                     weights=w, \n",
    "                                                     reduction=tf.compat.v1.losses.Reduction.MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def zero_loss(predicted_y, target_y):\n",
    "    return tf.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'conv_u0d-score':loss, \n",
    "          'softmax':zero_loss}\n",
    "metrics = {'softmax': [tf.keras.metrics.Recall(class_id=1), \n",
    "                       tf.keras.metrics.Precision(class_id=1),\n",
    "                       tf.keras.metrics.BinaryAccuracy(),\n",
    "                       IoU(num_classes=2, class_id=1, name='IoU')\n",
    "                      ]}\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "unet.model.compile(optimizer=opt, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train = np.random.rand(36,540,540,1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train = np.random.randint(1,2,size=(36,540-184,540-184,3))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train2 = np.random.randint(1,2,size=(36,540-184,540-184,2))\n",
    "y_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hist= unet.model.fit(x_train, \n",
    "               {'conv_u0d-score': y_train, 'softmax': y_train2},\n",
    "          batch_size=2,\n",
    "          epochs=1,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from deepflash import preproc\n",
    "from skimage import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODER = 'staple'  #'rohini', 'dennis', 'cora', 'manju', 'corinna' ['cc_cons_1', 'cc_cons_2', 'cc_cons_3', 'cc_cons_4', 'cc_cons_5']\n",
    "CHANNELS_IMG = 1\n",
    "DATA_PATH = \"01_data\"#\"data/images\"\n",
    "ASSIGNMENT_PATH = 'data/samples_36_final.csv'\n",
    "TILE_SHAPE = (540,540)\n",
    "PADDING = (184,184)\n",
    "SEED = 44\n",
    "EL_SIZE = [635.9, 635.9] #micrometers\n",
    "WEIGHTS_DIR = 'weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASK = 'cFOS'\n",
    "IMAGE = 'red'\n",
    "MASK_PATH = \"data/labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAMBDA = 50 #50\n",
    "V_BAL = 0.1 #0.1\n",
    "SIGMA_BAL = 10 #10 \n",
    "SIGMA_SEP = 6 #6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assignment = pd.read_csv(ASSIGNMENT_PATH, converters={'Nummer': lambda x: str(x).zfill(4)})\n",
    "assignment['Group_ID'] = assignment.groupby(['Kondition', 'Area']).ngroup()\n",
    "file_ids = assignment['Nummer'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_list = [io.imread(os.path.join(DATA_PATH, img_name), as_gray=True) for \n",
    "              img_name in [s + '_' + IMAGE + '.tif' for s in file_ids]]\n",
    "\n",
    "image_list = [np.expand_dims(img, axis=2) for img in image_list]\n",
    "data = [{'rawdata': img, 'element_size_um': EL_SIZE} for img in image_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask_list = [io.imread(os.path.join(MASK_PATH, CODER, x), as_gray=True).astype('int')//255\n",
    "         for x in [s + '_' + MASK + '.png' for s in file_ids]]\n",
    "assert np.array(mask_list).max() == 1 \n",
    "\n",
    "X_train = np.array(image_list)\n",
    "y_train = np.array(mask_list)\n",
    "\n",
    "data_train = [{'rawdata': img, 'element_size_um': EL_SIZE} for img in X_train]\n",
    "\n",
    "weights = None\n",
    "w_path = Path(WEIGHTS_DIR, '36_' + MASK + '_' + CODER + '_' + str(LAMBDA) + '_' + str(V_BAL) + '_' + str(SIGMA_BAL) + '_' + str(SIGMA_SEP) + '.pkl')\n",
    "if w_path.exists(): \n",
    "    print('Loading image weights')\n",
    "    weights = pickle.load(open(w_path, \"rb\"))\n",
    "## Generators\n",
    "train_generator = preproc.DataAugmentationGenerator(data = data_train, \n",
    "                                                classlabels=y_train,\n",
    "                                                instancelabels=None,\n",
    "                                                tile_shape = TILE_SHAPE, \n",
    "                                                padding= PADDING,\n",
    "                                                batch_size = 4,\n",
    "                                                n_classes=2,\n",
    "                                                ignore=None,\n",
    "                                                weights=weights,\n",
    "                                                element_size_um=None,\n",
    "                                                rotation_range_deg=(0, 360),\n",
    "                                                flip=False,\n",
    "                                                deformation_grid=(150, 150),\n",
    "                                                deformation_magnitude=(10, 10),\n",
    "                                                value_minimum_range=(0, 0),\n",
    "                                                value_maximum_range=(0.0, 1),\n",
    "                                                value_slope_range=(1, 1),\n",
    "                                                shuffle=True,\n",
    "                                                foreground_dist_sigma_px=SIGMA_BAL,\n",
    "                                                border_weight_sigma_px=SIGMA_SEP,\n",
    "                                                border_weight_factor=LAMBDA,\n",
    "                                                foreground_background_ratio=V_BAL\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 6s 670ms/step - loss: 0.6451 - conv_u0d-score_loss: 0.6451 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.2483 - softmax_precision_31: 0.0179 - softmax_binary_accuracy: 0.6875 - softmax_IoU: 0.3514\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 6s 628ms/step - loss: 0.5182 - conv_u0d-score_loss: 0.5182 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0368 - softmax_precision_31: 0.0107 - softmax_binary_accuracy: 0.9232 - softmax_IoU: 0.4657\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.4656 - conv_u0d-score_loss: 0.4656 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0045 - softmax_precision_31: 0.0143 - softmax_binary_accuracy: 0.9743 - softmax_IoU: 0.4889\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.4468 - conv_u0d-score_loss: 0.4468 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0017 - softmax_precision_31: 0.0612 - softmax_binary_accuracy: 0.9756 - softmax_IoU: 0.4886\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 6s 628ms/step - loss: 0.4027 - conv_u0d-score_loss: 0.4027 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0018 - softmax_precision_31: 0.2174 - softmax_binary_accuracy: 0.9768 - softmax_IoU: 0.4893\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.3645 - conv_u0d-score_loss: 0.3645 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0026 - softmax_precision_31: 0.5520 - softmax_binary_accuracy: 0.9798 - softmax_IoU: 0.4912\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.3472 - conv_u0d-score_loss: 0.3472 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0031 - softmax_precision_31: 0.6957 - softmax_binary_accuracy: 0.9831 - softmax_IoU: 0.4931\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 6s 628ms/step - loss: 0.3334 - conv_u0d-score_loss: 0.3334 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0033 - softmax_precision_31: 0.8806 - softmax_binary_accuracy: 0.9788 - softmax_IoU: 0.4910\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.3072 - conv_u0d-score_loss: 0.3072 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0067 - softmax_precision_31: 0.8673 - softmax_binary_accuracy: 0.9790 - softmax_IoU: 0.4929\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 6s 628ms/step - loss: 0.3032 - conv_u0d-score_loss: 0.3032 - softmax_loss: 0.0000e+00 - softmax_recall_35: 0.0145 - softmax_precision_31: 0.6802 - softmax_binary_accuracy: 0.9835 - softmax_IoU: 0.4989\n"
     ]
    }
   ],
   "source": [
    "hist = unet.model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        epochs=10,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f259b1e34d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preds[1][2][...,1]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999917"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1][2][...,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 356)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0][1]['softmax'][0,...,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_generator[0][1]['softmax'][0,...,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
