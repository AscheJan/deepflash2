{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> This module defines tools for image data preprocessing and real-time data augmentation that is used to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Orininal Paper:__ Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70.\n",
    "\n",
    "__The code was provided by the authors and adapted for this package.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.interpolate import interp1d\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deformation field class for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DeformationField:\n",
    "    def __init__(self, shape=(540, 540)):\n",
    "        self.shape = shape\n",
    "        self.deformationField = np.meshgrid(*[np.arange(d) - d / 2 for d in shape])[\n",
    "            ::-1\n",
    "        ]\n",
    "\n",
    "    def rotate(self, theta=0, phi=0, psi=0):\n",
    "        if len(self.shape) == 2:\n",
    "            self.deformationField = [\n",
    "                self.deformationField[0] * math.cos(theta)\n",
    "                + self.deformationField[1] * math.sin(theta),\n",
    "                -self.deformationField[0] * math.sin(theta)\n",
    "                + self.deformationField[1] * math.cos(theta),\n",
    "            ]\n",
    "        else:\n",
    "            self.deformationField = [\n",
    "                self.deformationField[0],\n",
    "                self.deformationField[1] * math.cos(theta)\n",
    "                + self.deformationField[2] * math.sin(theta),\n",
    "                -self.deformationField[1] * math.sin(theta)\n",
    "                + self.deformationField[2] * math.cos(theta),\n",
    "            ]\n",
    "            self.deformationField = [\n",
    "                self.deformationField[0] * math.cos(phi)\n",
    "                + self.deformationField[2] * math.sin(phi),\n",
    "                self.deformationField[1]\n",
    "                - self.deformationField[0] * math.sin(phi)\n",
    "                + self.deformationField[2] * math.cos(phi),\n",
    "            ]\n",
    "            self.deformationField = [\n",
    "                self.deformationField[0],\n",
    "                self.deformationField[1] * math.cos(psi)\n",
    "                + self.deformationField[2] * math.sin(psi),\n",
    "                -self.deformationField[1] * math.sin(psi)\n",
    "                + self.deformationField[2] * math.cos(psi),\n",
    "            ]\n",
    "\n",
    "    def mirror(self, dims):\n",
    "        for d in range(len(self.shape)):\n",
    "            if dims[d]:\n",
    "                self.deformationField[d] = -self.deformationField[d]\n",
    "\n",
    "    def addRandomDeformation(self, grid=(150, 150), sigma=(10, 10)):\n",
    "        seedGrid = np.meshgrid(\n",
    "            *[np.arange(-g / 2, s + g / 2, g) for (g, s) in zip(grid, self.shape)]\n",
    "        )\n",
    "        seed = [np.random.normal(0, s, g.shape) for (g, s) in zip(seedGrid, sigma)]\n",
    "        defFcn = [Rbf(*seedGrid, s, function=\"cubic\") for s in seed]\n",
    "        targetGrid = np.meshgrid(*map(np.arange, self.shape))\n",
    "        deformation = [f(*targetGrid) for f in defFcn]\n",
    "        self.deformationField = [\n",
    "            f + df for (f, df) in zip(self.deformationField, deformation)\n",
    "        ]\n",
    "\n",
    "    def get(self, offset=(0, 0), pad=(0, 0)):\n",
    "        sliceDef = tuple(slice(int(p / 2), int(-p / 2)) if p > 0 else None for p in pad)\n",
    "        deform = [d[sliceDef] for d in self.deformationField]\n",
    "        return [d + offs for (d, offs) in zip(deform, offset)]\n",
    "\n",
    "    def apply(self, data, offset=(0, 0), pad=(0, 0), order=1):\n",
    "        coords = [d.flatten() for d in self.get(offset, pad)]\n",
    "        outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n",
    "        if len(data.shape) == len(self.shape) + 1:\n",
    "            tile = np.empty((*outshape, data.shape[-1]))\n",
    "            for c in range(data.shape[-1]):\n",
    "                tile[..., c] = ndimage.interpolation.map_coordinates(\n",
    "                    data[..., c], coords, order=order, mode=\"reflect\"\n",
    "                ).reshape(outshape)\n",
    "            return tile.astype(data.dtype)\n",
    "        else:\n",
    "            return (\n",
    "                ndimage.interpolation.map_coordinates(\n",
    "                    data, coords, order=order, mode=\"reflect\"\n",
    "                )\n",
    "                .reshape(outshape)\n",
    "                .astype(data.dtype)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataPreProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        element_size_um=None,\n",
    "        border_weight_sigma_px=6,\n",
    "        foreground_dist_sigma_px=6,\n",
    "        border_weight_factor=50,\n",
    "        foreground_background_ratio=1.0,\n",
    "    ):\n",
    "        self.element_size_um = element_size_um\n",
    "        self.border_weight_sigma_px = border_weight_sigma_px\n",
    "        self.foreground_dist_sigma_px = foreground_dist_sigma_px\n",
    "        self.border_weight_factor = border_weight_factor\n",
    "        self.foreground_background_ratio = foreground_background_ratio\n",
    "\n",
    "    def generateSample(\n",
    "        self, data, instancelabels=None, classlabels=None, ignore=None, weights=None\n",
    "    ):\n",
    "\n",
    "        dataScaled = data[\"rawdata\"].astype(float)\n",
    "        elSize = data[\"element_size_um\"]\n",
    "        nDims = len(dataScaled.shape) - 1\n",
    "        instlabels = instancelabels\n",
    "        clabels = classlabels\n",
    "        ign = ignore\n",
    "        wghts = weights\n",
    "\n",
    "        # If weights need to be computed, and no instance labels are given,\n",
    "        # generate them now\n",
    "        if wghts is None and clabels is not None and instlabels is None:\n",
    "            instlabels = np.zeros_like(clabels)\n",
    "            classes = np.unique(clabels)[1:]\n",
    "            nextInstance = 1\n",
    "            for c in classes:\n",
    "                comps, nInstances = ndimage.measurements.label(clabels == c)\n",
    "                instlabels[comps > 0] = comps[comps > 0] + nextInstance\n",
    "                # instlabels[comps > 0] = instances[comps > 0] + nextInstance #old\n",
    "                nextInstance += nInstances\n",
    "\n",
    "        # Rescale blobs to processing element size\n",
    "        if self.element_size_um is not None and np.any(\n",
    "            np.asarray(elSize) != np.asarray(self.element_size_um)\n",
    "        ):\n",
    "            print(\"  Rescaling...\")\n",
    "            scales = tuple(s / t for (s, t) in zip(elSize, self.element_size_um))\n",
    "\n",
    "            dataScaled = ndimage.zoom(dataScaled, (*scales, 1), order=1, mode=\"reflect\")\n",
    "\n",
    "            if instlabels is not None:\n",
    "                instlabels = ndimage.zoom(instlabels, scales, order=0, mode=\"reflect\")\n",
    "            if clabels is not None:\n",
    "                clabels = ndimage.zoom(clabels, scales, order=0, mode=\"reflect\")\n",
    "            if ign is not None:\n",
    "                ign = ndimage.zoom(ign, scales, order=0, mode=\"reflect\")\n",
    "            if wghts is not None:\n",
    "                wghts = ndimage.zoom(wghts, scales, order=1, mode=\"reflect\")\n",
    "\n",
    "        # Normalize values to [0,1] range\n",
    "        # print(\"  Normalizing intensity range...\")\n",
    "        # pdb.set_trace()\n",
    "        for c in range(dataScaled.shape[-1]):\n",
    "            minValue = np.min(dataScaled[..., c])\n",
    "            maxValue = np.max(dataScaled[..., c])\n",
    "            dataScaled[..., c] = (dataScaled[..., c] - minValue) / (maxValue - minValue)\n",
    "\n",
    "        # If no labels are given we are done and simply return the data array\n",
    "        if instlabels is None and clabels is None:\n",
    "            return dataScaled.astype(np.float32), None, None, None\n",
    "\n",
    "        # If no classlabels are given treat the problem as binary segmentation\n",
    "        # ==> Create a new array assigning class 1 (foreground) to each instance\n",
    "        if clabels is None:\n",
    "            clabels = instlabels > 0\n",
    "\n",
    "        # If weights are given we only need to compute the sample pdf and we're\n",
    "        # done\n",
    "        if wghts is not None:\n",
    "            pdf = (clabels > 0) + self.foreground_background_ratio * (clabels == 0)\n",
    "            if ign is not None:\n",
    "                pdf *= 1 - ign\n",
    "            return (\n",
    "                dataScaled.astype(np.float32),\n",
    "                clabels.astype(np.int32),\n",
    "                wghts.astype(np.float32),\n",
    "                pdf.astype(np.float32),\n",
    "            )\n",
    "\n",
    "        # No weights given, so we need to compute them\n",
    "\n",
    "        # Initialize label and weights arrays with background\n",
    "        labels = np.zeros_like(clabels)\n",
    "        wghts = self.foreground_background_ratio * np.ones_like(clabels)\n",
    "        frgrd_dist = np.zeros_like(clabels, dtype='float32')\n",
    "        # Get all foreground class labels\n",
    "        classes = np.unique(clabels)[1:]\n",
    "\n",
    "        for c in classes:\n",
    "\n",
    "            # Extract all instance labels of class c\n",
    "            instances = np.unique(instlabels * (clabels == c))[1:]\n",
    "\n",
    "            # Generate background ridges between touching instances\n",
    "            # of that class, avoid overlapping instances\n",
    "            # print(\"  Generating ridges...\")\n",
    "            for instance in instances:\n",
    "                objectMaskDil = ndimage.morphology.binary_dilation(\n",
    "                    labels == c, structure=np.ones((3,) * nDims)\n",
    "                )\n",
    "                labels[(instlabels == instance) & (objectMaskDil == 0)] = c\n",
    "\n",
    "            # Generate weights\n",
    "            # print(\"   Generating weights...\")\n",
    "            min1dist = 1e10 * np.ones(labels.shape)\n",
    "            min2dist = 1e10 * np.ones(labels.shape)\n",
    "            for instance in instances:\n",
    "                dt = ndimage.morphology.distance_transform_edt(instlabels != instance)\n",
    "                frgrd_dist += np.exp(-dt ** 2 / (2*self.foreground_dist_sigma_px ** 2))\n",
    "                min2dist = np.minimum(min2dist, dt)\n",
    "                newMin1 = np.minimum(min1dist, min2dist)\n",
    "                newMin2 = np.maximum(min1dist, min2dist)\n",
    "                min1dist = newMin1\n",
    "                min2dist = newMin2\n",
    "            wghts += self.border_weight_factor * np.exp(\n",
    "                -(min1dist + min2dist) ** 2 / (2*self.border_weight_sigma_px ** 2)\n",
    "            )\n",
    "\n",
    "        # Set weight for distance to the closest foreground object\n",
    "        # wghts[labels == 0] += (1-self.foreground_background_ratio)*frgrd_dist[labels == 0]\n",
    "        # Set foreground weights to 1\n",
    "        wghts[labels > 0] = 1\n",
    "        pdf = (labels > 0) + (labels == 0) * self.foreground_background_ratio\n",
    "\n",
    "        # Set weight and sampling probability for ignored regions to 0\n",
    "        if ign is not None:\n",
    "            wghts[ign] = 0\n",
    "            pdf[ign] = 0\n",
    "\n",
    "        return (\n",
    "            dataScaled.astype(np.float32),\n",
    "            labels.astype(np.int32),\n",
    "            wghts.astype(np.float32),\n",
    "            pdf.astype(np.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataAugmentationGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"\n",
    "    data - A list of tuples of the form\n",
    "           [{ rawdata: numpy.ndarray (HxWxC),\n",
    "              element_size_um: [e_y, e_x] }, ...]\n",
    "           containing the raw data ([0-1] normalized) and corresponding\n",
    "           element sizes in micrometers\n",
    "    instancelabels - A list containing the corresponding instance labels.\n",
    "                     0 = background, 1-m instance labels\n",
    "    tile_shape - The tile shape the network expects as input\n",
    "    padding - The padding (input shape - output shape)\n",
    "    classlabels - A list containing the corresponding class labels.\n",
    "                  0 = ignore, 1 = background, 2-n foreground classes\n",
    "                  If None, the problem will be treated as binary segmentation\n",
    "    n_classes - The number of classes including background\n",
    "    ignore - A list containing the corresponding ignore regions.\n",
    "    weights - A list containing the corresponding weights.\n",
    "    element_size_um - The target pixel size in micrometers\n",
    "    batch_size - The number of tiles to generate per batch\n",
    "    rotation_range_deg - (alpha_min, alpha_max): The range of rotation angles.\n",
    "                         A random rotation is drawn from a uniform distribution\n",
    "                         in the given range\n",
    "    flip - If true, a coin flip decides whether a mirrored tile will be\n",
    "           generated\n",
    "    deformation_grid - (dx, dy): The distance of neighboring grid points in\n",
    "                       pixels for which random deformation vectors are drawn\n",
    "    deformation_magnitude - (sx, sy): The standard deviations of the\n",
    "                            Gaussians, the components of the deformation\n",
    "                            vector are drawn from\n",
    "    value_minimum_range - (v_min, v_max): Input intensity zero will be mapped\n",
    "                          to a random value in the given range\n",
    "    value_maximum_range - (v_min, v_max): Input intensity one will be mapped\n",
    "                          to a random value within the given range\n",
    "    value_slope_range - (s_min, s_max): The slope at control points is drawn\n",
    "                        from a uniform distribution in the given range\n",
    "    border_weight_sigma_px - The border weight standard deviation in pixels\n",
    "    border_weight_factor - The border weight factor to enforce instance\n",
    "                           separation\n",
    "    foreground_background_ratio - The ratio between foreground and background\n",
    "                                  pixels\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        instancelabels=None,\n",
    "        classlabels=None,\n",
    "        tile_shape=(540,540),\n",
    "        padding=(184,184),\n",
    "        n_classes=2,\n",
    "        ignore=None,\n",
    "        weights=None,\n",
    "        batch_size=4,\n",
    "        element_size_um=None,\n",
    "        rotation_range_deg=(0, 360),\n",
    "        flip=False,\n",
    "        deformation_grid=(150, 150),\n",
    "        deformation_magnitude=(10, 10),\n",
    "        value_minimum_range=(0, 0),\n",
    "        value_maximum_range=(1, 1),\n",
    "        value_slope_range=(1, 1),\n",
    "        shuffle=True,\n",
    "        foreground_dist_sigma_px=10,\n",
    "        border_weight_sigma_px=6,\n",
    "        border_weight_factor=50,\n",
    "        foreground_background_ratio=0.1,\n",
    "    ):\n",
    "\n",
    "        assert instancelabels is not None or classlabels is not None\n",
    "\n",
    "        self.tile_shape = tile_shape\n",
    "        self.padding = padding\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.rotation_range_deg = rotation_range_deg\n",
    "        self.flip = flip\n",
    "        self.deformation_grid = deformation_grid\n",
    "        self.deformation_magnitude = deformation_magnitude\n",
    "        self.value_minimum_range = value_minimum_range\n",
    "        self.value_maximum_range = value_maximum_range\n",
    "        self.value_slope_range = value_slope_range\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.n_channels = data[0][\"rawdata\"].shape[2]\n",
    "        self.output_shape = tuple(int(t - p) for (t, p) in zip(tile_shape, padding))\n",
    "\n",
    "        pre = DataPreProcessor(\n",
    "            element_size_um,\n",
    "            border_weight_sigma_px,\n",
    "            foreground_dist_sigma_px,\n",
    "            border_weight_factor,\n",
    "            foreground_background_ratio,\n",
    "        )\n",
    "\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.weights = []\n",
    "        self.pdf = []\n",
    "        print(\"Processing training samples\")\n",
    "        for i in tqdm(range(len(data))):\n",
    "\n",
    "            (sampleData, sampleLabels, sampleWeights, samplePdf) = pre.generateSample(\n",
    "                data[i],\n",
    "                instancelabels[i] if instancelabels is not None else None,\n",
    "                classlabels=classlabels[i] if classlabels is not None else None,\n",
    "                ignore=ignore[i] if ignore is not None else None,\n",
    "                weights=weights[i] if weights is not None else None,\n",
    "            )\n",
    "            self.data.append(sampleData)\n",
    "            self.labels.append(sampleLabels)\n",
    "            self.weights.append(sampleWeights)\n",
    "            self.pdf.append(samplePdf)\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "        #return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Option to retrieve multiple random samples\n",
    "        index = np.mod(index,len(self))\n",
    "        if index >= len(self):\n",
    "            raise ValueError('Asked to retrieve element {index}, '\n",
    "                             'but the Sequence '\n",
    "                             'has length {length}'.format(index=index,\n",
    "                                                          length=len(self)))\n",
    "        return self.__data_generation(\n",
    "            self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # print()\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "\n",
    "        if self.shuffle:\n",
    "            # print(\"Shuffling training samples\")\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "        # print(\"Generating deformation field\")\n",
    "        self.deformationField = DeformationField(self.tile_shape)\n",
    "\n",
    "        if self.rotation_range_deg[1] > self.rotation_range_deg[0]:\n",
    "            self.deformationField.rotate(\n",
    "                theta=math.pi\n",
    "                * (\n",
    "                    np.random.random()\n",
    "                    * (self.rotation_range_deg[1] - self.rotation_range_deg[0])\n",
    "                    + self.rotation_range_deg[0]\n",
    "                )\n",
    "                / 180.0\n",
    "            )\n",
    "\n",
    "        if self.flip:\n",
    "            self.deformationField.mirror(np.random.choice((True,False),2)\n",
    "            )\n",
    "\n",
    "        if self.deformation_grid is not None:\n",
    "            self.deformationField.addRandomDeformation(\n",
    "                self.deformation_grid, self.deformation_magnitude\n",
    "            )\n",
    "\n",
    "        # print(\"Generating value augmentation function\")\n",
    "        minValue = (\n",
    "            self.value_minimum_range[0]\n",
    "            + (self.value_minimum_range[1] - self.value_minimum_range[0])\n",
    "            * np.random.random()\n",
    "        )\n",
    "        maxValue = (\n",
    "            self.value_maximum_range[0]\n",
    "            + (self.value_maximum_range[1] - self.value_maximum_range[0])\n",
    "            * np.random.random()\n",
    "        )\n",
    "        intermediateValue = 0.5 * (\n",
    "            self.value_slope_range[0]\n",
    "            + (self.value_slope_range[1] - self.value_slope_range[0])\n",
    "            * np.random.random()\n",
    "        )\n",
    "        self.gammaFcn = interp1d(\n",
    "            [0, 0.5, 1.0], [minValue, intermediateValue, maxValue], kind=\"quadratic\"\n",
    "        )\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        X = np.empty(\n",
    "            (self.batch_size, *self.tile_shape, self.n_channels), dtype=np.float32\n",
    "        )\n",
    "        Y = np.zeros((self.batch_size, *self.output_shape), dtype=np.int)\n",
    "        W = np.empty((self.batch_size, *self.output_shape), dtype=np.float)\n",
    "        for i, idx in enumerate(indexes):\n",
    "            cumulatedPdf = np.cumsum(self.pdf[idx] / np.sum(self.pdf[idx]))\n",
    "            # Random center\n",
    "            center = np.unravel_index(np.argmax(cumulatedPdf > np.random.random()), self.pdf[idx].shape)\n",
    "            X[i,...] = self.gammaFcn(self.deformationField.apply(self.data[idx], center).flatten()).reshape((*self.tile_shape, self.n_channels))\n",
    "            Y[i, ...] = self.deformationField.apply(self.labels[idx], center, self.padding, 0)\n",
    "            W[i, ...] = self.deformationField.apply(self.weights[idx], center, self.padding, 1)\n",
    "\n",
    "        Y = tf.keras.utils.to_categorical(Y, num_classes=self.n_classes)\n",
    "        return  (X, {'conv_u0d-score': np.append(Y, np.expand_dims(W, axis=-1), axis=-1), 'softmax': Y}, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile Generator\n",
    "\n",
    "For validation and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TileGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"\n",
    "    data - A list of tuples of the form\n",
    "           [{ rawdata: numpy.ndarray (HxWxC),\n",
    "              element_size_um: [e_y, e_x] }, ...]\n",
    "           containing the raw data ([0-1] normalized) and corresponding\n",
    "           element sizes in micrometers\n",
    "    instancelabels - A list containing the corresponding instance labels.\n",
    "                     0 = background, 1-m instance labels\n",
    "    tile_shape - The tile shape the network expects as input\n",
    "    padding - The padding (input shape - output shape)\n",
    "    classlabels - A list containing the corresponding class labels.\n",
    "                   0 = ignore, 1 = background, 2-n foreground classes\n",
    "                   If None, the problem will be treated as binary segmentation\n",
    "    n_classes - The number of classes including background\n",
    "    ignore - A list containing the corresponding ignore regions.\n",
    "    weights - A list containing the corresponding weights.\n",
    "    element_size_um - The target pixel size in micrometers\n",
    "    border_weight_sigma_px - The border weight standard deviation in pixels\n",
    "    border_weight_factor - The border weight factor to enforce instance\n",
    "                           separation\n",
    "    foreground_background_ratio - The ratio between foreground and background\n",
    "                                  pixels\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        tile_shape=(540,540),\n",
    "        padding=(184,184),\n",
    "        instancelabels=None,\n",
    "        classlabels=None,\n",
    "        n_classes=2,\n",
    "        ignore=None,\n",
    "        weights=None,\n",
    "        element_size_um=None,\n",
    "        foreground_dist_sigma_px=10,\n",
    "        border_weight_sigma_px=6,\n",
    "        border_weight_factor=50,\n",
    "        foreground_background_ratio=0.1,\n",
    "    ):\n",
    "        self.tile_shape = tile_shape\n",
    "        self.padding = padding\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.n_channels = data[0][\"rawdata\"].shape[-1]\n",
    "        self.output_shape = tuple(int(t - p) for (t, p) in zip(tile_shape, padding))\n",
    "\n",
    "        pre = DataPreProcessor(\n",
    "            element_size_um,\n",
    "            border_weight_sigma_px,\n",
    "            foreground_dist_sigma_px,\n",
    "            border_weight_factor,\n",
    "            foreground_background_ratio,\n",
    "        )\n",
    "        tiler = DeformationField(tile_shape)\n",
    "\n",
    "        self.hasLabels = instancelabels is not None or classlabels is not None\n",
    "        self.data = []\n",
    "        self.labels = [] if self.hasLabels else None\n",
    "        self.weights = [] if self.hasLabels else None\n",
    "        self.image_indices = []\n",
    "        self.image_shapes = []\n",
    "        self.in_slices = []\n",
    "        self.out_slices = []\n",
    "\n",
    "        print(\"Processing test samples\")\n",
    "\n",
    "        for i in tqdm(range(len(data))):\n",
    "            (sampleData, sampleLabels, sampleWeights, _) = pre.generateSample(\n",
    "                data[i],\n",
    "                instancelabels[i] if instancelabels is not None else None,\n",
    "                classlabels=classlabels[i] if classlabels is not None else None,\n",
    "                ignore=ignore[i] if ignore is not None else None,\n",
    "                weights=weights[i] if weights is not None else None,\n",
    "            )\n",
    "\n",
    "            # Tiling\n",
    "            data_shape = sampleData.shape[:-1]\n",
    "            for ty in range(int(np.ceil(data_shape[0] / self.output_shape[0]))):\n",
    "                for tx in range(int(np.ceil(data_shape[1] / self.output_shape[1]))):\n",
    "                    centerPos = (\n",
    "                        int((ty + 0.5) * self.output_shape[0]),\n",
    "                        int((tx + 0.5) * self.output_shape[1]),\n",
    "                    )\n",
    "                    self.data.append(tiler.apply(sampleData, centerPos))\n",
    "                    if self.hasLabels:\n",
    "                        self.labels.append(\n",
    "                            tiler.apply(sampleLabels, centerPos, padding, order=0)\n",
    "                        )\n",
    "                        self.weights.append(\n",
    "                            tiler.apply(sampleWeights, centerPos, padding, order=1)\n",
    "                        )\n",
    "                    self.image_indices.append(i)\n",
    "                    self.image_shapes.append(data_shape)\n",
    "                    sliceDef = tuple(\n",
    "                        slice(tIdx * o, min((tIdx + 1) * o, s))\n",
    "                        for (tIdx, o, s) in zip((ty, tx), self.output_shape, data_shape)\n",
    "                    )\n",
    "                    self.out_slices.append(sliceDef)\n",
    "                    sliceDef = tuple(\n",
    "                        slice(0, min((tIdx + 1) * o, s) - tIdx * o)\n",
    "                        for (tIdx, o, s) in zip((ty, tx), self.output_shape, data_shape)\n",
    "                    )\n",
    "                    self.in_slices.append(sliceDef)\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __data_generation(self, idx, training=True):\n",
    "        X = np.empty((1, *self.tile_shape, self.n_channels), dtype=np.float32)\n",
    "        Y = np.zeros((1, *self.output_shape), dtype=np.int) if self.hasLabels else None\n",
    "        W = (\n",
    "            np.empty((1, *self.output_shape), dtype=np.float)\n",
    "            if self.hasLabels\n",
    "            else None\n",
    "        )\n",
    "        X[0, ...] = self.data[idx]\n",
    "        if self.hasLabels:\n",
    "            Y[0, ...] = self.labels[idx]\n",
    "            W[0, ...] = self.weights[idx]\n",
    "            Y = tf.keras.utils.to_categorical(Y, num_classes=self.n_classes)\n",
    "            return  (X,{'conv_u0d-score': np.append(Y, np.expand_dims(W, axis=-1), axis=-1), 'softmax': Y}, {})\n",
    "        else:\n",
    "            return  X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
