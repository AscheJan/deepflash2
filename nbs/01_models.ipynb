{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "from fastcore.basics import patch\n",
    "from fastdownload import download_url\n",
    "from fastprogress import progress_bar\n",
    "from pathlib import Path\n",
    "import sys, subprocess\n",
    "from pip._internal.operations import freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#architectures-\n",
    "ARCHITECTURES =  ['Unet', 'UnetPlusPlus', 'FPN', 'PAN', 'PSPNet', 'Linknet', 'DeepLabV3', 'DeepLabV3Plus'] #'MAnet',\n",
    "\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#encoders-\n",
    "ENCODERS = [*smp.encoders.encoders.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenation Models Pytorch Integration\n",
    "\n",
    "From the website: \n",
    "\n",
    "- High level API (just two lines to create a neural network)\n",
    "- 9 models architectures for binary and multi class segmentation (including legendary Unet)\n",
    "- 104 available encoders\n",
    "- All encoders have pre-trained weights for faster and better convergence\n",
    "\n",
    "See https://github.com/qubvel/segmentation_models.pytorch for API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_pretrained_options(encoder_name):\n",
    "    'Return available options for pretrained weights for a given encoder'\n",
    "    options = smp.encoders.encoders[encoder_name]['pretrained_settings'].keys()\n",
    "    return [*options, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "PATCH_UNET_DECODER = False\n",
    "\n",
    "@patch\n",
    "def forward(self:smp.decoders.unet.decoder.UnetDecoder, *features):\n",
    "\n",
    "    features = features[1:]  # remove first skip with same spatial resolution\n",
    "    features = features[::-1]  # reverse channels to start from head of encoder\n",
    "\n",
    "    head = features[0]\n",
    "    skips = features[1:]\n",
    "\n",
    "    x = self.center(head)\n",
    "    for i, decoder_block in enumerate(self.blocks):\n",
    "        skip = skips[i] if i < len(skips) else None\n",
    "        x = decoder_block(x, skip)\n",
    "\n",
    "    if PATCH_UNET_DECODER:\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_smp_model(arch, **kwargs):\n",
    "    'Create segmentation_models_pytorch model'\n",
    "    \n",
    "    assert arch in ARCHITECTURES, f'Select one of {ARCHITECTURES}'\n",
    "    is_convnext_encoder = kwargs['encoder_name'].startswith('tu-convnext')\n",
    "    assert not all((arch!=\"Unet\", is_convnext_encoder)), 'ConvNeXt encoder can only be used with Unet'\n",
    "    \n",
    "    if arch==\"Unet\": \n",
    "        global PATCH_UNET_DECODER\n",
    "        if is_convnext_encoder:\n",
    "            kwargs['encoder_depth'] = 4\n",
    "            kwargs['decoder_channels'] = (256, 128, 64, 16)\n",
    "            PATCH_UNET_DECODER = True\n",
    "        else:\n",
    "            PATCH_UNET_DECODER = False\n",
    "        model =  smp.Unet(**kwargs)\n",
    "        \n",
    "    elif arch==\"UnetPlusPlus\": model = smp.UnetPlusPlus(**kwargs)\n",
    "    elif arch==\"MAnet\":model = smp.MAnet(**kwargs)\n",
    "    elif arch==\"FPN\": model = smp.FPN(**kwargs)\n",
    "    elif arch==\"PAN\": model = smp.PAN(**kwargs)\n",
    "    elif arch==\"PSPNet\": model = smp.PSPNet(**kwargs)\n",
    "    elif arch==\"Linknet\": model = smp.Linknet(**kwargs)\n",
    "    elif arch==\"DeepLabV3\": model = smp.DeepLabV3(**kwargs)\n",
    "    elif arch==\"DeepLabV3Plus\": model = smp.DeepLabV3Plus(**kwargs)\n",
    "    else: raise NotImplementedError\n",
    "    \n",
    "    setattr(model, 'kwargs', kwargs)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "bs = 2\n",
    "tile_shapes = [256, 640] #1024\n",
    "in_channels = [1] #1,3,4\n",
    "classes = [2, 5] # 2,5\n",
    "encoders = ENCODERS[0:1]+['tu-convnext_tiny']#+ENCODERS[-1:]\n",
    "archs = ARCHITECTURES[0:1]\n",
    "\n",
    "for ts in tile_shapes:\n",
    "    for in_c in in_channels:\n",
    "        for c in classes:\n",
    "            inp = torch.randn(bs, in_c, ts, ts)\n",
    "            out_shape = [bs, c, ts, ts]\n",
    "            for arch in archs:\n",
    "                for encoder_name in encoders:\n",
    "                    model = create_smp_model(arch=arch, \n",
    "                                             encoder_name=encoder_name,\n",
    "                                             #encoder_weights=None,\n",
    "                                             in_channels=in_c, \n",
    "                                             classes=c)\n",
    "                    out = model(inp)\n",
    "                    test_eq(out.shape, out_shape)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_smp_model(model, arch, path, stats=None, pickle_protocol=2):\n",
    "    'Save smp model, optionally including  stats'\n",
    "    path = Path(path)\n",
    "    state = model.state_dict()\n",
    "    save_dict = {'model': state, 'arch': arch, 'stats': stats, **model.kwargs}\n",
    "    torch.save(save_dict, path, pickle_protocol=pickle_protocol, _use_new_zipfile_serialization=False)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'Unet'\n",
    "path = 'tst.pth'\n",
    "stats = (1,1)\n",
    "kwargs = {'encoder_name': 'resnet34'}\n",
    "tst = create_smp_model(arch, **kwargs)\n",
    "path = save_smp_model(tst, arch, path, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_smp_model(path, device=None, strict=True, **kwargs):\n",
    "    'Loads smp model from file '\n",
    "    path = Path(path)\n",
    "    if isinstance(device, int): device = torch.device('cuda', device)\n",
    "    elif device is None: device = 'cpu'  \n",
    "    model_dict = torch.load(path, map_location=device)\n",
    "    state = model_dict.pop('model')    \n",
    "    stats = model_dict.pop('stats') \n",
    "    # Ensure that no pretrained encoder weights are loaded \n",
    "    model_dict.pop('encoder_weights', None)\n",
    "    model = create_smp_model(**model_dict,  encoder_weights=None, **kwargs)\n",
    "    model.load_state_dict(state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2, stats2 = load_smp_model(path)\n",
    "for p1, p2 in zip(tst.parameters(), tst2.parameters()):\n",
    "    test_eq(p1.detach(), p2.detach())\n",
    "test_eq(stats, stats2)\n",
    "path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellpose integration\n",
    "\n",
    "for reliable cell and nucleus segmentation. Visit [cellpose](https://github.com/MouseLand/cellpose) for more information. \n",
    "\n",
    "Cellpose integration for deepflash2 is tested on version 0.6.6.dev13+g316927e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_cellpose_installation(show_progress=True):\n",
    "    tarball = 'cellpose-0.6.6.dev13+g316927e.tar.gz' # '316927eff7ad2201391957909a2114c68baee309'\n",
    "    try: \n",
    "        extract = [x for x in freeze.freeze() if x.startswith('cellpose')][0][-15:]\n",
    "        assert extract==tarball[-15:]\n",
    "    except:\n",
    "        print(f'Installing cellpose. Please wait.')\n",
    "        home_dir = Path.home()/'.deepflash2'\n",
    "        home_dir.mkdir(exist_ok=True, parents=True)\n",
    "        url = f'https://github.com/matjesg/deepflash2/releases/download/0.1.4/{tarball}'\n",
    "        file = download_url(url, home_dir, show_progress=show_progress)\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", '--no-deps', file.as_posix()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_diameters(masks):\n",
    "    'Get diameters from deepflash2 prediction'\n",
    "    from cellpose import utils\n",
    "    diameters = []\n",
    "    for m in masks:\n",
    "        _, comps = cv2.connectedComponents(m.astype('uint8'), connectivity=4)\n",
    "        diameters.append(utils.diameters(comps)[0])\n",
    "    return int(np.array(diameters).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_cellpose(probs, masks, model_type='nuclei', diameter=0, min_size=-1, gpu=True, flow_threshold=0.4):\n",
    "    'Run cellpose on deepflash2 predictions'\n",
    "    check_cellpose_installation()\n",
    "\n",
    "    if diameter==0: \n",
    "        diameter = get_diameters(masks)\n",
    "    print(f'Using diameter of {diameter}')\n",
    "    \n",
    "    from cellpose import models, dynamics, utils\n",
    "    @patch\n",
    "    def _compute_masks(self:models.CellposeModel, dP, cellprob, p=None, niter=200,\n",
    "                        flow_threshold=0.4, interp=True, do_3D=False, min_size=15, resize=None, **kwargs):\n",
    "        \"\"\" compute masks using dynamics from dP and cellprob \"\"\"\n",
    "        if p is None:\n",
    "            p = dynamics.follow_flows(-1 * dP * mask / 5., niter=niter, interp=interp, use_gpu=self.gpu)\n",
    "        maski = dynamics.get_masks(p, iscell=mask, flows=dP, threshold=flow_threshold)\n",
    "        \n",
    "        # remove postpreocessing?\n",
    "        maski = utils.fill_holes_and_remove_small_masks(maski, min_size=min_size)\n",
    "        \n",
    "        # resizing does not work \n",
    "        #if resize is not None:\n",
    "        #    maski = transforms.resize_image(maski, resize[0], resize[1], interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        return maski, p\n",
    "    \n",
    "    model = models.Cellpose(gpu=gpu, model_type=model_type)\n",
    "    cp_masks = []\n",
    "    for prob, mask in progress_bar(zip(probs, masks), total=len(probs), leave=False):\n",
    "        cp_pred, _, _, _ = model.eval(prob, \n",
    "                                       net_avg=True,\n",
    "                                       augment=True,\n",
    "                                       diameter=diameter, \n",
    "                                       normalize=False,\n",
    "                                       min_size=min_size,\n",
    "                                       flow_threshold=flow_threshold,\n",
    "                                       resample=True,\n",
    "                                       channels=[0,0])\n",
    "        cp_masks.append(cp_pred)\n",
    "    return cp_masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using diameter of 17.0\n",
      "2022-07-12 14:52:03,044 [INFO] WRITING LOG OUTPUT TO /home/magr/.cellpose/run.log\n",
      "2022-07-12 14:52:05,343 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2022-07-12 14:52:05,343 [INFO] >>>> using GPU\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-12 14:52:05,392 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-07-12 14:52:07,577 [INFO] >>>> TOTAL TIME 2.19 sec\n"
     ]
    }
   ],
   "source": [
    "probs = [np.random.rand(512,512)]\n",
    "masks = [x>0. for x in probs]\n",
    "cp_preds = run_cellpose(probs, masks, diameter=17.)\n",
    "test_eq(probs[0].shape, cp_preds[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_learner.ipynb.\n",
      "Converted 04_inference.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted tutorial.ipynb.\n",
      "Converted tutorial_gt.ipynb.\n",
      "Converted tutorial_pred.ipynb.\n",
      "Converted tutorial_train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
