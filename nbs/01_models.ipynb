{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Unet models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Unet2D(n_channels=1, n_classes=2, n_levels=4, n_features=64,\n",
    "           n_batch_norm_levels=0, upsample = False,\n",
    "           relu_alpha=0.1, k_init=\"he_normal\"):\n",
    "\n",
    "    # Define custom layers\n",
    "    conf2d = partial(layers.Conv2D, padding=\"valid\", kernel_initializer= k_init)\n",
    "    conf2dT = partial(layers.Conv2DTranspose, padding=\"valid\", kernel_initializer= k_init)\n",
    "\n",
    "    # Inputs\n",
    "    inputs = layers.Input(shape=(None, None,  n_channels), name=\"data\")\n",
    "    down_stack = []\n",
    "\n",
    "    # Modules of the analysis path consist of two convolutions and max pooling\n",
    "    for l in range( n_levels):\n",
    "        x = conf2d(2**l *  n_features, 3, name=\"conv_d{}a-b\".format(l))(inputs if l == 0 else x)\n",
    "        x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "        if l >  n_batch_norm_levels:\n",
    "            x = layers.BatchNormalization(axis=-1)(x)\n",
    "        x = conf2d(2**l *  n_features, 3, name=\"conv_d{}b-c\".format(l))(x)\n",
    "        x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "        if l >  n_batch_norm_levels:\n",
    "            x = layers.BatchNormalization(axis=-1)(x)\n",
    "        if l >= 2:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        down_stack.append(x)\n",
    "        x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Deepest layer has two convolutions only\n",
    "    x = conf2d(2** n_levels *  n_features, 3, name=\"conv_d{}a-b\".format( n_levels))(x)\n",
    "    x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "    if l >  n_batch_norm_levels:\n",
    "        x = layers.BatchNormalization(axis=-1)(x)\n",
    "    x = conf2d(2** n_levels *  n_features, 3, name=\"conv_d{}b-c\".format( n_levels))(x)\n",
    "    x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "    if l >  n_batch_norm_levels:\n",
    "        x = layers.BatchNormalization(axis=-1)(x)\n",
    "    pad = 8\n",
    "\n",
    "    # Modules in the synthesis path consist of up-convolution,\n",
    "    # concatenation and two convolutions\n",
    "    for l in range( n_levels - 1, -1, -1):\n",
    "        name = \"upconv_{}{}{}_u{}a\".format(\n",
    "            *((\"d\", l+1, \"c\", l) if l ==  n_levels - 1 else (\"u\", l+1, \"d\", l)))\n",
    "        if  upsample:\n",
    "            x = layers.UpSampling2D(size=(2, 2), name=name)(x)\n",
    "        else:\n",
    "            x = conf2dT(2**np.max((l, 1)) *  n_features, (2, 2), strides=2, name=name)(x)\n",
    "            x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "            if l >  n_batch_norm_levels:\n",
    "                x = layers.BatchNormalization(axis=-1)(x)\n",
    "        x = layers.Concatenate()([layers.Cropping2D(cropping=int(pad / 2))(down_stack[l]), x])\n",
    "        x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "        x = conf2d(2**np.max((l, 1)) *  n_features, 3, name=\"conv_u{}b-c\".format(l))(x)\n",
    "        if l >  n_batch_norm_levels:\n",
    "            x = layers.BatchNormalization(axis=-1)(x)\n",
    "        x = conf2d(2**np.max((l, 1)) *  n_features, 3, name=\"conv_u{}c-d\".format(l))(x)\n",
    "        x = layers.LeakyReLU(alpha= relu_alpha)(x)\n",
    "        if l >  n_batch_norm_levels:\n",
    "            x = layers.BatchNormalization(axis=-1)(x)\n",
    "        pad = 2 * (pad + 8)\n",
    "\n",
    "    score = conf2d( n_classes, 1, name=\"conv_u0d-score\")(x)\n",
    "    softmax_score = layers.Softmax(name='softmax')(score)\n",
    "\n",
    "    model= tf.keras.Model(inputs=inputs, outputs=[score, softmax_score])\n",
    "\n",
    "    model.n_channels = n_channels\n",
    "    model.n_levels = n_levels\n",
    "    model.n_classes = n_classes\n",
    "    model.n_features = n_features\n",
    "    model.n_batch_norm_levels = n_batch_norm_levels\n",
    "    model.relu_alpha = relu_alpha\n",
    "    model.k_init = k_init\n",
    "    model.upsample = upsample\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
