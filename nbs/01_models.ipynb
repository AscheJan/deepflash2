{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to deepflash2.models,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch implementation adapted from https://github.com/jvanvugt/pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm,\n",
    "                 dropout=0., neg_slope=0.1):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        if dropout>0.:\n",
    "            block.append(nn.Dropout(p=dropout))\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "        block.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
    "\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "        block.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm,\n",
    "                 dropout=0., neg_slope=0.1):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        up_block = []\n",
    "        if dropout>0.:\n",
    "            up_block.append(nn.Dropout(p=dropout))\n",
    "        if up_mode == 'upconv':\n",
    "            up_block.append(nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2))\n",
    "        elif up_mode == 'upsample':\n",
    "            up_block.append(nn.Upsample(mode='bilinear', scale_factor=2))\n",
    "            up_block.append(nn.Conv2d(in_size, out_size, kernel_size=1))\n",
    "        if batch_norm:\n",
    "            up_block.append(nn.BatchNorm2d(out_size))\n",
    "        up_block.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
    "\n",
    "        self.up = nn.Sequential(*up_block)\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class UNet2D(nn.Module):\n",
    "    \"Pytorch U-Net Implementation\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        dropout = 0.,\n",
    "        neg_slope=0.,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            if batch_norm:\n",
    "                bn = True if i>0 else False\n",
    "            else:\n",
    "                bn = False\n",
    "            if dropout>0.:\n",
    "                do = dropout if i>2 else 0.\n",
    "            else:\n",
    "                do = 0.\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding,\n",
    "                              batch_norm=bn, dropout=do,neg_slope=neg_slope)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            if batch_norm:\n",
    "                bn = True if i>0 else False\n",
    "            else:\n",
    "                bn = False\n",
    "            if dropout>0.:\n",
    "                do = dropout if i>2 else 0.\n",
    "            else:\n",
    "                do = 0.\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding,\n",
    "                            batch_norm=bn, dropout=do, neg_slope=neg_slope)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize layer weights\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Args__:\\\n",
    "`in_channels` (int): the number of input channels.\\\n",
    "`n_classes` (int): the number of output channels. \\\n",
    "`depth` (int): depth of the network.\\\n",
    "`wf` (int): number of filters in the first layer is 2^wf\n",
    "`padding` (bool): if True, apply padding such that the input shape is the same as the output. This may introduce artifacts\\\n",
    "`batch_norm` (bool): Use BatchNorm after layers with an activation function\\\n",
    "`up_mode` (str): one of 'upconv' or 'upsample'. 'upconv' will use transposed convolutions for learned upsampling. 'upsample' will use bilinear upsampling.\\\n",
    "`neg_slope`(float): Controls the angle of the negative slope for LeakyReLU. Standard ReLU if set to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "_MODEL_BASE_URL = 'https://github.com/matjesg/deepflash2/releases/download/model_library/'\n",
    "def _load_pretrained(model, dataset, progress):\n",
    "    \"Loads pretrained model weights\"\n",
    "    url = _MODEL_BASE_URL+dataset+'.pth'\n",
    "    try:\n",
    "        state_dict = torch.hub.load_state_dict_from_url(url, map_location='cpu', progress=progress)\n",
    "    except:\n",
    "        print(f\"Error: No weights available for model trained on {dataset}.\")\n",
    "\n",
    "    if model.state_dict()['last.weight'].shape != state_dict['last.weight'].shape:\n",
    "        print(f\"No pretrained weights for {model.state_dict()['last.weight'].shape[0]} classes in final layer.\")\n",
    "        state_dict.pop('last.bias')\n",
    "        state_dict.pop('last.weight')\n",
    "        \n",
    "\n",
    "    # TODO Better handle different number of input channels\n",
    "    _ = model.load_state_dict(state_dict, strict=False)\n",
    "    #print(f\"Loaded model weights trained on {dataset}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original U-Net architecture based on _Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def unet_ronneberger2015(in_channels=1 ,n_classes=2, pretrained=False, dataset='wue1_cFOS', progress=True):\n",
    "    \"Original U-Net architecture based on Ronnberger et al. (2015)\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes,\n",
    "                   depth=5, wf=6, padding=False, batch_norm=False,\n",
    "                   neg_slope=0., up_mode='upconv', dropout=0)\n",
    "    if pretrained:\n",
    "        _load_pretrained(model, dataset, progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net architecture based on _Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def unet_falk2019(in_channels=1 ,n_classes=2, pretrained=False, dataset='wue1_cFOS', progress=True):\n",
    "    \"U-Net architecture based on Falk et al. (2019)\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes,\n",
    "               depth=5, wf=6, padding=False, batch_norm=False,\n",
    "               neg_slope=0.1, up_mode='upconv', dropout=0)\n",
    "    if pretrained:\n",
    "        _load_pretrained(model, dataset, progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net model optimized for deepflash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def unet_deepflash2(in_channels=1 ,n_classes=2, pretrained=False, dataset='wue_cFOS', progress=True, dropout=.5):\n",
    "    \"U-Net model optimized for deepflash2\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes, dropout=dropout, \n",
    "                   depth=5, wf=6, padding=False, batch_norm=True,\n",
    "                   neg_slope=0.1, up_mode='upconv', )\n",
    "    if pretrained:\n",
    "        _load_pretrained(model, dataset, progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained weights for 3 classes in final layer.\n"
     ]
    }
   ],
   "source": [
    "tst = unet_deepflash2()\n",
    "tst = unet_deepflash2(pretrained=True)\n",
    "tst = unet_deepflash2(n_classes=3, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def unet_custom(in_channels=1 ,n_classes=2, pretrained=False, progress=True, **kwargs):\n",
    "    \"Customizable U-Net model. Customize via kwargs\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes, **kwargs)\n",
    "    if pretrained:\n",
    "        print('No pretrained weights available for custom architecture.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
