{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "![deepflash2](https://raw.githubusercontent.com/matjesg/deepflash2/master/nbs/media/logo/deepflash2_logo_medium.png)\n",
    "\n",
    "Official repository of deepflash2 - a deep-learning pipeline for segmentation of ambiguous microscopic images.\n",
    "\n",
    "![CI](https://github.com/matjesg/deepflash2/workflows/CI/badge.svg) \n",
    "[![PyPI](https://img.shields.io/pypi/v/deepflash2?color=blue&label=pypi%20version)](https://pypi.org/project/deepflash2/#description) \n",
    "[![PyPI - Downloads](https://img.shields.io/pypi/dm/deepflash2)](https://pypistats.org/packages/deepflash2)\n",
    "[![Conda (channel only)](https://img.shields.io/conda/vn/matjesg/deepflash2?color=seagreen&label=conda%20version)](https://anaconda.org/matjesg/deepflash2) \n",
    "[![Build fastai images](https://github.com/matjesg/deepflash2/workflows/Build%20deepflash2%20images/badge.svg)](https://github.com/matjesg/deepflash2)\n",
    "[![GitHub stars](https://img.shields.io/github/stars/matjesg/deepflash2?style=social)](https://github.com/matjesg/deepflash2/)\n",
    "[![GitHub forks](https://img.shields.io/github/forks/matjesg/deepflash2?style=social)](https://github.com/matjesg/deepflash2/)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The best of two worlds:__\n",
    "Combining state-of-the-art deep learning with a barrier free environment for life science researchers. \n",
    "\n",
    "> Read the [paper](https://arxiv.org/abs/2111.06693), watch the [tutorials](https://matjesg.github.io/deepflash2/tutorial.html), or read the [docs](https://matjesg.github.io/deepflash2/).\n",
    "    \n",
    "- **No coding skills required** (graphical user interface)\n",
    "- **Ground truth estimation** from the annotations of multiple experts for model training and validation\n",
    "- **Quality assurance and out-of-distribution detection** for reliable prediction on new data \n",
    "- **Best-in-class performance** for semantic and instance segmentation\n",
    "\n",
    "<img src=\"https://github.com/matjesg/deepflash2/blob/master/nbs/media/sample_images.png?raw=true\" width='800px'>\n",
    "\n",
    "\n",
    "<img style=\"float: left;padding: 0px 10px 0px 0px;\" src=\"https://www.kaggle.com/static/images/medals/competitions/goldl@1x.png\"/>\n",
    "\n",
    "**Kaggle Gold Medal and Innovation Price Winner:** The *deepflash2* Python API built the foundation for winning the [Innovation Award](https://hubmapconsortium.github.io/ccf/pages/kaggle.html) a Kaggle Gold Medal in the [HuBMAP - Hacking the Kidney](https://www.kaggle.com/c/hubmap-kidney-segmentation) challenge. \n",
    "Have a look at our [solution](https://www.kaggle.com/matjes/hubmap-deepflash2-judge-price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start and Demo\n",
    "> Get started in less than a minute. Watch the [tutorials](https://matjesg.github.io/deepflash2/tutorial.html) for help.\n",
    "\n",
    "For a quick start, run *deepflash2* in Google Colaboratory with free access to graphics processing units (GPUs).\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matjesg/deepflash2/blob/master/deepflash2_GUI.ipynb) \n",
    "\n",
    "To try the functionalities of *deepflash2*, open the *deepflash2* GUI in [Colab]((https://colab.research.google.com/github/matjesg/deepflash2/blob/master/deepflash2_GUI.ipynb) or follow the installation instructions below. The GUI provides a build-in use for sample data. After starting the GUI, select the task (GT Estimation, Training, or Prediction) and click `Load Sample Data`. For futher instructions watch the [tutorials](https://matjesg.github.io/deepflash2/tutorial.html).\n",
    "\n",
    "We provide an overview of the tasks below:\n",
    "\n",
    "|  | Ground Truth (GT) Estimation | Training | Prediction |\n",
    "|---|---|---|---|\n",
    "| Main Task | STAPLE or Majority Voting | Ensemble training  and validation | Semantic and instance segmentation |\n",
    "| Sample Data | 5 masks from 5 experts each | 5 image/mask pairs | 5 images and 2 trained models |\n",
    "| Expected Output | 5 GT Segmentation Masks | 5 models | 5 predicted segmentation masks  (semantic and instance) and uncertainty maps|\n",
    "| Estimated Time | ~ 1 min | ~ 150 min | ~ 4 min |\n",
    "\n",
    "Times are estimated for Google Colab (with free NVIDIA Tesla K80 GPU). You can download the sample data [here](https://github.com/matjesg/deepflash2/releases/tag/sample_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper and Experiments \n",
    "\n",
    "We provide a complete guide to reproduce our experiments using the *deepflash2 Python API* [here](https://github.com/matjesg/deepflash2/tree/master/paper). The data is currently available on [Google Drive](xxx).\n",
    "\n",
    "The preprint of our paper is available on [arXiv](https://arxiv.org/abs/2111.06693). Please cite\n",
    "\n",
    "```\n",
    "@misc{griebel2021deepflash2,\n",
    "    title={Deep-learning in the bioimaging wild: Handling ambiguous data with deepflash2}, \n",
    "    author={Matthias Griebel and Dennis Segebarth and Nikolai Stein and Nina Schukraft and Philip Tovote and Robert Blum and Christoph M. Flath},\n",
    "    year={2021},\n",
    "    eprint={2111.06693},\n",
    "    archivePrefix={arXiv}\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System requirements\n",
    "> Works in the browser an on your local pc/server\n",
    "\n",
    "*deepflash2* is designed to run on Windows, Linux, or Mac (x86-64) if [pytorch](https://pytorch.org/get-started/locally/) is installable.\n",
    "\n",
    "We generally recommend using Google Colab as it only requires a Google Account and a device with a web browser. \n",
    "To run *deepflash2* locally, we recommend using a system with a GPU (e.g., 2 CPUs, NVIDIA Tesla K80 GPU or better).\n",
    "\n",
    "Software dependencies are defined in the [settings.ini](https://github.com/matjesg/deepflash2/blob/master/settings.ini) file. Additionally, the ground truth estimation functionalities are based on the simpleITK>=2.0 and the instance segmentation capabilities are complemented using cellpose with commit hash `316927eff7ad2201391957909a2114c68baee309`.\n",
    "\n",
    "*deepflash2* is tested on Google Colab (Ubuntu 18.04.5 LTS) and locally (Ubuntu 20.04 LTS, Windows 10 (tbd), MacOS 12.0.1 (tbd))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Installation Guide\n",
    "\n",
    "> Typical install time is about 1-5 minutes, depending on your internet connection\n",
    "\n",
    "The GUI of *deepflash2* runs as a web application inside a Jupyter Notebook, the de-facto standard of computational notebooks in the scientific community. The GUI is built on top of the *deepflash2* Python API, which can be used independently (read the [docs](https://matjesg.github.io/deepflash2/)).\n",
    "\n",
    "#### Google Colab\n",
    "\n",
    "Excute the `Set up environment` cell or follow the `pip` instructions.\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matjesg/deepflash2/blob/master/deepflash2_GUI.ipynb) \n",
    "\n",
    "\n",
    "#### Other systems\n",
    "\n",
    "##### [conda](https://docs.conda.io/en/latest/)\n",
    "\n",
    "We recommend installation into a new, clean [environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge -c fastchan -c matjesg deepflash2 \n",
    "```\n",
    "\n",
    "##### [pip](https://pip.pypa.io/en/stable/)\n",
    "\n",
    "You should install PyTorch first by following the installation instructions of [pytorch](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "```bash\n",
    "pip install deepflash2\n",
    "```\n",
    "\n",
    "\n",
    "If you want to use the GUI, make sure to download the GUI notebook and start a Jupyter server. \n",
    "```bash\n",
    "curl -o deepflash2_GUI.ipynb https://raw.githubusercontent.com/matjesg/deepflash2/master/deepflash2_GUI.ipynb\n",
    "jupyter notebook\n",
    "```\n",
    "Then, open `deepflash2_GUI.ipynb` within Notebook environment.\n",
    "\n",
    "##### Docker\n",
    "\n",
    "Docker images for __deepflash2__ are built on top of [the latest pytorch image](https://hub.docker.com/r/pytorch/pytorch/). \n",
    "\n",
    "- CPU only\n",
    "\n",
    "> `docker run -p 8888:8888 matjes/deepflash2 ./run_jupyter.sh`\n",
    "\n",
    "- For training, we recommend to run docker with GPU support (You need to install [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) to enable gpu compatibility with these containers.)\n",
    "\n",
    "> `docker run --gpus all --shm-size=256m -p 8888:8888 matjes/deepflash2 ./run_jupyter.sh`\n",
    "\n",
    "\n",
    "All docker containers are configured to start a jupyter server. To add data, we recomment using [bind mounts](https://docs.docker.com/storage/bind-mounts/) with `/workspace` as target. To start the GUI, open `deepflash2_GUI.ipynb` within Notebook environment.\n",
    "\n",
    "For more information on how to run docker see [docker orientation and setup](https://docs.docker.com/get-started/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating segmentation masks with Fiji/ImageJ\n",
    "\n",
    "If you don't have labelled training data available, you can use this [instruction manual](https://github.com/matjesg/DeepFLaSH/raw/master/ImageJ/create_maps_howto.pdf) for creating segmentation maps.\n",
    "The ImagJ-Macro is available [here](https://raw.githubusercontent.com/matjesg/DeepFLaSH/master/ImageJ/Macro_create_maps.ijm)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
