{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp inference\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "> Classes for inference with model ensembles using Torchscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Tuple, List\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import deepflash2.tta as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Gaussian weighting for merging different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# adapted from https://github.com/scipy/scipy/blob/f2ec91c4908f9d67b5445fbfacce7f47518b35d1/scipy/signal/windows.py#L976\n",
    "@torch.jit.script\n",
    "def torch_gaussian(M:int, std:float, sym:bool=True) ->torch.Tensor:\n",
    "    'Returns a Gaussian window'\n",
    "    assert M > 2, 'Kernel size must be greater than 2.'\n",
    "    odd = M % 2\n",
    "    if not sym and not odd:\n",
    "        M = M + 1\n",
    "    n = torch.arange(0, M) - (M - 1.0) / 2.0\n",
    "    sig2 = 2 * std * std\n",
    "    w = torch.exp(-n ** 2 / sig2)\n",
    "    if not sym and not odd:\n",
    "        w = w[:-1]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@torch.jit.script\n",
    "def gaussian_kernel_2d(patch_size: Tuple[int, int], sigma_scale:float=1/8) ->torch.Tensor:\n",
    "    'Returns a 2D Gaussian kernel tensor.'\n",
    "    \n",
    "    patch_size = [patch_size[0], patch_size[1]]\n",
    "    sigmas = [i * sigma_scale for i in patch_size]\n",
    "    gkern1ds = [torch_gaussian(kernlen, std=std) for kernlen, std in zip(patch_size, sigmas)]\n",
    "    gkern2d = torch.outer(gkern1ds[0], gkern1ds[1])\n",
    "    gkern2d = gkern2d / gkern2d.max()\n",
    "    gkern2d[gkern2d==0] = gkern2d.min()\n",
    "    return gkern2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "gw = gaussian_kernel_2d((256,256), sigma_scale=1/8)\n",
    "test_eq(gw.max(), 1)\n",
    "plt.imshow(gw);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of epistemic and aleatoric uncertainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# adapted from https://github.com/ykwon0407/UQ_BNN/blob/master/retina/utils.py\n",
    "@torch.jit.script\n",
    "def epistemic_uncertainty(x: torch.Tensor):\n",
    "    return torch.mean(x**2, dim=0) - torch.mean(x, dim=0)**2\n",
    "\n",
    "@torch.jit.script\n",
    "def aleatoric_uncertainty(x: torch.Tensor):\n",
    "    return torch.mean(x * (1 - x), dim=0)\n",
    "\n",
    "@torch.jit.script\n",
    "def uncertainty(x: torch.Tensor):\n",
    "    # Add uncertainties\n",
    "    uncertainty = epistemic_uncertainty(x) + aleatoric_uncertainty(x)\n",
    "    # Scale to 1 max overall\n",
    "    uncertainty /= 0.25\n",
    "    return uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiling\n",
    "\n",
    "Functions and classes for tiling (slicing) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@torch.jit.export\n",
    "def get_in_slices_1d(center:torch.Tensor, len_x:int, len_tile:int) ->torch.Tensor: \n",
    "    start = (len_tile/2-center).clip(0).to(torch.int64)\n",
    "    stop = torch.tensor(len_tile).clip(max=(len_x-center+len_tile/2).to(torch.int64))\n",
    "    return torch.stack((start, stop))\n",
    "    \n",
    "@torch.jit.export\n",
    "def get_out_slices_1d(center:torch.Tensor, len_x:int, len_tile:int) ->torch.Tensor: \n",
    "    start = (center - (len_tile/2)).clip(0, len_x).to(torch.int64)\n",
    "    stop = (center + (len_tile/2)).clip(max=len_x).to(torch.int64)\n",
    "    return torch.stack((start, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TileModule(torch.nn.Module):\n",
    "    \"Class for tiling data.\"\n",
    "    def __init__(self, \n",
    "                 tile_shape = (512, 512), \n",
    "                 scale:float = 1.,\n",
    "                 border_padding_factor:float = 0.25,\n",
    "                 max_tile_shift:float = 0.5):\n",
    "        \n",
    "        super(TileModule, self).__init__()\n",
    "        self.tile_shape = tile_shape\n",
    "        self.scale = scale\n",
    "        self.border_padding_factor = border_padding_factor\n",
    "        self.max_tile_shift = max_tile_shift\n",
    "        \n",
    "        grid_range = [torch.linspace(-self.scale, self.scale, steps=d) for d in tile_shape] \n",
    "        self.deformationField = torch.meshgrid(*grid_range, indexing='ij')\n",
    "        \n",
    "        \n",
    "    @torch.jit.export\n",
    "    def get_centers_1d(self, len_x:int, len_tile:int) ->torch.Tensor:\n",
    "        len_padding = float(len_tile*self.border_padding_factor)\n",
    "        start_point = len_tile/2 - len_padding\n",
    "        end_point = len_x - start_point\n",
    "        #end_point = max(len_x - start_point, start_point)\n",
    "        n_points = int((len_x+2*len_padding)//(len_tile*self.max_tile_shift))+1\n",
    "        return torch.linspace(start_point, end_point, n_points, dtype=torch.int64)\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def get_center_combinations(self, shape:List[int]) ->torch.Tensor:\n",
    "        c_list = [self.get_centers_1d(shape[i], self.tile_shape[i]) for i in range(2)]\n",
    "        center_combinations = torch.meshgrid(c_list[0],c_list[1], indexing='ij')\n",
    "        return torch.stack(center_combinations).permute([2, 1, 0]).reshape(-1,2)\n",
    "    \n",
    "    \n",
    "    @torch.jit.export\n",
    "    def get_slices_and_centers(self, shape:List[int]) -> Tuple[List[torch.Tensor], List[torch.Tensor], torch.Tensor]:\n",
    "        shape = [int(shape[i]/self.scale) for i in range(2)]\n",
    "        center_combinations =  self.get_center_combinations(shape)\n",
    "        in_slices = [get_in_slices_1d(center_combinations[:,i], shape[i], self.tile_shape[i]) for i in range(2)]    \n",
    "        out_slices = [get_out_slices_1d(center_combinations[:,i], shape[i], self.tile_shape[i]) for i in range(2)] \n",
    "        scaled_centers = (center_combinations*self.scale).type(torch.int64)\n",
    "        \n",
    "        return in_slices, out_slices, scaled_centers            \n",
    "    \n",
    "    @torch.jit.export\n",
    "    def forward(self, x, center:torch.Tensor) ->torch.Tensor:\n",
    "        \"Apply deformation field to image using interpolation\"\n",
    "\n",
    "        # Align grid to relative position and scale\n",
    "        grids = []\n",
    "        for i in range(2):\n",
    "            s = x.shape[i]\n",
    "            scale_ratio = self.tile_shape[i]/s\n",
    "            relative_center = (center[i]-s/2)/(s/2)\n",
    "            coords = (self.deformationField[i]*scale_ratio)+relative_center\n",
    "            grids.append(coords.to(x))\n",
    "        \n",
    "        # grid with shape (N, H, W, 2)\n",
    "        vgrid = torch.stack(grids[::-1], dim=-1).to(x).unsqueeze_(0)\n",
    "        \n",
    "        # input with shape (N, C, H, W)\n",
    "        x = x.permute(2,0,1).unsqueeze_(0)\n",
    "        \n",
    "        # Remap\n",
    "        x = torch.nn.functional.grid_sample(x, vgrid, mode='bilinear', padding_mode='reflection', align_corners=True)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Generate an initial random image and mask with two circles\n",
    "np.random.seed(0)\n",
    "x, y = np.indices((540, 540))\n",
    "x1, y1, x2, y2 = 180, 180, 41*7, 52*7\n",
    "r1, r2 = 10*7.20, 20*7\n",
    "mask_circle1 = (x - x1) ** 2 + (y - y1) ** 2 < r1 ** 2\n",
    "mask_circle2 = (x - x2) ** 2 + (y - y2) ** 2 < r2 ** 2\n",
    "mask = np.logical_or(mask_circle1, mask_circle2).astype(int)\n",
    "mask[:10,:] = 1\n",
    "mask[-10:,:] = 1\n",
    "mask[:,:10] = 1\n",
    "mask[:,-10:] = 1\n",
    "image = np.random.rand(*mask.shape)+mask*2.\n",
    "image /= image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests: Output == Input\n",
    "ts = 540\n",
    "os = ts/2\n",
    "\n",
    "t = TileModule(tile_shape=(ts, ts))\n",
    "inp = torch.from_numpy(image).float().unsqueeze_(-1)\n",
    "out = t(inp, (os,os))[0,0]\n",
    "test_close(out,image, eps=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Visual) tests: Different arg combinations\n",
    "TS = [256, 512, 1024]\n",
    "SCALES = [0.5, 1., 2.]\n",
    "SHIFTS = [0.5, 0.9, 1.]\n",
    "BPFACTORS = [0.25, 0.1, 0.]\n",
    "inp = torch.from_numpy(image).float().unsqueeze_(-1)\n",
    "\n",
    "for ts in TS:\n",
    "    for scale in SCALES:\n",
    "        for max_tile_shift in SHIFTS:\n",
    "            for border_padding_factor in BPFACTORS:\n",
    "                t = TileModule(tile_shape=(ts, ts), scale=scale, max_tile_shift=max_tile_shift, border_padding_factor=border_padding_factor)\n",
    "                out = torch.zeros(*[int(x/t.scale) for x in inp.shape[:2]]).unsqueeze_(-1)\n",
    "                in_slices, out_slices, center_points = t.get_slices_and_centers(inp.shape)\n",
    "                assert len(center_points)!=0\n",
    "                for i, cp in enumerate(center_points):\n",
    "                    ix0, ix1, iy0, iy1 = in_slices[0][0][i], in_slices[0][1][i], in_slices[1][0][i], in_slices[1][1][i]\n",
    "                    ox0, ox1, oy0, oy1 = out_slices[0][0][i], out_slices[0][1][i], out_slices[1][0][i], out_slices[1][1][i]\n",
    "                    assert (ix1-ix0) == (ox1-ox0), 'Input/Output slices do not match'\n",
    "                    assert (iy1-iy0) == (oy1-oy0), 'Input/Output slices do not match'\n",
    "                    tile = t(inp, cp)\n",
    "                    out[ox0:ox1, oy0:oy1, 0] += tile[0 ,0, ix0:ix1, iy0:iy1]\n",
    "                    #plt.imshow(out)\n",
    "                    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test onnx export\n",
    "if torch.__version__.split(\".\") > [\"1\", \"11\", \"0\"]:\n",
    "    t_scripted = torch.jit.script(t)\n",
    "    ost = torch.tensor(os)\n",
    "    path = Path('TileModule.onnx')\n",
    "    _ = torch.onnx.export(t_scripted, (inp, torch.tensor([ost, ost])), path, verbose=True, opset_version=16)\n",
    "    path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Ensemble\n",
    "Scripable module for inference with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InferenceEnsemble(torch.nn.Module):\n",
    "    'Class for model ensemble inference'\n",
    "    def __init__(self, \n",
    "                 models,\n",
    "                 num_classes, \n",
    "                 model_stats,\n",
    "                 tile_shape=(512,512), \n",
    "                 use_gaussian: bool = True, \n",
    "                 gaussian_kernel_sigma_scale:float = 1./8,\n",
    "                 use_tta:bool=True,\n",
    "                 border_padding_factor:float = 0.25,\n",
    "                 max_tile_shift:float = 0.9,\n",
    "                 scale:float = 1.): \n",
    "        \n",
    "        super().__init__()     \n",
    "        self.num_classes = num_classes\n",
    "        self.use_tta = use_tta\n",
    "        self.use_gaussian = use_gaussian\n",
    "        self.gaussian_kernel_sigma_scale = gaussian_kernel_sigma_scale\n",
    "        self.tile_shape = tile_shape\n",
    "        \n",
    "        self.register_buffer('channel_means', torch.tensor(model_stats['channel_means'], dtype=torch.float32))\n",
    "        self.register_buffer('channel_stds', torch.tensor(model_stats['channel_stds'], dtype=torch.float32))\n",
    "        \n",
    "        dummy_input = torch.rand(1, 1, *self.tile_shape)\n",
    "        self.models = torch.nn.ModuleList([torch.jit.trace(m.eval(), dummy_input) for m in models])\n",
    "        \n",
    "        self.tiler = torch.jit.script(TileModule(tile_shape=tile_shape, \n",
    "                                                 scale=scale, \n",
    "                                                 border_padding_factor=border_padding_factor, \n",
    "                                                 max_tile_shift=max_tile_shift))\n",
    "        \n",
    "        mw = gaussian_kernel_2d(tile_shape, gaussian_kernel_sigma_scale) if use_gaussian else torch.ones(tile_shape[0], tile_shape[1])\n",
    "        self.register_buffer('mw', mw)\n",
    "        \n",
    "        tfms = [tta.HorizontalFlip(),tta.VerticalFlip()] if self.use_tta else []\n",
    "        self.tta_tfms = tta.Compose(tfms)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Extract image shape (assuming HWC)\n",
    "        sh = x.shape[:-1]\n",
    "        # Workaround for sh_scaled = [int(s/self.tiler.scale) for s in img_shape]\n",
    "        sh_scaled = (torch.tensor(sh)/self.tiler.scale).to(torch.int64)\n",
    "        sh_scaled = [int(t.item()) for t in sh_scaled]\n",
    "        \n",
    "        # Create zero arrays (only on CPU RAM to avoid GPU memory overflow on large images)\n",
    "        # softmax = torch.zeros((sh_scaled[0], sh_scaled[1], self.num_classes), dtype=torch.float32, device=x.device)\n",
    "        softmax = torch.zeros((self.num_classes, sh_scaled[0], sh_scaled[1]), dtype=torch.float32, device=x.device)\n",
    "        merge_map = torch.zeros((sh_scaled[0], sh_scaled[1]), dtype=torch.float32, device=x.device)\n",
    "        stdeviation = torch.zeros((sh_scaled[0], sh_scaled[1]), dtype=torch.float32, device=x.device)\n",
    "        \n",
    "        # Get slices for tiling\n",
    "        in_slices, out_slices, center_points = self.tiler.get_slices_and_centers(sh)\n",
    "        \n",
    "        # Loop over tiles\n",
    "        for i, cp in enumerate(center_points):\n",
    "            \n",
    "            tile = self.tiler(x, cp).to(self.channel_means)\n",
    "            \n",
    "            # Normalize\n",
    "            tile = (tile - self.channel_means)/self.channel_stds\n",
    "        \n",
    "            smxs = []   \n",
    "            # Loop over tt-augmentations\n",
    "            for t in self.tta_tfms.items: \n",
    "                aug_tile = t.augment(tile)\n",
    "\n",
    "                # Loop over models\n",
    "                for model in self.models:\n",
    "                    logits = model(aug_tile)\n",
    "                    logits = t.deaugment(logits)\n",
    "                    smxs.append(F.softmax(logits, dim=1))\n",
    "\n",
    "            smxs = torch.stack(smxs)\n",
    "                        \n",
    "            ix0, ix1, iy0, iy1 = in_slices[0][0][i], in_slices[0][1][i], in_slices[1][0][i], in_slices[1][1][i]\n",
    "            ox0, ox1, oy0, oy1 = out_slices[0][0][i], out_slices[0][1][i], out_slices[1][0][i], out_slices[1][1][i]\n",
    "            \n",
    "            # Apply weigthing\n",
    "            batch_smx = torch.mean(smxs, dim=0)*self.mw.view(1,1,self.mw.shape[0],self.mw.shape[1])\n",
    "            #softmax[ox0:ox1, oy0:oy1] += batch_smx.permute(0,2,3,1)[0][ix0:ix1, iy0:iy1].to(softmax)  \n",
    "            softmax[..., ox0:ox1, oy0:oy1] += batch_smx[0, ..., ix0:ix1, iy0:iy1].to(softmax)  \n",
    "            merge_map[ox0:ox1, oy0:oy1] += self.mw[ix0:ix1, iy0:iy1].to(merge_map)\n",
    "            \n",
    "            # Encertainty_estimates\n",
    "            batch_std = torch.mean(uncertainty(smxs), dim=1)*self.mw.view(1,self.mw.shape[0],self.mw.shape[1])\n",
    "            stdeviation[ox0:ox1, oy0:oy1] += batch_std[0][ix0:ix1, iy0:iy1].to(stdeviation)\n",
    "            \n",
    "\n",
    "        # Normalize weighting\n",
    "        softmax /= torch.unsqueeze(merge_map, 0)\n",
    "        stdeviation /= merge_map\n",
    "        \n",
    "        # Rescale results\n",
    "        if self.tiler.scale!=1.:\n",
    "            softmax = F.interpolate(softmax.unsqueeze_(0), scale_factor=self.tiler.scale, mode=\"bilinear\", align_corners=True)[0]\n",
    "            stdeviation = stdeviation.view(1, 1, stdeviation.shape[0], stdeviation.shape[1])\n",
    "            stdeviation = F.interpolate(stdeviation, scale_factor=self.tiler.scale, mode=\"bilinear\", align_corners=True)[0][0]\n",
    "        \n",
    "        argmax = torch.argmax(softmax, dim=0).to(torch.uint8)\n",
    "\n",
    "        return argmax, softmax, stdeviation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy class for testing\n",
    "class DummyModule(torch.nn.Module):\n",
    "    'Dummy Module for testing'\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x[:,:1].repeat(1, self.num_classes, 1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with different params\n",
    "NUM_CLASSES = [2, 5]\n",
    "SCALES = [0.5, 1., 4.]\n",
    "IMG_SHAPES = [512]#[256, 512, 1024]\n",
    "model_stats = {'channel_means': 0, 'channel_stds': 1}\n",
    "\n",
    "for num_classes in NUM_CLASSES:\n",
    "    models = [DummyModule(num_classes=num_classes) for _ in range(2)]\n",
    "    for sx in IMG_SHAPES:\n",
    "        for sy in IMG_SHAPES:\n",
    "            inp = torch.rand(sx,sy, num_classes)\n",
    "            for scale in SCALES:\n",
    "                ensemble = InferenceEnsemble(models, num_classes=num_classes, model_stats=model_stats, scale=scale)\n",
    "                ensemble = torch.jit.script(ensemble)\n",
    "                outs = ensemble(inp)\n",
    "                test_eq(outs[0].shape, (sx, sy))\n",
    "                test_eq(outs[1].shape, (num_classes, sx, sy))\n",
    "                test_eq(outs[2].shape, (sx, sy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test torchscript export\n",
    "path_pt = Path('ensemble.pt')\n",
    "scripted_ensemble = torch.jit.script(ensemble)\n",
    "scripted_ensemble.save(path_pt)\n",
    "_ = torch.jit.load(path_pt)\n",
    "path_pt.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test onnx export\n",
    "if torch.__version__.split(\".\") >= [\"1\", \"12\", \"0\"]:\n",
    "    print(torch.__version__)\n",
    "    input_names=[\"inp\"]\n",
    "    output_names=[\"argmax\", \"softmax\", \"stdeviation\"]\n",
    "    dynamic_axes = {\"inp\": [0, 1], \"argmax\": [0, 1], \"softmax\": [0, 1, 2], \"stdeviation\": [0, 1]}\n",
    "    path_onnx = Path('ensemble.onnx')\n",
    "    torch.onnx.export(scripted_ensemble, inp, f=path_onnx, verbose=True, opset_version=16, \n",
    "                      input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes)\n",
    "    \n",
    "    #import onnxruntime\n",
    "    #ort_session = onnxruntime.InferenceSession(path_onnx.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
