{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#default_exp learner\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Training and Prediction\n",
    "\n",
    "> Implements the meta classes for training and inference with deep model ensembles for deepflash2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import time\n",
    "import zarr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "from typing import List, Union, Tuple\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.basics import GetAttr\n",
    "from fastcore.foundation import L\n",
    "from fastai import optimizer\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastai.callback.progress import CSVLogger\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.transforms import get_image_files, get_files\n",
    "\n",
    "from deepflash2.config import Config\n",
    "from deepflash2.data import BaseDataset, TileDataset, RandomTileDataset\n",
    "from deepflash2.models import create_smp_model, save_smp_model, load_smp_model, run_cellpose\n",
    "from deepflash2.inference import InferenceEnsemble\n",
    "from deepflash2.losses import get_loss\n",
    "from deepflash2.utils import compose_albumentations as _compose_albumentations\n",
    "from deepflash2.utils import dice_score, binary_dice_score, plot_results, get_label_fn, save_mask, save_unc, export_roi_set, get_instance_segmentation_metrics\n",
    "from fastai.metrics import Dice, DiceMulti\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "#https://discuss.pytorch.org/t/slow-forward-on-traced-graph-on-cuda-2nd-iteration/118445/7\n",
    "try: torch._C._jit_set_fusion_strategy([('STATIC', 0)])\n",
    "except: torch._C._jit_set_bailout_depth(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_optim_dict = {\n",
    "    'ranger' : optimizer.ranger,\n",
    "    'Adam' : optimizer.Adam,\n",
    "    'RAdam' : optimizer.RAdam,\n",
    "    'QHAdam' :optimizer.QHAdam,\n",
    "    'Larc' : optimizer.Larc,\n",
    "    'Lamb' : optimizer.Lamb,\n",
    "    'SGD' : optimizer.SGD,\n",
    "    'RMSProp' : optimizer.RMSProp,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleBase(GetAttr):\n",
    "    _default = 'config' \n",
    "    def __init__(self, image_dir:str=None, mask_dir:str=None, files:List[Path]=None, label_fn:callable=None, \n",
    "                 config:Config=None, path:Path=None, zarr_store:str=None):\n",
    "\n",
    "        self.config = config or Config()\n",
    "        self.path = Path(path) if path is not None else Path('.')\n",
    "        self.label_fn = None\n",
    "        self.files = L()\n",
    "        \n",
    "        store = str(zarr_store) if zarr_store else zarr.storage.TempStore()\n",
    "        root = zarr.group(store=store, overwrite=False)\n",
    "        self.store = root.chunk_store.path\n",
    "        self.g_pred, self.g_smx, self.g_std  = root.require_groups('preds', 'smxs', 'stds')\n",
    "        \n",
    "        if any(v is not None for v in (image_dir, files)):\n",
    "            self.files = L(files) or self.get_images(image_dir)\n",
    "            \n",
    "            if any(v is not None for v in (mask_dir, label_fn)):\n",
    "                assert hasattr(self, 'files'), 'image_dir or files must be provided'\n",
    "                self.label_fn = label_fn or self.get_label_fn(mask_dir)\n",
    "                self.check_label_fn()     \n",
    "        \n",
    "    def get_images(self, img_dir:str='images', img_path:Path=None) -> List[Path]:\n",
    "        'Returns list of image paths'\n",
    "        path = img_path or self.path/img_dir\n",
    "        files = get_image_files(path, recurse=False)\n",
    "        print(f'Found {len(files)} images in \"{path}\".')\n",
    "        if len(files)==0: warnings.warn('Please check your provided images and image folder')\n",
    "        return files\n",
    "\n",
    "    def get_label_fn(self, msk_dir:str='masks', msk_path:Path=None):\n",
    "        'Returns label function to get paths of masks'\n",
    "        path = msk_path or self.path/msk_dir\n",
    "        return get_label_fn(self.files[0], path)\n",
    "\n",
    "    def check_label_fn(self):\n",
    "        'Checks label function'\n",
    "        mask_check = [self.label_fn(x).exists() for x in self.files]\n",
    "        chk_str = f'Found {sum(mask_check)} corresponding masks.'\n",
    "        print(chk_str)\n",
    "        if len(self.files)!=sum(mask_check):\n",
    "            warnings.warn(f'Please check your images and masks (and folders).')\n",
    "            \n",
    "    def predict(self, arr:Union[np.ndarray, torch.Tensor]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        'Get prediction for arr using inference_ensemble'\n",
    "        inp = torch.tensor(arr).float().to(self.device)\n",
    "        with torch.inference_mode():\n",
    "            preds = self.inference_ensemble(inp)\n",
    "        preds = [x.cpu().numpy() for x in preds]\n",
    "        return tuple(preds)\n",
    "    \n",
    "    def save_preds_zarr(self, f_name, pred, smx, std):\n",
    "        self.g_pred[f_name] = pred\n",
    "        self.g_smx[f_name] = smx\n",
    "        self.g_std[f_name] = std\n",
    "        \n",
    "    def _create_ds(self, **kwargs):\n",
    "        self.ds = BaseDataset(self.files, label_fn=self.label_fn, instance_labels=self.instance_labels,\n",
    "                              num_classes=self.num_classes, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests tbd.\n",
    "tst = EnsembleBase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleLearner(EnsembleBase):\n",
    "    \"Meta class to training model ensembles with `n` models\"\n",
    "    def __init__(self, *args, ensemble_path=None, preproc_dir=None, metrics=None, cbs=None, \n",
    "                 ds_kwargs={}, dl_kwargs={}, model_kwargs={}, stats=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        assert hasattr(self, 'label_fn'), 'mask_dir or label_fn must be provided.'\n",
    "        self.stats = stats\n",
    "        self.dl_kwargs = dl_kwargs\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.add_ds_kwargs = ds_kwargs\n",
    "        default_metrics = [Dice()] if self.num_classes==2 else [DiceMulti()]\n",
    "        self.metrics = metrics or default_metrics\n",
    "        self.loss_fn = self.get_loss()\n",
    "        self.cbs = cbs or [SaveModelCallback(monitor='dice' if self.num_classes==2 else 'dice_multi')] #ShowGraphCallback\n",
    "        self.ensemble_dir = ensemble_path or self.path/self.ens_dir\n",
    "        if ensemble_path is not None: \n",
    "            ensemble_path.mkdir(exist_ok=True, parents=True)\n",
    "            self.load_models(path=ensemble_path)\n",
    "        else: self.models = {}\n",
    "                  \n",
    "        self.n_splits=min(len(self.files), self.max_splits)\n",
    "        self._set_splits()\n",
    "        self._create_ds(stats=self.stats, preproc_dir=preproc_dir, verbose=1, **self.add_ds_kwargs)\n",
    "        self.stats = self.ds.stats\n",
    "        self.in_channels = self.ds.get_data(max_n=1)[0].shape[-1]\n",
    "        self.df_val, self.df_ens, self.df_model, self.ood = None,None,None,None\n",
    "        self.recorder = {}\n",
    "               \n",
    "    def _set_splits(self):\n",
    "        if self.n_splits>1:\n",
    "            kf = KFold(self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "            self.splits = {key:(self.files[idx[0]], self.files[idx[1]]) for key, idx in zip(range(1,self.n_splits+1), kf.split(self.files))}    \n",
    "        else:\n",
    "            self.splits = {1: (self.files[0], self.files[0])}\n",
    "            \n",
    "    def _compose_albumentations(self, **kwargs):\n",
    "        return _compose_albumentations(**kwargs)\n",
    "        \n",
    "    @property        \n",
    "    def pred_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        ds_kwargs['use_preprocessed_labels']= True\n",
    "        ds_kwargs['preproc_dir']=self.ds.preproc_dir\n",
    "        ds_kwargs['instance_labels']= self.instance_labels\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['num_classes']= self.num_classes\n",
    "        ds_kwargs['max_tile_shift']= self.max_tile_shift\n",
    "        ds_kwargs['scale']= self.scale\n",
    "        ds_kwargs['border_padding_factor']= self.border_padding_factor\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property        \n",
    "    def train_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        # Settings from config\n",
    "        ds_kwargs['use_preprocessed_labels']= True\n",
    "        ds_kwargs['preproc_dir']=self.ds.preproc_dir\n",
    "        ds_kwargs['instance_labels']= self.instance_labels\n",
    "        ds_kwargs['stats']= self.stats\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['num_classes']= self.num_classes\n",
    "        ds_kwargs['scale']= self.scale\n",
    "        ds_kwargs['flip'] = self.flip\n",
    "        ds_kwargs['max_tile_shift']= 1.\n",
    "        ds_kwargs['border_padding_factor']= 0.\n",
    "        ds_kwargs['scale']= self.scale\n",
    "        ds_kwargs['albumentations_tfms'] = self._compose_albumentations(**self.albumentation_kwargs)\n",
    "        ds_kwargs['sample_mult'] = self.sample_mult if self.sample_mult>0 else None\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        encoder_name = self.encoder_name.replace('_', '-')\n",
    "        return f'{self.arch}_{encoder_name}_{self.num_classes}classes'  \n",
    "                    \n",
    "    def get_loss(self):\n",
    "        kwargs = {'mode':self.mode,\n",
    "                  'classes':[x for x in range(1, self.num_classes)],\n",
    "                  'smooth_factor': self.loss_smooth_factor,\n",
    "                  'alpha':self.loss_alpha, \n",
    "                  'beta':self.loss_beta, \n",
    "                  'gamma':self.loss_gamma}\n",
    "        return get_loss(self.loss, **kwargs)\n",
    "    \n",
    "    \n",
    "    def _get_dls(self, files, files_val=None):\n",
    "        ds = []\n",
    "        ds.append(RandomTileDataset(files, label_fn=self.label_fn, **self.train_ds_kwargs, verbose=0))\n",
    "        if files_val: \n",
    "            ds.append(TileDataset(files_val, label_fn=self.label_fn, **self.train_ds_kwargs, verbose=0))\n",
    "        else:\n",
    "            ds.append(ds[0])\n",
    "        dls = DataLoaders.from_dsets(*ds, bs=self.batch_size, pin_memory=True, **self.dl_kwargs).to(self.device)\n",
    "        return dls\n",
    "    \n",
    "    def _create_model(self):\n",
    "        model = create_smp_model(arch=self.arch, \n",
    "                                 encoder_name=self.encoder_name, \n",
    "                                 encoder_weights=self.encoder_weights, \n",
    "                                 in_channels=self.in_channels, \n",
    "                                 classes=self.num_classes, \n",
    "                                 **self.model_kwargs).to(self.device)\n",
    "        return model\n",
    "\n",
    "               \n",
    "    def fit(self, i, n_epochs=None, base_lr=None, **kwargs):\n",
    "        'Fit model number `i`'\n",
    "        n_epochs = n_epochs or self.n_epochs\n",
    "        base_lr = base_lr or self.base_lr\n",
    "        name = self.ensemble_dir/'single_models'/f'{self.model_name}-fold{i}.pth'\n",
    "        model = self._create_model()\n",
    "        files_train, files_val = self.splits[i]\n",
    "        dls = self._get_dls(files_train, files_val)  \n",
    "        log_name = f'{name.name}_{time.strftime(\"%Y%m%d-%H%M%S\")}.csv'\n",
    "        log_dir = self.ensemble_dir/'logs'\n",
    "        log_dir.mkdir(exist_ok=True, parents=True)\n",
    "        cbs = self.cbs.append(CSVLogger(fname=log_dir/log_name))\n",
    "        self.learn = Learner(dls, model, \n",
    "                             metrics=self.metrics, \n",
    "                             wd=self.weight_decay, \n",
    "                             loss_func=self.loss_fn, \n",
    "                             opt_func=_optim_dict[self.optim], \n",
    "                             cbs=self.cbs)\n",
    "        self.learn.model_dir = self.ensemble_dir.parent/'.tmp'\n",
    "        if self.mixed_precision_training: self.learn.to_fp16()\n",
    "        print(f'Starting training for {name.name}')\n",
    "        self.learn.fine_tune(n_epochs, base_lr=base_lr)\n",
    "\n",
    "        print(f'Saving model at {name}')\n",
    "        name.parent.mkdir(exist_ok=True, parents=True)\n",
    "        save_smp_model(self.learn.model, self.arch, name, stats=self.stats)\n",
    "        self.models[i]=name\n",
    "        self.recorder[i]=self.learn.recorder\n",
    "        \n",
    "        del model\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        \n",
    "    def get_inference_ensemble(self, model_path=None):\n",
    "        model_paths = [model_path] if model_path is not None else self.models.values()\n",
    "        models = [load_smp_model(p)[0] for p in model_paths]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            ensemble = InferenceEnsemble(models, \n",
    "                                         num_classes=self.num_classes, \n",
    "                                         in_channels=self.in_channels,\n",
    "                                         channel_means=self.stats['channel_means'].tolist(),\n",
    "                                         channel_stds=self.stats['channel_stds'].tolist(),\n",
    "                                         tile_shape=(self.tile_shape,)*2, \n",
    "                                         **self.inference_kwargs).to(self.device)\n",
    "        return torch.jit.script(ensemble)\n",
    "        \n",
    "    def save_inference_ensemble(self):\n",
    "        ensemble = self.get_inference_ensemble()\n",
    "        ensemble_name = self.ensemble_dir/f'ensemble_{self.model_name}.pt'\n",
    "        print(f'Saving model at {ensemble_name}')\n",
    "        ensemble.save(ensemble_name)\n",
    "        \n",
    "    def fit_ensemble(self, n_epochs=None, skip=False, save_inference_ensemble=True, **kwargs):\n",
    "        'Fit `i` models and `skip` existing'\n",
    "        for i in range(1, self.n_models+1):\n",
    "            if skip and (i in self.models): continue\n",
    "            self.fit(i, n_epochs,  **kwargs)\n",
    "        if save_inference_ensemble: self.save_inference_ensemble()\n",
    "       \n",
    "    def set_n(self, n):\n",
    "        \"Change to `n` models per ensemble\"\n",
    "        for i in range(n, len(self.models)):\n",
    "            self.models.pop(i+1, None)            \n",
    "        self.n_models = n\n",
    "                                                       \n",
    "    def get_valid_results(self, model_no=None, zarr_store=None, export_dir=None, filetype='.png', **kwargs):\n",
    "        \"Validate models on validation data and save results\"\n",
    "        res_list = []\n",
    "        model_dict = self.models if not model_no else {k:v for k,v in self.models.items() if k==model_no}\n",
    "        metric_name = 'dice_score' if self.num_classes==2 else 'average_dice_score'\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for i, model_path in model_dict.items():\n",
    "            print(f'Validating model {i}.')\n",
    "            self.inference_ensemble = self.get_inference_ensemble(model_path=model_path)\n",
    "            _, files_val = self.splits[i]\n",
    "            \n",
    "            for j, f in progress_bar(enumerate(files_val), total=len(files_val)):\n",
    "\n",
    "                pred, smx, std = self.predict(self.ds.data[f.name][:])\n",
    "                self.save_preds_zarr(f.name, pred, smx, std)\n",
    "                msk = self.ds.labels[f.name][:] #.get_data(f, mask=True)[0])\n",
    "                m_dice = dice_score(msk, pred, num_classes=self.num_classes)\n",
    "                df_tmp = pd.Series({'file' : f.name,\n",
    "                        'model' :  model_path,\n",
    "                        'model_no' : i,\n",
    "                        metric_name: m_dice,\n",
    "                        'uncertainty_score': np.mean(std[pred>0]),\n",
    "                        'image_path': f,\n",
    "                        'mask_path': self.label_fn(f),\n",
    "                        'pred_path': f'{self.store}/{self.g_pred.path}/{f.name}',\n",
    "                        'softmax_path': f'{self.store}/{self.g_smx.path}/{f.name}',\n",
    "                        'uncertainty_path': f'{self.store}/{self.g_std.path}/{f.name}'})\n",
    "                res_list.append(df_tmp)\n",
    "                if export_dir:   \n",
    "                    save_mask(pred, pred_path/f'{df_tmp.file}_model{df_tmp.model_no}_mask', filetype)\n",
    "                    save_unc(std, unc_path/f'{df_tmp.file}_model{df_tmp.model_no}_uncertainty', filetype)\n",
    "                        \n",
    "        del self.inference_ensemble\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        \n",
    "        self.df_val = pd.DataFrame(res_list)\n",
    "        if export_dir: \n",
    "            self.df_val.to_csv(export_dir/f'val_results.csv', index=False)\n",
    "            self.df_val.to_excel(export_dir/f'val_results.xlsx')\n",
    "        return self.df_val\n",
    "        \n",
    "    def show_valid_results(self, model_no=None, files=None, metric_name='auto', **kwargs):\n",
    "        \"Plot results of all or `file` validation images\",\n",
    "        if self.df_val is None: self.get_valid_results(**kwargs)\n",
    "        df = self.df_val\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        if model_no is not None: df = df[df.model_no==model_no] \n",
    "        if metric_name=='auto': metric_name = 'dice_score' if self.num_classes==2 else 'average_dice_score'\n",
    "        for _, r in df.iterrows():\n",
    "            img = self.ds.data[r.file][:]\n",
    "            msk = self.ds.labels[r.file][:]\n",
    "            pred = self.g_pred[r.file][:]\n",
    "            std = self.g_std[r.file][:]\n",
    "            _d_model = f'Model {r.model_no}'\n",
    "            plot_results(img, msk, pred, std, df=r, num_classes=self.num_classes, metric_name=metric_name, model=_d_model)  \n",
    "          \n",
    "    def load_models(self, path=None):\n",
    "        \"Get models saved at `path`\"\n",
    "        path = path or self.ensemble_dir/'single_models'\n",
    "        models = sorted(get_files(path, extensions='.pth', recurse=False))\n",
    "        self.models = {}\n",
    "        \n",
    "        for i, m in enumerate(models,1):\n",
    "            if i==0: self.num_classes = int(m.name.split('_')[2][0])\n",
    "            else: assert self.num_classes==int(m.name.split('_')[2][0]), 'Check models. Models are trained on different number of classes.'\n",
    "            self.models[i] = m\n",
    "        \n",
    "        if len(self.models)>0: \n",
    "            self.set_n(len(self.models))\n",
    "            print(f'Found {len(self.models)} models in folder {path}:')\n",
    "            print([m.name for m in self.models.values()])\n",
    "            \n",
    "            # Reset stats\n",
    "            print(f'Loading stats from {self.models[1].name}') \n",
    "            _, self.stats = load_smp_model(self.models[1])\n",
    "                                          \n",
    "    def lr_find(self, files=None, **kwargs):\n",
    "        \"Wrapper function for learning rate finder\"\n",
    "        files = files or self.files\n",
    "        dls = self._get_dls(files)\n",
    "        model = self._create_model()\n",
    "        learn = Learner(dls, model, metrics=self.metrics, wd=self.weight_decay, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim])\n",
    "        if self.mixed_precision_training: learn.to_fp16()\n",
    "        sug_lrs = learn.lr_find(**kwargs)\n",
    "        return sug_lrs, learn.recorder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"EnsembleLearner\" class=\"doc_header\"><code>class</code> <code>EnsembleLearner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>EnsembleLearner</code>(**\\*`args`**, **`ensemble_path`**=*`None`*, **`preproc_dir`**=*`None`*, **`metrics`**=*`None`*, **`cbs`**=*`None`*, **`ds_kwargs`**=*`{}`*, **`dl_kwargs`**=*`{}`*, **`model_kwargs`**=*`{}`*, **`stats`**=*`None`*, **\\*\\*`kwargs`**) :: [`EnsembleBase`](/deepflash2/learner.html#EnsembleBase)\n",
       "\n",
       "Meta class to training model ensembles with `n` models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EnsembleLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsemblePredictor(EnsembleBase):\n",
    "    def __init__(self, *args, ensemble_path:Path=None, **kwargs):\n",
    "        if ensemble_path is not None: \n",
    "            self.load_inference_ensemble(ensemble_path)\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        if hasattr(self, 'inference_ensemble'): \n",
    "            self.config.num_classes = self.inference_ensemble.num_classes\n",
    "        \n",
    "        if hasattr(self, 'files'): \n",
    "            self._create_ds(stats={}, use_zarr_data = False, verbose=1)\n",
    "            \n",
    "        self.ensemble_dir = self.path/self.ens_dir\n",
    "        \n",
    "        #if ensemble_path is not None:\n",
    "        #    self.load_inference_ensemble(ensemble_path)\n",
    "\n",
    "    def load_inference_ensemble(self, ensemble_path:Path=None):\n",
    "        \"Load inference_ensemble from `self.ensemle_dir` or from `path`\"\n",
    "        path = ensemble_path or self.ensemble_dir\n",
    "        if path.is_dir():\n",
    "            path_list = get_files(path, extensions='.pt', recurse=False)\n",
    "            if len(path_list)==0: \n",
    "                warnings.warn(f'No inference ensemble available at {path}. Did you train your ensemble correctly?')\n",
    "                return\n",
    "            path = path_list[0]\n",
    "        self.inference_ensemble_name = path.name\n",
    "        if hasattr(self, 'device'): self.inference_ensemble = torch.jit.load(path).to(self.device)\n",
    "        else: self.inference_ensemble = torch.jit.load(path)\n",
    "        print(f'Successfully loaded InferenceEnsemble from {path}')\n",
    "        \n",
    "        \n",
    "    def get_ensemble_results(self, file_list=None, export_dir=None, filetype='.png', **kwargs):  \n",
    "        'Predict files in file_list using InferenceEnsemble'\n",
    "        \n",
    "        if file_list is not None:\n",
    "            self.files = file_list\n",
    "            self._create_ds(stats={}, use_zarr_data = False, verbose=1)\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        res_list = []\n",
    "        for f in progress_bar(self.files):\n",
    "            img = self.ds.read_img(f)\n",
    "            pred, smx, std = self.predict(img)\n",
    "            self.save_preds_zarr(f.name, pred, smx, std)\n",
    "            df_tmp = pd.Series({'file' : f.name,\n",
    "                                'ensemble' : self.inference_ensemble_name, \n",
    "                                'uncertainty_score': np.mean(std[pred>0]),\n",
    "                                'image_path': f,\n",
    "                                'pred_path': f'{self.store}/{self.g_pred.path}/{f.name}',\n",
    "                                'softmax_path': f'{self.store}/{self.g_smx.path}/{f.name}',\n",
    "                                'uncertainty_path': f'{self.store}/{self.g_std.path}/{f.name}'})\n",
    "            res_list.append(df_tmp)\n",
    "            if export_dir:   \n",
    "                save_mask(pred, pred_path/f'{df_tmp.file}_mask', filetype)\n",
    "                save_unc(std, unc_path/f'{df_tmp.file}_unc', filetype)\n",
    "                    \n",
    "        self.df_ens  = pd.DataFrame(res_list)\n",
    "        return self.g_pred, self.g_smx, self.g_std\n",
    "    \n",
    "    def score_ensemble_results(self, mask_dir=None, label_fn=None):\n",
    "        \"Compare ensemble results to given segmentation masks.\"\n",
    "        \n",
    "        if any(v is not None for v in (mask_dir, label_fn)):\n",
    "            self.label_fn = label_fn or self.get_label_fn(mask_dir)\n",
    "            self._create_ds(stats={}, use_zarr_data = False, verbose=1)\n",
    "        \n",
    "        print('Calculating metrics')\n",
    "        for i, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            msk = self.ds.labels[r.file][:]\n",
    "            pred = self.g_pred[r.file][:]\n",
    "            \n",
    "            if self.num_classes==2: \n",
    "                self.df_ens.loc[i, f'dice_score'] = binary_dice_score(msk, pred)\n",
    "            else: \n",
    "                for cl in range(self.num_classes):\n",
    "                    msk_bin = msk==cl\n",
    "                    pred_bin = pred==cl\n",
    "                    if np.any([msk_bin, pred_bin]):\n",
    "                        self.df_ens.loc[i, f'dice_score_class{cl}'] = binary_dice_score(msk_bin, pred_bin)\n",
    "                \n",
    "        if self.num_classes>2: \n",
    "            self.df_ens['average_dice_score'] = self.df_ens[[col for col in self.df_ens if col.startswith('dice_score_class')]].mean(axis=1)\n",
    "        \n",
    "        return self.df_ens\n",
    "    \n",
    "    def show_ensemble_results(self, files=None, unc=True, unc_metric=None, metric_name='auto'):\n",
    "        \"Show result of ensemble or `model_no`\"\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        df = self.df_ens\n",
    "        if files is not None: df = df.reset_index().set_index('file', drop=False).loc[files]\n",
    "        if metric_name=='auto': metric_name = 'dice_score' if self.num_classes==2 else 'average_dice_score'\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = []\n",
    "            imgs.append(self.ds.read_img(r.image_path))\n",
    "            if metric_name in r.index:\n",
    "                imgs.append(self.ds.labels[r.file][:])\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            imgs.append(self.g_pred[r.file])\n",
    "            if unc: imgs.append(self.g_std[r.file])\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, num_classes=self.num_classes, metric_name=metric_name, unc_metric=unc_metric) \n",
    "\n",
    "            \n",
    "    def get_cellpose_results(self, export_dir=None):\n",
    "        'Get instance segmentation results using the cellpose integration'\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        cl = self.cellpose_export_class\n",
    "        assert cl<self.num_classes, f'{cl} not avaialable from {self.num_classes} classes'\n",
    "        \n",
    "        smxs, preds = [], []\n",
    "        for _, r in self.df_ens.iterrows():\n",
    "            smxs.append(self.g_smx[r.file][:])\n",
    "            preds.append(self.g_pred[r.file][:])\n",
    "            \n",
    "        probs = [x[cl] for x in smxs]\n",
    "        masks = [x==cl for x in preds]\n",
    "        cp_masks = run_cellpose(probs, masks,\n",
    "                                model_type=self.cellpose_model, \n",
    "                                diameter=self.cellpose_diameter, \n",
    "                                min_size=self.min_pixel_export, \n",
    "                                gpu=torch.cuda.is_available())\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)/'instance_labels'\n",
    "            export_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for idx, r in self.df_ens.iterrows():\n",
    "                tifffile.imwrite(export_dir/f'{r.file}_class{cl}.tif', cp_masks[idx], compress=6)    \n",
    "                \n",
    "        self.cellpose_masks = cp_masks\n",
    "        return cp_masks\n",
    "    \n",
    "    def score_cellpose_results(self, mask_dir=None, label_fn=None):\n",
    "        \"Compare cellpose nstance segmentation results to given masks.\"\n",
    "        assert self.cellpose_masks is not None, 'Run get_cellpose_results() first'\n",
    "        if any(v is not None for v in (mask_dir, label_fn)):\n",
    "            self.label_fn = label_fn or self.get_label_fn(mask_dir)\n",
    "            self._create_ds(stats={}, use_zarr_data = False, verbose=1)\n",
    "            \n",
    "        cl = self.cellpose_export_class\n",
    "        for i, r in self.df_ens.iterrows():\n",
    "            msk = self.ds.labels[r.file][:]==cl\n",
    "            _, msk = cv2.connectedComponents(msk.astype('uint8'), connectivity=4)\n",
    "            pred = self.cellpose_masks[i]\n",
    "            ap, tp, fp, fn = get_instance_segmentation_metrics(msk, pred, is_binary=False, min_pixel=self.min_pixel_export)\n",
    "            self.df_ens.loc[i, f'mAP_class{cl}'] = ap.mean()\n",
    "            self.df_ens.loc[i, f'mAP_iou50_class{cl}'] = ap[0]\n",
    "        return self.df_ens\n",
    "    \n",
    "      \n",
    "    def show_cellpose_results(self, files=None, unc_metric=None, metric_name='auto'):\n",
    "        'Show instance segmentation results from cellpose predictions.'\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        df = self.df_ens.reset_index()\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        if metric_name=='auto': metric_name=f'mAP_class{self.cellpose_export_class}'\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = [self.ds.read_img(r.image_path)]\n",
    "            if metric_name in r.index: \n",
    "                mask = self.ds.labels[r.file][:]\n",
    "                mask = (mask==self.cellpose_export_class).astype('uint8')\n",
    "                _, comps = cv2.connectedComponents(mask, connectivity=4)\n",
    "                imgs.append(label2rgb(comps, bg_label=0))\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            \n",
    "            imgs.append(label2rgb(self.cellpose_masks[r['index']], bg_label=0))\n",
    "            imgs.append(self.g_std[r.file])\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, num_classes=self.num_classes, instance_labels=True, metric_name=metric_name, unc_metric=unc_metric) \n",
    "    \n",
    "    def export_imagej_rois(self, output_folder='ROI_sets', **kwargs):\n",
    "        'Export ImageJ ROI Sets to `ouput_folder`'\n",
    "        assert self.df_ens is not None, \"Please run prediction first.\"\n",
    "        \n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "        for idx, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            pred = self.g_pred[r.file][:]\n",
    "            uncertainty = self.g_std[r.file][:]\n",
    "            export_roi_set(pred, uncertainty, name=r.file, path=output_folder, ascending=False, **kwargs)\n",
    "        \n",
    "    def export_cellpose_rois(self, output_folder='cellpose_ROI_sets', **kwargs):\n",
    "        'Export cellpose predictions to ImageJ ROI Sets in `ouput_folder`'\n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "        for idx, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            pred = self.cellpose_masks[idx]\n",
    "            uncertainty = self.g_std[r.file][:]\n",
    "            export_roi_set(pred, uncertainty, instance_labels=True, name=r.file, path=output_folder, ascending=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"EnsemblePredictor\" class=\"doc_header\"><code>class</code> <code>EnsemblePredictor</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>EnsemblePredictor</code>(**\\*`args`**, **`ensemble_path`**:`Path`=*`None`*, **\\*\\*`kwargs`**) :: [`EnsembleBase`](/deepflash2/learner.html#EnsembleBase)\n",
       "\n",
       "Inherit from this to have all attr accesses in `self._xtra` passed down to `self.default`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EnsemblePredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests tbd.\n",
    "t = EnsemblePredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_learner.ipynb.\n",
      "Converted 04_inference.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted tutorial.ipynb.\n",
      "Converted tutorial_gt.ipynb.\n",
      "Converted tutorial_pred.ipynb.\n",
      "Converted tutorial_train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
