{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#default_exp learner\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learner\n",
    "\n",
    "> Implements functions necessary to build an  `EnsembleLearner` suitable for bioimgage segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TileDataset' from 'deepflash2.data' (/media/data/deepflash2/deepflash2/data.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-413b51f25889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepflash2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepflash2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_smp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_smp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_smp_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepflash2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTileDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomTileDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_read_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_read_msk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepflash2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_unc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_roi_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepflash2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompose_albumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_compose_albumentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TileDataset' from 'deepflash2.data' (/media/data/deepflash2/deepflash2/data.py)"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import shutil, gc, joblib, json, zarr, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "from dataclasses import dataclass, field, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.basics import patch, GetAttr\n",
    "from fastcore.foundation import add_docs, L\n",
    "from fastai import optimizer\n",
    "from fastai.torch_core import TensorImage\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.transforms import get_image_files, get_files\n",
    "from fastai.vision.augment import Brightness, Contrast, Saturation\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "\n",
    "from deepflash2.metrics import Dice, Iou\n",
    "from deepflash2.losses import get_loss\n",
    "from deepflash2.models import create_smp_model, save_smp_model, load_smp_model\n",
    "from deepflash2.data import TileDataset, RandomTileDataset, _read_img, _read_msk\n",
    "from deepflash2.utils import iou, plot_results, get_label_fn, calc_iterations, save_mask, save_unc, export_roi_set\n",
    "from deepflash2.utils import compose_albumentations as _compose_albumentations\n",
    "import deepflash2.tta as tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"Config class for settings.\"\n",
    "\n",
    "    # Project\n",
    "    proj_dir:str = 'deepflash2'\n",
    "\n",
    "    # GT Estimation Settings\n",
    "    staple_thres:float = 0.5\n",
    "    staple_fval:int= 1\n",
    "    mv_undec:int = 0\n",
    "\n",
    "    # Train General Settings\n",
    "    n:int = 5\n",
    "    max_splits:int=5\n",
    "    random_state:int = 42\n",
    "        \n",
    "    # Pytorch Segmentation Model Settings\n",
    "    arch:str = 'Unet'\n",
    "    encoder_name:str = 'resnet34'\n",
    "    encoder_weights:str = 'imagenet'\n",
    "\n",
    "    # Train Data Settings\n",
    "    c:int = 2\n",
    "    tile_shape:int = 512\n",
    "    il:bool = False\n",
    "\n",
    "    # Train Settings\n",
    "    base_lr:float = 0.001\n",
    "    bs:int = 4\n",
    "    wd:float = 0.001\n",
    "    mpt:bool = False\n",
    "    optim:str = 'Adam'\n",
    "    loss:str = 'CrossEntropyDiceLoss'\n",
    "    n_iter:int = 2000\n",
    "    sample_mult:int = 0\n",
    "\n",
    "    # Validation and Prediction Settings\n",
    "    tta:bool = True\n",
    "    border_padding_factor:float = 0.25\n",
    "    shift:float = 0.5\n",
    "\n",
    "    # Train Data Augmentation\n",
    "    gamma_limit_lower:int = 80\n",
    "    gamma_limit_upper:int = 120\n",
    "    CLAHE_clip_limit:float = 0.0\n",
    "    brightness_limit:float = 0.0\n",
    "    contrast_limit:float = 0.0\n",
    "    flip:bool = True\n",
    "    rot:int = 360\n",
    "    distort_limit:float = 0\n",
    "        \n",
    "    # Loss Settings\n",
    "    mode:str = 'multiclass' #currently only tested for multiclass\n",
    "    loss_alpha:float = 0.5 # Twerksky/Focal loss\n",
    "    loss_beta:float = 0.5 # Twerksy Loss\n",
    "    loss_gamma:float = 2.0 # Focal loss\n",
    "    loss_smooth_factor:float = 0. #SoftCrossEntropyLoss\n",
    "    \n",
    "    # Pred Settings\n",
    "    pred_tta:bool = True\n",
    "    min_pixel_export:int = 0\n",
    "\n",
    "    # Folder Structure\n",
    "    gt_dir:str = 'GT_Estimation'\n",
    "    train_dir:str = 'Training'\n",
    "    pred_dir:str = 'Prediction'\n",
    "    ens_dir:str = 'ensemble'\n",
    "    val_dir:str = 'valid'\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def albumentation_kwargs(self):\n",
    "        kwargs = ['gamma_limit_lower', 'gamma_limit_upper', 'CLAHE_clip_limit', \n",
    "                  'brightness_limit', 'contrast_limit', 'distort_limit']\n",
    "        return dict(filter(lambda x: x[0] in kwargs, self.__dict__.items()))\n",
    "\n",
    "    @property\n",
    "    def svm_kwargs(self):\n",
    "        svm_vars = ['kernel', 'nu', 'gamma']\n",
    "        return dict(filter(lambda x: x[0] in svm_vars, self.__dict__.items()))\n",
    "\n",
    "    def save(self, path):\n",
    "        'Save configuration to path'\n",
    "        path = Path(path)\n",
    "        with open(path.with_suffix('.json'), 'w') as config_file:\n",
    "            json.dump(asdict(self), config_file)\n",
    "        print(f'Saved current configuration to {path}.json')\n",
    "\n",
    "    def load(self, path):\n",
    "        'Load configuration from path'\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            with open(path) as config_file: c = json.load(config_file)\n",
    "            if not Path(c['proj_dir']).is_dir(): c['proj_dir']='deepflash2'\n",
    "            for k,v in c.items(): setattr(self, k, v)\n",
    "            print(f'Successsfully loaded configuration from {path}')\n",
    "        except:\n",
    "            print('Error! Select valid config file (.json)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Config(n=3)\n",
    "t1.save('test_config')\n",
    "t2 = Config()\n",
    "t2.load('test_config.json')\n",
    "test_eq(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_optim_dict = {\n",
    "    'ranger' : optimizer.ranger,\n",
    "    'Adam' : optimizer.Adam,\n",
    "    'RAdam' : optimizer.RAdam,\n",
    "    'QHAdam' :optimizer.QHAdam,\n",
    "    'Larc' : optimizer.Larc,\n",
    "    'Lamb' : optimizer.Lamb,\n",
    "    'SGD' : optimizer.SGD,\n",
    "    'RMSProp' : optimizer.RMSProp,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from https://github.com/MIC-DKFZ/nnUNet/blob/2fade8f32607220f8598544f0d5b5e5fa73768e5/nnunet/network_architecture/neural_network.py#L250\n",
    "def _get_gaussian(patch_size, sigma_scale=1. / 8) -> np.ndarray:\n",
    "    tmp = np.zeros(patch_size)\n",
    "    center_coords = [i // 2 for i in patch_size]\n",
    "    sigmas = [i * sigma_scale for i in patch_size]\n",
    "    tmp[tuple(center_coords)] = 1\n",
    "    gaussian_importance_map = gaussian_filter(tmp, sigmas, 0, mode='constant', cval=0)\n",
    "    gaussian_importance_map = gaussian_importance_map / np.max(gaussian_importance_map) * 1\n",
    "    gaussian_importance_map = gaussian_importance_map.astype(np.float32)\n",
    "\n",
    "    # gaussian_importance_map cannot be 0, otherwise we may end up with nans!\n",
    "    gaussian_importance_map[gaussian_importance_map == 0] = np.min(\n",
    "        gaussian_importance_map[gaussian_importance_map != 0])\n",
    "\n",
    "    return gaussian_importance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(_get_gaussian((512,512)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def energy_score(x, T=1, dim=1):\n",
    "    'Return the energy score as proposed by  Liu, Weitang, et al. (2020).'\n",
    "    return -(T*torch.logsumexp(x/T, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsemblePredict():\n",
    "    'Class for prediction with multiple models'\n",
    "    def __init__(self, models_paths, zarr_store=None):\n",
    "        self.models_paths = models_paths\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.init_models()\n",
    "        \n",
    "        # Init zarr storage\n",
    "        self.store = str(zarr_store) if zarr_store else zarr.storage.TempStore()\n",
    "        self.root = zarr.group(store=self.store)\n",
    "        self.g_smx = self.root.require_group('smx')\n",
    "        self.g_std = self.root.require_group('std')\n",
    "        self.g_eng = self.root.require_group('energy')\n",
    "        \n",
    "    def init_models(self):\n",
    "        self.models = []\n",
    "        self.stats = None\n",
    "        for p in self.models_paths:        \n",
    "            model, stats = load_smp_model(p)\n",
    "            if not self.stats: self.stats = stats\n",
    "            assert np.array_equal(stats, self.stats), 'Only models trained on the same stats are allowed.'\n",
    "            model.float()\n",
    "            model.eval()\n",
    "            model.to(self.device)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, \n",
    "                ds, \n",
    "                use_tta=True, \n",
    "                bs=4, \n",
    "                use_gaussian=True, \n",
    "                sigma_scale=1./8, \n",
    "                uncertainty_estimates=True, \n",
    "                energy_T = 1., \n",
    "                verbose=0):\n",
    "        \n",
    "        if verbose>0: print('Ensemble prediction with models:', self.models_paths)\n",
    "            \n",
    "        tfms = [tta.HorizontalFlip(),tta.VerticalFlip()] if use_tta else []\n",
    "        if verbose>0: print('Using Test-Time Augmentation with:', tfms)\n",
    "                      \n",
    "        dl = DataLoader(ds, bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "\n",
    "        # Create zero arrays\n",
    "        data_shape = ds.image_shapes[0]\n",
    "        softmax = np.zeros((*data_shape, ds.c), dtype='float32')\n",
    "        merge_map = np.zeros(data_shape, dtype='float32')\n",
    "        stdeviation = np.zeros(data_shape, dtype='float32') if uncertainty_estimates else None\n",
    "        energy = np.zeros(data_shape, dtype='float32') if uncertainty_estimates else None\n",
    "\n",
    "        # Define merge weights\n",
    "        if use_gaussian:\n",
    "            mw_numpy = _get_gaussian(ds.output_shape, sigma_scale)\n",
    "        else: \n",
    "            mw_numpy = np.ones(dl.output_shape)\n",
    "        mw = torch.from_numpy(mw_numpy).to(self.device)\n",
    "        \n",
    "        # Loop over tiles (indices required!)\n",
    "        for tiles, idxs in iter(dl):\n",
    "            tiles = tiles.to(self.device)\n",
    "            smx_merger = tta.Merger()\n",
    "            if uncertainty_estimates: \n",
    "                energy_merger = tta.Merger()\n",
    "            \n",
    "            # Loop over tt-augmentations\n",
    "            for t in tta.Compose(tfms): \n",
    "                aug_tiles = t.augment_image(tiles)\n",
    "                model_merger = tta.Merger()\n",
    "                if uncertainty_estimates: engergy_list = []\n",
    "                \n",
    "                # Loop over models\n",
    "                for model in self.models:\n",
    "                    with torch.no_grad(): \n",
    "                        logits = model(aug_tiles)\n",
    "                    logits = t.deaugment_mask(logits)\n",
    "                    smx_merger.append(F.softmax(logits, dim=1)) \n",
    "                    if uncertainty_estimates: \n",
    "                        energy_merger.append(-energy_score(logits, energy_T)) #negative energy score\n",
    "\n",
    "            out_list = []\n",
    "            # Apply gaussian weigthing\n",
    "            batch_smx = smx_merger.result()*mw.view(1,1,*mw.shape)\n",
    "            # Reshape and append to list\n",
    "            out_list.append([x for x in batch_smx.permute(0,2,3,1).cpu().numpy()])\n",
    "            \n",
    "            if uncertainty_estimates:\n",
    "                batch_std = torch.mean(smx_merger.result('std'), dim=1)*mw.view(1,*mw.shape)\n",
    "                out_list.append([x for x in batch_std.cpu().numpy()])\n",
    "\n",
    "                batch_energy =  energy_merger.result()*mw.view(1,*mw.shape)\n",
    "                out_list.append([x for x in batch_energy.cpu().numpy()])\n",
    "\n",
    "            # Compose predictions\n",
    "            for preds in zip(*out_list, idxs):\n",
    "                if uncertainty_estimates: smx,std,eng,idx = preds \n",
    "                else: smx, idx = preds\n",
    "                out_slice = ds.out_slices[idx]\n",
    "                in_slice = ds.in_slices[idx]\n",
    "                softmax[out_slice] += smx[in_slice]\n",
    "                merge_map[out_slice] += mw_numpy[in_slice]\n",
    "                \n",
    "                if uncertainty_estimates:\n",
    "                    stdeviation[out_slice] += std[in_slice]\n",
    "                    energy[out_slice] += eng[in_slice]\n",
    "                    \n",
    "        # Normalize weighting           \n",
    "        softmax /= merge_map[..., np.newaxis]\n",
    "        if uncertainty_estimates:\n",
    "            energy /= merge_map\n",
    "            stdeviation /= merge_map   \n",
    "            \n",
    "        return softmax, stdeviation, energy\n",
    "    \n",
    "    def predict_images(self, image_list, ds_kwargs={}, verbose=1, **kwargs):\n",
    "        \"Predict images in 'image_list' with kwargs and save to zarr\"\n",
    "        for f in progress_bar(image_list, leave=False):\n",
    "            if verbose>0: print(f'Predicting {f.name}')\n",
    "            ds = TileDataset([f], stats=self.stats, return_index=True, **ds_kwargs)\n",
    "            softmax, stdeviation, energy = self.predict(ds, **kwargs)\n",
    "            \n",
    "            # Save to zarr\n",
    "            self.g_smx[f.name] = softmax\n",
    "            if stdeviation is not None: self.g_std[f.name] = stdeviation\n",
    "            if energy is not None: self.g_eng[f.name] = energy\n",
    "        \n",
    "        return self.g_smx, self.g_std, self.g_eng       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleLearner(GetAttr):\n",
    "    _default = 'config' \n",
    "    def __init__(self, image_dir='images', mask_dir=None, config=None, path=None, ensemble_dir=None, item_tfms=None,\n",
    "                 label_fn=None, metrics=None, cbs=None, ds_kwargs={}, dl_kwargs={}, model_kwargs={}, stats=None, files=None):\n",
    "\n",
    "        self.config = config or Config()\n",
    "        self.stats = stats \n",
    "        self.dl_kwargs = dl_kwargs\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.add_ds_kwargs = ds_kwargs\n",
    "        self.item_tfms = item_tfms\n",
    "        self.path = Path(path) if path is not None else Path('.')\n",
    "        self.metrics = metrics or [Iou(), Dice()]\n",
    "        self.loss_fn = self.get_loss()\n",
    "        self.cbs = cbs or [SaveModelCallback(monitor='iou')] #ShowGraphCallback\n",
    "        self.ensemble_dir = ensemble_dir or self.path/'ensemble'    \n",
    "        \n",
    "        self.files = L(files) or get_image_files(self.path/image_dir, recurse=False)\n",
    "        assert len(self.files)>0, f'Found {len(self.files)} images in \"{image_dir}\". Please check your images and image folder'\n",
    "        if any([mask_dir, label_fn]):\n",
    "            if label_fn: self.label_fn = label_fn\n",
    "            else: self.label_fn = get_label_fn(self.files[0], self.path/mask_dir)\n",
    "            #Check if corresponding masks exist\n",
    "            mask_check = [self.label_fn(x).exists() for x in self.files]\n",
    "            chk_str = f'Found {len(self.files)} images in \"{image_dir}\" and {sum(mask_check)} masks in \"{mask_dir}\".'\n",
    "            assert len(self.files)==sum(mask_check) and len(self.files)>0, f'Please check your images and masks (and folders). {chk_str}'\n",
    "            print(chk_str)\n",
    "                  \n",
    "        else:\n",
    "            self.label_fn = label_fn\n",
    "        self.n_splits=min(len(self.files), self.max_splits)\n",
    "          \n",
    "        self.models = {}\n",
    "        self.recorder = {}\n",
    "        self._set_splits()\n",
    "        self.ds = RandomTileDataset(self.files, label_fn=self.label_fn, stats=self.stats, verbose=0)\n",
    "        self.stats = stats or self.ds.stats\n",
    "        self.in_channels = self.ds.get_data(max_n=1)[0].shape[-1]\n",
    "        self.df_val, self.df_ens, self.df_model, self.ood = None,None,None,None\n",
    "               \n",
    "    def _set_splits(self):\n",
    "        if self.n_splits>1:\n",
    "            kf = KFold(self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "            self.splits = {key:(self.files[idx[0]], self.files[idx[1]]) for key, idx in zip(range(1,self.n_splits+1), kf.split(self.files))}    \n",
    "        else:\n",
    "            self.splits = {1: (self.files[0], self.files[0])}\n",
    "            \n",
    "    def _compose_albumentations(self, **kwargs):\n",
    "        return _compose_albumentations(**kwargs)\n",
    "        \n",
    "    @property        \n",
    "    def pred_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['n_classes']= self.c\n",
    "        ds_kwargs['shift']= self.shift\n",
    "        ds_kwargs['border_padding_factor']= self.border_padding_factor\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property        \n",
    "    def train_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        # Settings from config\n",
    "        ds_kwargs['stats']= self.stats\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['n_classes']= self.c\n",
    "        ds_kwargs['shift']= 1.\n",
    "        ds_kwargs['border_padding_factor']= 0.\n",
    "        ds_kwargs['flip'] = self.flip\n",
    "        ds_kwargs['albumentation_tfms'] = self._compose_albumentations(**self.albumentation_kwargs)\n",
    "        ds_kwargs['sample_mult'] = self.sample_mult if self.sample_mult>0 else None\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        return f'{self.arch}_{self.encoder_name}_{self.c}classes'  \n",
    "                    \n",
    "    def get_loss(self):\n",
    "        kwargs = {'mode':self.mode,\n",
    "                  'classes':[x for x in range(1, self.c)],\n",
    "                  'smooth_factor': self.loss_smooth_factor,\n",
    "                  'alpha':self.loss_alpha, \n",
    "                  'beta':self.loss_beta, \n",
    "                  'gamma':self.loss_gamma}\n",
    "        return get_loss(self.loss, **kwargs)\n",
    "    \n",
    "    \n",
    "    def _get_dls(self, files, files_val=None):\n",
    "        ds = []\n",
    "        ds.append(RandomTileDataset(files, label_fn=self.label_fn, **self.train_ds_kwargs))\n",
    "        if files_val: \n",
    "            ds.append(TileDataset(files_val, label_fn=self.label_fn, **self.train_ds_kwargs))\n",
    "        else:\n",
    "            ds.append(ds[0])\n",
    "        dls = DataLoaders.from_dsets(*ds, bs=self.bs, pin_memory=True, **self.dl_kwargs)\n",
    "        if torch.cuda.is_available(): dls.cuda()\n",
    "        return dls\n",
    "    \n",
    "    def _create_model(self):\n",
    "        model = create_smp_model(arch=self.arch, \n",
    "                                 encoder_name=self.encoder_name, \n",
    "                                 encoder_weights=self.encoder_weights, \n",
    "                                 in_channels=self.in_channels, \n",
    "                                 classes=self.c, \n",
    "                                 **self.model_kwargs)\n",
    "        if torch.cuda.is_available(): model.cuda()\n",
    "        return model\n",
    "               \n",
    "    def fit(self, i, n_iter=None, base_lr=None, **kwargs):\n",
    "        n_iter = n_iter or self.n_iter\n",
    "        base_lr = base_lr or self.base_lr\n",
    "        name = self.ensemble_dir/f'{self.model_name}-fold{i}.pth'\n",
    "        model = self._create_model()\n",
    "        files_train, files_val = self.splits[i]\n",
    "        dls = self._get_dls(files_train, files_val)    \n",
    "        self.learn = Learner(dls, model, metrics=self.metrics, wd=self.wd, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim], cbs=self.cbs)\n",
    "        self.learn.model_dir = self.ensemble_dir.parent/'.tmp'\n",
    "        if self.mpt: self.learn.to_fp16()\n",
    "        print(f'Starting training for {name.name}')\n",
    "        epochs = calc_iterations(n_iter=n_iter,ds_length=len(dls.train_ds), bs=self.bs)\n",
    "        #self.learn.fit_one_cycle(epochs, lr_max)\n",
    "        self.learn.fine_tune(epochs, base_lr=base_lr)\n",
    "\n",
    "        print(f'Saving model at {name}')\n",
    "        name.parent.mkdir(exist_ok=True, parents=True)\n",
    "        save_smp_model(self.learn.model, self.arch, name, stats=self.stats)\n",
    "        self.models[i]=name\n",
    "        self.recorder[i]=self.learn.recorder\n",
    "        \n",
    "    def fit_ensemble(self, n_iter, skip=False, **kwargs):\n",
    "        for i in range(1, self.n+1):\n",
    "            if skip and (i in self.models): continue\n",
    "            self.fit(i, n_iter,  **kwargs)\n",
    "       \n",
    "    def set_n(self, n):\n",
    "        for i in range(n, len(self.models)):\n",
    "            self.models.pop(i+1, None)            \n",
    "        self.n = n\n",
    "                                                       \n",
    "    def get_valid_results(self, model_no=None, export_dir=None, filetype='.png', **kwargs):\n",
    "        res_list = []\n",
    "        model_list = self.models if not model_no else [model_no]\n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for i, model_path in model_list.items():\n",
    "            ep = EnsemblePredict(models_paths=[model_path])\n",
    "            _, files_val = self.splits[i]\n",
    "            g_smx, g_std, g_eng = ep.predict_images(files_val, bs=self.bs, ds_kwargs=self.pred_ds_kwargs, **kwargs)\n",
    "            \n",
    "            chunk_store = g_smx.chunk_store.path\n",
    "            for j, f in enumerate(files_val):\n",
    "                msk = self.ds.get_data(f, mask=True)[0]\n",
    "                pred = np.argmax(g_smx[f.name][:], axis=-1).astype('uint8')\n",
    "                m_iou = iou(msk, pred)\n",
    "                m_path = self.models[i].name\n",
    "                df_tmp = pd.Series({'file' : f.name,\n",
    "                        'model' :  m_path,\n",
    "                        'model_no' : i,\n",
    "                        'iou': m_iou,\n",
    "                        'dice': 2*m_iou/(m_iou+1),\n",
    "                        'mean_energy': np.mean(g_eng[f.name][:][pred>0]),\n",
    "                        'mean_uncertainty': np.mean(g_std[f.name][:][pred>0]),\n",
    "                        'image_path': f,\n",
    "                        'mask_path': self.label_fn(f),\n",
    "                        'softmax_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                        'engergy_path': f'{chunk_store}/{g_eng.path}/{f.name}' if g_eng is not None else None,\n",
    "                        'uncertainty_path': f'{chunk_store}/{g_std.path}/{f.name}'} if g_std is not None else None)\n",
    "                res_list.append(df_tmp)\n",
    "                if export_dir:   \n",
    "                    save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.model}_mask', filetype)\n",
    "                    if g_std is not None:\n",
    "                        save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_uncertainty', filetype)\n",
    "                    if g_eng is not None:\n",
    "                        save_unc(g_eng[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_energy', filetype)\n",
    "        self.df_val = pd.DataFrame(res_list)\n",
    "        if export_dir: \n",
    "            self.df_val.to_csv(export_dir/f'val_results.csv', index=False)\n",
    "            self.df_val.to_excel(export_dir/f'val_results.xlsx')\n",
    "        return self.df_val\n",
    "        \n",
    "    def show_valid_results(self, model_no=None, files=None, **kwargs):\n",
    "        if self.df_val is None: self.get_valid_results(**kwargs)\n",
    "        df = self.df_val\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        if model_no is not None: df = df[df.model_no==model_no] \n",
    "        for _, r in df.iterrows():\n",
    "            img = self.ds.get_data(r.image_path)[0][:]\n",
    "            msk = self.ds.get_data(r.image_path, mask=True)[0]\n",
    "            pred = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            std = zarr.load(r.uncertainty_path)\n",
    "            _d_model = f'Model {r.model_no}'\n",
    "            if self.tta: plot_results(img, msk, pred, std, df=r, model=_d_model)  \n",
    "            else: plot_results(img, msk, pred, np.zeros_like(pred), df=r, model=_d_model)  \n",
    "          \n",
    "    def load_ensemble(self, path=None):\n",
    "        path = path or self.ensemble_dir\n",
    "        models = sorted(get_files(path, extensions='.pth', recurse=False))\n",
    "        assert len(models)>0, f'No models found in {path}'\n",
    "        self.models = {}\n",
    "        for i, m in enumerate(models,1):\n",
    "            self.models[i] = m\n",
    "        print(f'Found {len(self.models)} models in folder {path}')\n",
    "        print(self.models)\n",
    "                           \n",
    "    def get_ensemble_results(self, files, zarr_store=None, export_dir=None, filetype='.png', **kwargs):   \n",
    "        ep = EnsemblePredict(models_paths=self.models.values(), zarr_store=zarr_store)\n",
    "        g_smx, g_std, g_eng = ep.predict_images(files, bs=self.bs, ds_kwargs=self.pred_ds_kwargs, **kwargs)\n",
    "        chunk_store = g_smx.chunk_store.path\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        res_list = []\n",
    "        for f in files:\n",
    "            pred = np.argmax(g_smx[f.name][:], axis=-1).astype('uint8')\n",
    "            df_tmp = pd.Series({'file' : f.name,\n",
    "                                'ensemble' :  self.model_name,\n",
    "                                'n_models' : len(self.models),\n",
    "                                'mean_energy': np.mean(g_eng[f.name][:][pred>0]),\n",
    "                                'mean_uncertainty': np.mean(g_std[f.name][:][pred>0]),\n",
    "                                'image_path': f,\n",
    "                                'softmax_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                                'uncertainty_path': f'{chunk_store}/{g_std.path}/{f.name}' if g_std is not None else None,\n",
    "                                'energy_path': f'{chunk_store}/{g_eng.path}/{f.name}'} if g_eng is not None else None)\n",
    "            res_list.append(df_tmp)\n",
    "            if export_dir:   \n",
    "                save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.ensemble}_mask', filetype)\n",
    "                if g_std is not None:\n",
    "                    save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.ensemble}_unc', filetype)\n",
    "                if g_eng is not None:\n",
    "                        save_unc(g_eng[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.ensemble}_energy', filetype)\n",
    "                    \n",
    "        self.df_ens  = pd.DataFrame(res_list)\n",
    "        return g_smx, g_std, g_eng\n",
    "    \n",
    "    def score_ensemble_results(self, mask_dir=None, label_fn=None):\n",
    "        if not label_fn:\n",
    "            label_fn = get_label_fn(self.df_ens.image_path[0], self.path/mask_dir)\n",
    "        for idx, r in self.df_ens.iterrows():\n",
    "            msk_path = self.label_fn(r.image_path)\n",
    "            msk = _read_msk(msk_path)\n",
    "            self.df_ens.loc[idx, 'mask_path'] = msk_path\n",
    "            pred = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            self.df_ens.loc[idx, 'iou'] = iou(msk, pred)\n",
    "        return self.df_ens\n",
    "       \n",
    "    def show_ensemble_results(self, files=None, model_no=None, unc=True, unc_metric=None):\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        if model_no is None: df = self.df_ens\n",
    "        else: df = self.df_models[df_models.model_no==model_no]\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = []\n",
    "            imgs.append(_read_img(r.image_path)[:])\n",
    "            if 'iou' in r.index: \n",
    "                imgs.append(_read_msk(r.mask_path))\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            imgs.append(np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8'))\n",
    "            if unc: imgs.append(zarr.load(r.uncertainty_path))\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, unc_metric=unc_metric) \n",
    "                \n",
    "    def lr_find(self, files=None, **kwargs):\n",
    "        files = files or self.files\n",
    "        dls = self.get_dls(files)\n",
    "        model = self.get_model()\n",
    "        learn = Learner(dls, model, metrics=self.metrics, wd=self.wd, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim])\n",
    "        if self.mpt: learn.to_fp16()\n",
    "        sug_lrs = learn.lr_find(**kwargs)\n",
    "        return sug_lrs, learn.recorder  \n",
    "    \n",
    "    def export_imagej_rois(self, output_folder='ImageJ_ROIs', **kwargs):\n",
    "        assert self.df_ens is not None, \"Please run prediction first.\"\n",
    "        \n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "        for idx, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            mask = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            energy = zarr.load(r.energy_path)\n",
    "            export_roi_set(mask, energy, name=r.file, path=output_folder, **kwargs)\n",
    "           \n",
    "    def clear_tmp(self):\n",
    "        try: \n",
    "            shutil.rmtree('/tmp/*', ignore_errors=True)\n",
    "            shutil.rmtree(self.path/'.tmp')\n",
    "            print(f'Deleted temporary files from {self.path/\".tmp\"}')\n",
    "        except: print(f'No temporary files to delete at {self.path/\".tmp\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "add_docs(EnsembleLearner, \"Meta class to train and predict model ensembles with `n` models\",\n",
    "         #save_model= \"Save `model` to `file` along with `arch`, `stats`, and `c` classes\",\n",
    "         #load_model=\"Load `model` from `file` along with `arch`, `stats`, and `c` classes\",\n",
    "         fit=\"Fit model number `i`\",\n",
    "         fit_ensemble=\"Fit `i` models and `skip` existing\",\n",
    "         #predict=\"Predict `files` with model at `model_path`\",\n",
    "         get_valid_results=\"Validate models on validation data and save results\",\n",
    "         show_valid_results=\"Plot results of all or `file` validation images\",\n",
    "         #ensemble_results=\"Merge single model results\",\n",
    "         get_ensemble_results=\"Get models and ensemble results\", \n",
    "         score_ensemble_results=\"Compare ensemble results (Intersection over the Union) to given segmentation masks.\",\n",
    "         show_ensemble_results=\"Show result of ensemble or `model_no`\",\n",
    "         load_ensemble=\"Get models saved at `path`\",\n",
    "         #compose_albumentations=\"Helper function to compose albumentations augmentations\",\n",
    "         #get_dls=\"Create datasets and dataloaders from files\",\n",
    "         #get_model=\"Get model architecture\",\n",
    "         get_loss=\"Get loss function from loss name (config)\",\n",
    "         set_n=\"Change to `n` models per ensemble\",\n",
    "         lr_find=\"Wrapper for learning rate finder\",\n",
    "         #show_mask_weights='Plot fn for masks and weights',\n",
    "         #ood_train=\"Train SVM for OOD Detection\",\n",
    "         #ood_score=\"Get OOD score\",\n",
    "         #ood_save='Save OOD model to path',\n",
    "         #ood_load='Load OOD model from path',\n",
    "         export_imagej_rois='Export ImageJ ROI Sets to `ouput_folder`',\n",
    "         clear_tmp=\"Clear directory with temporary files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(EnsembleLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
