{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from fastai.vision.all import *\n",
    "from fastcore.foundation import patch\n",
    "from deepflash2.data import TileDataset\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#export \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from fastai2.learner import Learner\n",
    "from fastprogress.fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patches for the `fastai` Learner\n",
    "\n",
    "> Imlements functions necessary to build `Learner` suitable for bioimgage segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport? \n",
    "@patch\n",
    "def predict_from_tiles(self:Learner, ds_idx=1, dl=None):\n",
    "        \"Predict and reconstruct images from tile dataset.\"\n",
    "        \n",
    "        if dl is None: dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "        softmax_score, _ = self.get_preds(dl=dl)\n",
    "        softmax_score = softmax_score.permute(0,2,3,1)\n",
    "        tile_list = [x for x in softmax_score.cpu().numpy()]\n",
    "\n",
    "        smxcores = dl.reconstruct_from_tiles(tile_list)\n",
    "        segmentations = [np.argmax(x, axis=-1) for x in smxcores]\n",
    "\n",
    "        return smxcores, segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "@patch\n",
    "def predict_tiles(self:Learner, ds_idx=1, dl=None, mc_dropout=False, n_times=1):\n",
    "    \"Make predictions with dropout applied.\"\n",
    "\n",
    "    if dl is None: dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "\n",
    "    self.model.eval()\n",
    "    if mc_dropout: self.apply_dropout()\n",
    "\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    for data in progress_bar(dl):\n",
    "        if isinstance(data, TensorImage):\n",
    "            images = data\n",
    "        else:\n",
    "            images, _, _ = data\n",
    "        out_list = []\n",
    "        for t in range(n_times):\n",
    "            with torch.no_grad():\n",
    "                out = self.model(images)\n",
    "            out = F.softmax(out, dim=1)\n",
    "            out_list.append(out)\n",
    "        out_stack = torch.stack(out_list)\n",
    "\n",
    "        out_means = torch.mean(out_stack, dim=0)\n",
    "        mean_list.append(out_means)\n",
    "\n",
    "        out_sdts = torch.std(out_stack, dim=0)\n",
    "        std_list.append(out_sdts)\n",
    "\n",
    "    softmax_pred = torch.cat(mean_list).permute(0,2,3,1)\n",
    "    smx_tiles = [x for x in softmax_pred.cpu().numpy()]\n",
    "\n",
    "    std_pred = torch.cat(std_list).permute(0,2,3,1)\n",
    "    std_tiles = [x for x in std_pred.cpu().numpy()]\n",
    "    \n",
    "    smxcores = dl.reconstruct_from_tiles(smx_tiles)\n",
    "    segmentations = [np.argmax(x, axis=-1) for x in smxcores]\n",
    "    std_deviations = dl.reconstruct_from_tiles(std_tiles)\n",
    "\n",
    "    return smxcores, segmentations, std_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "@patch\n",
    "def apply_dropout(self:Learner):\n",
    "    \"If a module contains 'dropout', it will be switched to .train() mode.\"\n",
    "    for m in self.model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport? \n",
    "@patch\n",
    "def predict_tiles_with_mc_dropout(self:Learner, ds_idx=1, dl=None, n_times=20):\n",
    "    \"Make predictions with dropout applied.\"\n",
    "\n",
    "    if dl is None: dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "\n",
    "    self.model.eval()\n",
    "    self.apply_dropout()\n",
    "\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    for data in progress_bar(dl):\n",
    "        images, _, _ = data\n",
    "        out_list = []\n",
    "        for t in range(n_times):\n",
    "            with torch.no_grad():\n",
    "                out = self.model(images)\n",
    "            out = F.softmax(out, dim=1)\n",
    "            out_list.append(out)\n",
    "        out_stack = torch.stack(out_list)\n",
    "\n",
    "        out_means = torch.mean(out_stack, dim=0)\n",
    "        mean_list.append(out_means)\n",
    "\n",
    "        out_sdts = torch.std(out_stack, dim=0)\n",
    "        std_list.append(out_sdts)\n",
    "\n",
    "    softmax_pred = torch.cat(mean_list).permute(0,2,3,1)\n",
    "    smx_tiles = [x for x in softmax_pred.cpu().numpy()]\n",
    "\n",
    "    std_pred = torch.cat(std_list).permute(0,2,3,1)\n",
    "    std_tiles = [x for x in std_pred.cpu().numpy()]\n",
    "    \n",
    "    smxcores = dl.reconstruct_from_tiles(smx_tiles)\n",
    "    segmentations = [np.argmax(x, axis=-1) for x in smxcores]\n",
    "    std_deviations = dl.reconstruct_from_tiles(std_tiles)\n",
    "\n",
    "    return smxcores, segmentations, std_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###export \n",
    "@patch\n",
    "def get_mc_dropout_results(self, plot=True, dl=None, tile_ds:TileDataset=None, \n",
    "                           max_n=9, n_times=20, figsize=(15,15), **kwargs):\n",
    "    \"Get results with MC Dropout enabled. Plot results is enabled by default.\"\n",
    "    if dl is None:\n",
    "        dl = self.dls.valid\n",
    "    if tile_ds is None:\n",
    "        tile_ds = self.dls.valid_ds    \n",
    "    \n",
    "    smxs, segs, std_devs = self.predict_tiles_with_mc_dropout(dl, tile_ds, n_times)\n",
    "    entrp = {tile_ds.files[i]:std_devs[i] for i in range(len(tile_ds.files))}\n",
    "    \n",
    "    if plot==True:\n",
    "        imgs = tile_ds.get_images()\n",
    "        for i, path in enumerate(tile_ds.files):\n",
    "            img = imgs[i]\n",
    "            msk = tile_ds.lbl_wgt_pdf[path.name][0] if path.name in tile_ds.lbl_wgt_pdf else np.ones_like(imgs)\n",
    "            pred = segs[i]\n",
    "            std_dev = std_devs[i]\n",
    "            entr = entropy(std_dev[...,1]).mean()\n",
    "            ser_tmp = pd.Series({'File' : path.name, 'Entropy': entr})\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=4, figsize=figsize)\n",
    "                        \n",
    "            \n",
    "            axs[0].imshow(imgs[i], cmap='binary_r')\n",
    "            axs[0].set_axis_off()\n",
    "            axs[0].set_title('Image {}'.format(path.name))\n",
    "            \n",
    "            axs[1].imshow(msk, cmap='binary_r')\n",
    "            axs[1].set_axis_off()\n",
    "            axs[1].set_title('Target')\n",
    "\n",
    "            \n",
    "            axs[3].set_title('Std ({} Entropy)'.format(np.round(entrop,2)))\n",
    "    \n",
    "    return smxs, segs, std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_results(self:Learner, ds_idx=1, dl=None, max_n=9, shuffle=True, **kwargs):\n",
    "    if dl is None: dl = self.dls[ds_idx].new(shuffle=shuffle)\n",
    "    b = dl.one_batch()\n",
    "    _, _, preds  = self.get_preds(dl=[b], with_decoded=True)\n",
    "    print(preds.shape)\n",
    "    print(b)\n",
    "    self.dls.show_results(b, preds, max_n=max_n, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def siampredict(self:Learner, item, rm_type_tfms=None, with_input=False):\n",
    "    res = self.predict(item, rm_type_tfms=None, with_input=False)\n",
    "    if res[0] == tensor(0):\n",
    "        SiameseImage(item[0], item[1], 'Prediction: Not similar').show()\n",
    "    else:\n",
    "        SiameseImage(item[0], item[1], 'Prediction: Similar').show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
