{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#default_exp learner\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learner\n",
    "\n",
    "> Implements functions necessary to build an  `EnsembleLearner` suitable for bioimgage segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import shutil, gc, joblib, json, zarr, numpy as np, pandas as pd\n",
    "import time\n",
    "import tifffile, cv2\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "from dataclasses import dataclass, field, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.basics import patch, GetAttr\n",
    "from fastcore.foundation import add_docs, L\n",
    "from fastai import optimizer\n",
    "from fastai.torch_core import TensorImage\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastai.callback.progress import CSVLogger\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.transforms import get_image_files, get_files\n",
    "from fastai.vision.augment import Brightness, Contrast, Saturation\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.metrics import Dice, DiceMulti\n",
    "\n",
    "from deepflash2.losses import get_loss\n",
    "from deepflash2.models import create_smp_model, save_smp_model, load_smp_model, run_cellpose\n",
    "from deepflash2.data import TileDataset, RandomTileDataset, _read_img, _read_msk\n",
    "from deepflash2.utils import dice_score, plot_results, get_label_fn, calc_iterations, save_mask, save_unc, export_roi_set, get_instance_segmentation_metrics\n",
    "from deepflash2.utils import compose_albumentations as _compose_albumentations\n",
    "import deepflash2.tta as tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"Config class for settings.\"\n",
    "\n",
    "    # Project\n",
    "    project_dir:str = '.'\n",
    "\n",
    "    # GT Estimation Settings\n",
    "    staple_thres:float = 0.5\n",
    "    staple_fval:int= 1\n",
    "    majority_vote_undec:int = 1\n",
    "\n",
    "    # Train General Settings\n",
    "    n_models:int = 5\n",
    "    max_splits:int=5\n",
    "    random_state:int = 42\n",
    "        \n",
    "    # Pytorch Segmentation Model Settings\n",
    "    arch:str = 'Unet'\n",
    "    encoder_name:str = 'resnet34'\n",
    "    encoder_weights:str = 'imagenet'\n",
    "\n",
    "    # Train Data Settings\n",
    "    n_classes:int = 2\n",
    "    tile_shape:int = 512\n",
    "    instance_labels:bool = False\n",
    "\n",
    "    # Train Settings\n",
    "    base_lr:float = 0.001\n",
    "    batch_size:int = 4\n",
    "    weight_decay:float = 0.001\n",
    "    mixed_precision_training:bool = False\n",
    "    optim:str = 'Adam'\n",
    "    loss:str = 'CrossEntropyDiceLoss'\n",
    "    n_iter:int = 2500\n",
    "    sample_mult:int = 0\n",
    "\n",
    "    # Validation and Prediction Settings\n",
    "    tta:bool = True\n",
    "    border_padding_factor:float = 0.25\n",
    "    shift:float = 0.5\n",
    "\n",
    "    # Train Data Augmentation\n",
    "    gamma_limit_lower:int = 80\n",
    "    gamma_limit_upper:int = 120\n",
    "    CLAHE_clip_limit:float = 0.0\n",
    "    brightness_limit:float = 0.0\n",
    "    contrast_limit:float = 0.0\n",
    "    flip:bool = True\n",
    "    rot:int = 360\n",
    "    distort_limit:float = 0\n",
    "        \n",
    "    # Loss Settings\n",
    "    mode:str = 'multiclass' #currently only tested for multiclass\n",
    "    loss_alpha:float = 0.5 # Twerksky/Focal loss\n",
    "    loss_beta:float = 0.5 # Twerksy Loss\n",
    "    loss_gamma:float = 2.0 # Focal loss\n",
    "    loss_smooth_factor:float = 0. #SoftCrossEntropyLoss\n",
    "    \n",
    "    # Pred Settings\n",
    "    pred_tta:bool = True\n",
    "    min_pixel_export:int = 0\n",
    "        \n",
    "    # Instance Segmentation Settings\n",
    "    cellpose_model:str='nuclei'\n",
    "    cellpose_diameter:int=0\n",
    "    cellpose_export_class:int=1\n",
    "    instance_segmentation_metrics:bool=False\n",
    "\n",
    "    # Folder Structure\n",
    "    gt_dir:str = 'GT_Estimation'\n",
    "    train_dir:str = 'Training'\n",
    "    pred_dir:str = 'Prediction'\n",
    "    ens_dir:str = 'models'\n",
    "    val_dir:str = 'valid'\n",
    "    \n",
    "    @property\n",
    "    def albumentation_kwargs(self):\n",
    "        kwargs = ['gamma_limit_lower', 'gamma_limit_upper', 'CLAHE_clip_limit', \n",
    "                  'brightness_limit', 'contrast_limit', 'distort_limit']\n",
    "        return dict(filter(lambda x: x[0] in kwargs, self.__dict__.items()))\n",
    "\n",
    "    @property\n",
    "    def svm_kwargs(self):\n",
    "        svm_vars = ['kernel', 'nu', 'gamma']\n",
    "        return dict(filter(lambda x: x[0] in svm_vars, self.__dict__.items()))\n",
    "\n",
    "    def save(self, path):\n",
    "        'Save configuration to path'\n",
    "        path = Path(path).with_suffix('.json')\n",
    "        with open(path, 'w') as config_file:\n",
    "            json.dump(asdict(self), config_file)\n",
    "        print(f'Saved current configuration to {path}.json')\n",
    "        return path\n",
    "\n",
    "    def load(self, path):\n",
    "        'Load configuration from path'\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            with open(path) as config_file: c = json.load(config_file)\n",
    "            if not Path(c['project_dir']).is_dir(): c['project_dir']='deepflash2'\n",
    "            for k,v in c.items(): setattr(self, k, v)\n",
    "            print(f'Successsfully loaded configuration from {path}')\n",
    "        except:\n",
    "            print('Error! Select valid config file (.json)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved current configuration to test_config.json.json\n",
      "Successsfully loaded configuration from test_config.json\n"
     ]
    }
   ],
   "source": [
    "t1 = Config(n_models=3)\n",
    "path = t1.save('test_config')\n",
    "t2 = Config()\n",
    "t2.load(path)\n",
    "test_eq(t1, t2)\n",
    "path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_optim_dict = {\n",
    "    'ranger' : optimizer.ranger,\n",
    "    'Adam' : optimizer.Adam,\n",
    "    'RAdam' : optimizer.RAdam,\n",
    "    'QHAdam' :optimizer.QHAdam,\n",
    "    'Larc' : optimizer.Larc,\n",
    "    'Lamb' : optimizer.Lamb,\n",
    "    'SGD' : optimizer.SGD,\n",
    "    'RMSProp' : optimizer.RMSProp,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from https://github.com/MIC-DKFZ/nnUNet/blob/2fade8f32607220f8598544f0d5b5e5fa73768e5/nnunet/network_architecture/neural_network.py#L250\n",
    "def _get_gaussian(patch_size, sigma_scale=1. / 8) -> np.ndarray:\n",
    "    tmp = np.zeros(patch_size)\n",
    "    center_coords = [i // 2 for i in patch_size]\n",
    "    sigmas = [i * sigma_scale for i in patch_size]\n",
    "    tmp[tuple(center_coords)] = 1\n",
    "    gaussian_importance_map = gaussian_filter(tmp, sigmas, 0, mode='constant', cval=0)\n",
    "    gaussian_importance_map = gaussian_importance_map / np.max(gaussian_importance_map) * 1\n",
    "    gaussian_importance_map = gaussian_importance_map.astype(np.float32)\n",
    "\n",
    "    # gaussian_importance_map cannot be 0, otherwise we may end up with nans!\n",
    "    gaussian_importance_map[gaussian_importance_map == 0] = np.min(\n",
    "        gaussian_importance_map[gaussian_importance_map != 0])\n",
    "\n",
    "    return gaussian_importance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(_get_gaussian((512,512)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def energy_score(x, T=1, dim=1):\n",
    "    'Return the energy score as proposed by  Liu, Weitang, et al. (2020).'\n",
    "    return -(T*torch.logsumexp(x/T, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsemblePredict():\n",
    "    'Class for prediction with multiple models'\n",
    "    def __init__(self, models_paths, zarr_store=None):\n",
    "        self.models_paths = models_paths\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.init_models()\n",
    "        \n",
    "        # Init zarr storage\n",
    "        self.store = str(zarr_store) if zarr_store else zarr.storage.TempStore()\n",
    "        self.root = zarr.group(store=self.store)\n",
    "        self.g_smx = self.root.require_group('smx')\n",
    "        self.g_eng, self.g_std = None, None\n",
    "        \n",
    "    def init_models(self):\n",
    "        self.models = []\n",
    "        self.stats = None\n",
    "        for p in self.models_paths:     \n",
    "            model, stats = load_smp_model(p)\n",
    "            if not self.stats: self.stats = stats\n",
    "            assert np.array_equal(stats, self.stats), 'Only models trained on the same stats are allowed.'\n",
    "            model.float()\n",
    "            model.eval()\n",
    "            model.to(self.device)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, \n",
    "                ds, \n",
    "                use_tta=True, \n",
    "                bs=4, \n",
    "                use_gaussian=True, \n",
    "                sigma_scale=1./8, \n",
    "                uncertainty_estimates=True, \n",
    "                uncertainty_type = 'uncertainty',\n",
    "                energy_scores=False, \n",
    "                energy_T = 1., \n",
    "                verbose=0):\n",
    "        \n",
    "        if verbose>0: print('Ensemble prediction with models:', self.models_paths)\n",
    "            \n",
    "        tfms = [tta.HorizontalFlip(),tta.VerticalFlip()] if use_tta else []\n",
    "        if verbose>0: print('Using Test-Time Augmentation with:', tfms)\n",
    "                      \n",
    "        dl = DataLoader(ds, bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "\n",
    "        # Create zero arrays\n",
    "        data_shape = ds.image_shapes[0]\n",
    "        softmax = np.zeros((*data_shape, ds.c), dtype='float32')\n",
    "        merge_map = np.zeros(data_shape, dtype='float32')\n",
    "        stdeviation = np.zeros(data_shape, dtype='float32') if uncertainty_estimates else None\n",
    "        energy = np.zeros(data_shape, dtype='float32') if energy_scores else None\n",
    "\n",
    "        # Define merge weights\n",
    "        if use_gaussian:\n",
    "            mw_numpy = _get_gaussian(ds.output_shape, sigma_scale)\n",
    "        else: \n",
    "            mw_numpy = np.ones(dl.output_shape)\n",
    "        mw = torch.from_numpy(mw_numpy).to(self.device)\n",
    "        \n",
    "        # Loop over tiles (indices required!)\n",
    "        for tiles, idxs in iter(dl):\n",
    "            tiles = tiles.to(self.device)\n",
    "            smx_merger = tta.Merger()\n",
    "            if energy_scores: \n",
    "                energy_merger = tta.Merger()\n",
    "            \n",
    "            # Loop over tt-augmentations\n",
    "            for t in tta.Compose(tfms): \n",
    "                aug_tiles = t.augment_image(tiles)\n",
    "                model_merger = tta.Merger()\n",
    "                if energy_scores: engergy_list = []\n",
    "                \n",
    "                # Loop over models\n",
    "                for model in self.models:\n",
    "                    with torch.inference_mode(): \n",
    "                        logits = model(aug_tiles)\n",
    "                    logits = t.deaugment_mask(logits)\n",
    "                    smx_merger.append(F.softmax(logits, dim=1)) \n",
    "                    if energy_scores: \n",
    "                        energy_merger.append(-energy_score(logits, energy_T)) #negative energy score\n",
    "\n",
    "            out_list = []\n",
    "            # Apply gaussian weigthing\n",
    "            batch_smx = smx_merger.result()*mw.view(1,1,*mw.shape)\n",
    "            # Reshape and append to list\n",
    "            out_list.append([x for x in batch_smx.permute(0,2,3,1).cpu().numpy()])\n",
    "            \n",
    "            if uncertainty_estimates:\n",
    "                batch_std = torch.mean(smx_merger.result(uncertainty_type), dim=1)*mw.view(1,*mw.shape)\n",
    "                out_list.append([x for x in batch_std.cpu().numpy()])\n",
    "            \n",
    "            if energy_scores:\n",
    "                batch_energy =  energy_merger.result()*mw.view(1,*mw.shape)\n",
    "                out_list.append([x for x in batch_energy.cpu().numpy()])\n",
    "\n",
    "            # Compose predictions\n",
    "            for preds in zip(*out_list, idxs):\n",
    "                if len(preds)==4: smx,std,eng,idx = preds \n",
    "                elif uncertainty_estimates: smx,std,idx = preds \n",
    "                elif energy_scores: smx,eng,idx = preds \n",
    "                \n",
    "                else: smx, idx = preds\n",
    "                out_slice = ds.out_slices[idx]\n",
    "                in_slice = ds.in_slices[idx]\n",
    "                softmax[out_slice] += smx[in_slice]\n",
    "                merge_map[out_slice] += mw_numpy[in_slice]\n",
    "                \n",
    "                if uncertainty_estimates:\n",
    "                    stdeviation[out_slice] += std[in_slice]\n",
    "                if energy_scores:\n",
    "                    energy[out_slice] += eng[in_slice]\n",
    "                    \n",
    "        # Normalize weighting           \n",
    "        softmax /= merge_map[..., np.newaxis]\n",
    "        if uncertainty_estimates:\n",
    "            stdeviation /= merge_map   \n",
    "        if energy_scores:\n",
    "            energy /= merge_map\n",
    "\n",
    "        return softmax, stdeviation, energy\n",
    "    \n",
    "    def predict_images(self, image_list, ds_kwargs={}, verbose=1, **kwargs):\n",
    "        \"Predict images in 'image_list' with kwargs and save to zarr\"\n",
    "    \n",
    "        for f in progress_bar(image_list, leave=False):\n",
    "            if verbose>0: print(f'Predicting {f.name}')\n",
    "            ds = TileDataset([f], stats=self.stats, return_index=True, **ds_kwargs)\n",
    "            softmax, stdeviation, energy = self.predict(ds, **kwargs)\n",
    "            \n",
    "            # Save to zarr\n",
    "            self.g_smx[f.name] = softmax\n",
    "            if stdeviation is not None: \n",
    "                self.g_std = self.root.require_group('std')\n",
    "                self.g_std[f.name] = stdeviation\n",
    "            if energy is not None: \n",
    "                self.g_eng = self.root.require_group('energy')\n",
    "                self.g_eng[f.name] = energy\n",
    "        \n",
    "        return self.g_smx, self.g_std, self.g_eng       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleLearner(GetAttr):\n",
    "    _default = 'config' \n",
    "    def __init__(self, image_dir='images', mask_dir=None, config=None, path=None, ensemble_path=None, preproc_dir=None, \n",
    "                 label_fn=None, metrics=None, cbs=None, ds_kwargs={}, dl_kwargs={}, model_kwargs={}, stats=None, files=None):\n",
    "\n",
    "        self.config = config or Config()\n",
    "        self.stats = stats\n",
    "        self.dl_kwargs = dl_kwargs\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.add_ds_kwargs = ds_kwargs\n",
    "        self.path = Path(path) if path is not None else Path('.')\n",
    "        default_metrics = [Dice()] if self.n_classes==2 else [DiceMulti()]\n",
    "        self.metrics = metrics or default_metrics\n",
    "        self.loss_fn = self.get_loss()\n",
    "        self.cbs = cbs or [SaveModelCallback(monitor='dice' if self.n_classes==2 else 'dice_multi')] #ShowGraphCallback\n",
    "        self.ensemble_dir = ensemble_path or self.path/self.ens_dir\n",
    "        if ensemble_path is not None: \n",
    "            ensemble_path.mkdir(exist_ok=True, parents=True)\n",
    "            self.load_ensemble(path=ensemble_path)\n",
    "        else: self.models = {}\n",
    "        \n",
    "        self.files = L(files) or get_image_files(self.path/image_dir, recurse=False)\n",
    "        assert len(self.files)>0, f'Found {len(self.files)} images in \"{image_dir}\". Please check your images and image folder'\n",
    "        if any([mask_dir, label_fn]):\n",
    "            if label_fn: self.label_fn = label_fn\n",
    "            else: self.label_fn = get_label_fn(self.files[0], self.path/mask_dir)\n",
    "            #Check if corresponding masks exist\n",
    "            mask_check = [self.label_fn(x).exists() for x in self.files]\n",
    "            chk_str = f'Found {len(self.files)} images in \"{image_dir}\" and {sum(mask_check)} masks in \"{mask_dir}\".'\n",
    "            assert len(self.files)==sum(mask_check) and len(self.files)>0, f'Please check your images and masks (and folders). {chk_str}'\n",
    "            print(chk_str)\n",
    "                  \n",
    "        else:\n",
    "            self.label_fn = label_fn\n",
    "        self.n_splits=min(len(self.files), self.max_splits)\n",
    "        self._set_splits()\n",
    "        self.ds = RandomTileDataset(self.files, label_fn=self.label_fn, \n",
    "                                    preproc_dir=preproc_dir,\n",
    "                                    instance_labels=self.instance_labels,\n",
    "                                    n_classes=self.n_classes, \n",
    "                                    stats=self.stats, \n",
    "                                    normalize = True,\n",
    "                                    sample_mult=self.sample_mult if self.sample_mult>0 else None, \n",
    "                                    verbose=0,\n",
    "                                    **self.add_ds_kwargs)\n",
    "        \n",
    "        self.stats = self.ds.stats\n",
    "        self.in_channels = self.ds.get_data(max_n=1)[0].shape[-1]\n",
    "        self.df_val, self.df_ens, self.df_model, self.ood = None,None,None,None\n",
    "        self.recorder = {}\n",
    "               \n",
    "    def _set_splits(self):\n",
    "        if self.n_splits>1:\n",
    "            kf = KFold(self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "            self.splits = {key:(self.files[idx[0]], self.files[idx[1]]) for key, idx in zip(range(1,self.n_splits+1), kf.split(self.files))}    \n",
    "        else:\n",
    "            self.splits = {1: (self.files[0], self.files[0])}\n",
    "            \n",
    "    def _compose_albumentations(self, **kwargs):\n",
    "        return _compose_albumentations(**kwargs)\n",
    "        \n",
    "    @property        \n",
    "    def pred_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        ds_kwargs['use_preprocessed_labels']= True\n",
    "        ds_kwargs['preproc_dir']=self.ds.preproc_dir\n",
    "        ds_kwargs['instance_labels']= self.instance_labels\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['n_classes']= self.n_classes\n",
    "        ds_kwargs['shift']= self.shift\n",
    "        ds_kwargs['border_padding_factor']= self.border_padding_factor\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property        \n",
    "    def train_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        # Settings from config\n",
    "        ds_kwargs['use_preprocessed_labels']= True\n",
    "        ds_kwargs['preproc_dir']=self.ds.preproc_dir\n",
    "        ds_kwargs['instance_labels']= self.instance_labels\n",
    "        ds_kwargs['stats']= self.stats\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['n_classes']= self.n_classes\n",
    "        ds_kwargs['shift']= 1.\n",
    "        ds_kwargs['border_padding_factor']= 0.\n",
    "        ds_kwargs['flip'] = self.flip\n",
    "        ds_kwargs['albumentations_tfms'] = self._compose_albumentations(**self.albumentation_kwargs)\n",
    "        ds_kwargs['sample_mult'] = self.sample_mult if self.sample_mult>0 else None\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        return f'{self.arch}_{self.encoder_name}_{self.n_classes}classes'  \n",
    "                    \n",
    "    def get_loss(self):\n",
    "        kwargs = {'mode':self.mode,\n",
    "                  'classes':[x for x in range(1, self.n_classes)],\n",
    "                  'smooth_factor': self.loss_smooth_factor,\n",
    "                  'alpha':self.loss_alpha, \n",
    "                  'beta':self.loss_beta, \n",
    "                  'gamma':self.loss_gamma}\n",
    "        return get_loss(self.loss, **kwargs)\n",
    "    \n",
    "    \n",
    "    def _get_dls(self, files, files_val=None):\n",
    "        ds = []\n",
    "        ds.append(RandomTileDataset(files, label_fn=self.label_fn, **self.train_ds_kwargs))\n",
    "        if files_val: \n",
    "            ds.append(TileDataset(files_val, label_fn=self.label_fn, **self.train_ds_kwargs))\n",
    "        else:\n",
    "            ds.append(ds[0])\n",
    "        dls = DataLoaders.from_dsets(*ds, bs=self.batch_size, pin_memory=True, **self.dl_kwargs)\n",
    "        if torch.cuda.is_available(): dls.cuda()\n",
    "        return dls\n",
    "    \n",
    "    def _create_model(self):\n",
    "        model = create_smp_model(arch=self.arch, \n",
    "                                 encoder_name=self.encoder_name, \n",
    "                                 encoder_weights=self.encoder_weights, \n",
    "                                 in_channels=self.in_channels, \n",
    "                                 classes=self.n_classes, \n",
    "                                 **self.model_kwargs)\n",
    "        if torch.cuda.is_available(): model.cuda()\n",
    "        return model\n",
    "               \n",
    "    def fit(self, i, n_iter=None, base_lr=None, **kwargs):\n",
    "        n_iter = n_iter or self.n_iter\n",
    "        base_lr = base_lr or self.base_lr\n",
    "        name = self.ensemble_dir/f'{self.model_name}-fold{i}.pth'\n",
    "        model = self._create_model()\n",
    "        files_train, files_val = self.splits[i]\n",
    "        dls = self._get_dls(files_train, files_val)  \n",
    "        log_name = f'{name.name}_{time.strftime(\"%Y%m%d-%H%M%S\")}.csv'\n",
    "        log_dir = self.ensemble_dir/'logs'\n",
    "        log_dir.mkdir(exist_ok=True, parents=True)\n",
    "        cbs = self.cbs.append(CSVLogger(fname=log_dir/log_name))\n",
    "        self.learn = Learner(dls, model, \n",
    "                             metrics=self.metrics, \n",
    "                             wd=self.weight_decay, \n",
    "                             loss_func=self.loss_fn, \n",
    "                             opt_func=_optim_dict[self.optim], \n",
    "                             cbs=self.cbs)\n",
    "        self.learn.model_dir = self.ensemble_dir.parent/'.tmp'\n",
    "        if self.mixed_precision_training: self.learn.to_fp16()\n",
    "        print(f'Starting training for {name.name}')\n",
    "        epochs = calc_iterations(n_iter=n_iter,ds_length=len(dls.train_ds), bs=self.batch_size)\n",
    "        #self.learn.fit_one_cycle(epochs, lr_max)\n",
    "        self.learn.fine_tune(epochs, base_lr=base_lr)\n",
    "\n",
    "        print(f'Saving model at {name}')\n",
    "        name.parent.mkdir(exist_ok=True, parents=True)\n",
    "        save_smp_model(self.learn.model, self.arch, name, stats=self.stats)\n",
    "        self.models[i]=name\n",
    "        self.recorder[i]=self.learn.recorder\n",
    "        \n",
    "    def fit_ensemble(self, n_iter, skip=False, **kwargs):\n",
    "        for i in range(1, self.n_models+1):\n",
    "            if skip and (i in self.models): continue\n",
    "            self.fit(i, n_iter,  **kwargs)\n",
    "       \n",
    "    def set_n(self, n):\n",
    "        for i in range(n, len(self.models)):\n",
    "            self.models.pop(i+1, None)            \n",
    "        self.n_models = n\n",
    "                                                       \n",
    "    def get_valid_results(self, model_no=None, zarr_store=None, export_dir=None, filetype='.png', **kwargs):\n",
    "        res_list = []\n",
    "        model_list = self.models if not model_no else {k:v for k,v in self.models.items() if k==model_no}\n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for i, model_path in model_list.items():\n",
    "            ep = EnsemblePredict(models_paths=[model_path], zarr_store=zarr_store)\n",
    "            _, files_val = self.splits[i]\n",
    "            g_smx, g_std, g_eng = ep.predict_images(files_val, bs=self.batch_size, ds_kwargs=self.pred_ds_kwargs, **kwargs)\n",
    "            del ep\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            chunk_store = g_smx.chunk_store.path\n",
    "            for j, f in enumerate(files_val):\n",
    "                msk = self.ds.get_data(f, mask=True)[0]\n",
    "                pred = np.argmax(g_smx[f.name][:], axis=-1).astype('uint8')\n",
    "                m_dice = dice_score(msk, pred)\n",
    "                m_path = self.models[i].name\n",
    "                df_tmp = pd.Series({'file' : f.name,\n",
    "                        'model' :  m_path,\n",
    "                        'model_no' : i,\n",
    "                        'dice_score': m_dice,\n",
    "                        #'mean_energy': np.mean(g_eng[f.name][:][pred>0]),\n",
    "                        'uncertainty_score': np.mean(g_std[f.name][:][pred>0]) if g_std is not None else None,\n",
    "                        'image_path': f,\n",
    "                        'mask_path': self.label_fn(f),\n",
    "                        'softmax_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                        'engergy_path': f'{chunk_store}/{g_eng.path}/{f.name}' if g_eng is not None else None,\n",
    "                        'uncertainty_path': f'{chunk_store}/{g_std.path}/{f.name}' if g_std is not None else None})\n",
    "                res_list.append(df_tmp)\n",
    "                if export_dir:   \n",
    "                    save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.model}_mask', filetype)\n",
    "                    if g_std is not None:\n",
    "                        save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_uncertainty', filetype)\n",
    "                    if g_eng is not None:\n",
    "                        save_unc(g_eng[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_energy', filetype)\n",
    "        self.df_val = pd.DataFrame(res_list)\n",
    "        if export_dir: \n",
    "            self.df_val.to_csv(export_dir/f'val_results.csv', index=False)\n",
    "            self.df_val.to_excel(export_dir/f'val_results.xlsx')\n",
    "        return self.df_val\n",
    "        \n",
    "    def show_valid_results(self, model_no=None, files=None, **kwargs):\n",
    "        if self.df_val is None: self.get_valid_results(**kwargs)\n",
    "        df = self.df_val\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        if model_no is not None: df = df[df.model_no==model_no] \n",
    "        for _, r in df.iterrows():\n",
    "            img = self.ds.get_data(r.image_path)[0][:]\n",
    "            msk = self.ds.get_data(r.image_path, mask=True)[0]\n",
    "            pred = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            std = zarr.load(r.uncertainty_path)\n",
    "            _d_model = f'Model {r.model_no}'\n",
    "            if self.tta: plot_results(img, msk, pred, std, df=r, model=_d_model)  \n",
    "            else: plot_results(img, msk, pred, np.zeros_like(pred), df=r, model=_d_model)  \n",
    "          \n",
    "    def load_ensemble(self, path=None):\n",
    "        path = path or self.ensemble_dir\n",
    "        models = sorted(get_files(path, extensions='.pth', recurse=False))\n",
    "        self.models = {}\n",
    "        \n",
    "        for i, m in enumerate(models,1):\n",
    "            if i==0: self.n_classes = int(m.name.split('_')[2][0])\n",
    "            else: assert self.n_classes==int(m.name.split('_')[2][0]), 'Check models. Models are trained on different number of classes.'\n",
    "            self.models[i] = m\n",
    "        \n",
    "        if len(self.models)>0: \n",
    "            self.set_n(len(self.models))\n",
    "            print(f'Found {len(self.models)} models in folder {path}:')\n",
    "            print([m.name for m in self.models.values()])\n",
    "            \n",
    "            # Reset stats\n",
    "            print(f'Loading stats from {self.models[1].name}') \n",
    "            _, self.stats = load_smp_model(self.models[1])\n",
    "                           \n",
    "    def get_ensemble_results(self, files, zarr_store=None, export_dir=None, filetype='.png', **kwargs):   \n",
    "        ep = EnsemblePredict(models_paths=self.models.values(), zarr_store=zarr_store)\n",
    "        g_smx, g_std, g_eng = ep.predict_images(files, bs=self.batch_size, ds_kwargs=self.pred_ds_kwargs, **kwargs)\n",
    "        chunk_store = g_smx.chunk_store.path\n",
    "        del ep\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        res_list = []\n",
    "        for f in files:\n",
    "            pred = np.argmax(g_smx[f.name][:], axis=-1).astype('uint8')\n",
    "            df_tmp = pd.Series({'file' : f.name,\n",
    "                                'ensemble' :  self.model_name,\n",
    "                                'n_models' : len(self.models),\n",
    "                                #'mean_energy': np.mean(g_eng[f.name][:][pred>0]),\n",
    "                                'uncertainty_score': np.mean(g_std[f.name][:][pred>0]) if g_std is not None else None,\n",
    "                                'image_path': f,\n",
    "                                'softmax_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                                'uncertainty_path': f'{chunk_store}/{g_std.path}/{f.name}' if g_std is not None else None,\n",
    "                                'energy_path': f'{chunk_store}/{g_eng.path}/{f.name}' if g_eng is not None else None})\n",
    "            res_list.append(df_tmp)\n",
    "            if export_dir:   \n",
    "                save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.ensemble}_mask', filetype)\n",
    "                if g_std is not None:\n",
    "                    save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.ensemble}_unc', filetype)\n",
    "                if g_eng is not None:\n",
    "                    save_unc(g_eng[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.ensemble}_energy', filetype)\n",
    "                    \n",
    "        self.df_ens  = pd.DataFrame(res_list)\n",
    "        return g_smx, g_std, g_eng\n",
    "    \n",
    "    def score_ensemble_results(self, mask_dir=None, label_fn=None):\n",
    "        if mask_dir is not None and label_fn is None:\n",
    "            label_fn = get_label_fn(self.df_ens.image_path[0], self.path/mask_dir)\n",
    "        for i, r in self.df_ens.iterrows():\n",
    "            if label_fn is not None:\n",
    "                msk_path = self.label_fn(r.image_path)\n",
    "                msk = _read_msk(msk_path, n_classes=self.n_classes, instance_labels=self.instance_labels)\n",
    "                self.df_ens.loc[i, 'mask_path'] = msk_path\n",
    "            else:\n",
    "                msk = self.ds.labels[r.file][:]\n",
    "            pred = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            self.df_ens.loc[i, 'dice_score'] = dice_score(msk, pred)\n",
    "        return self.df_ens\n",
    "       \n",
    "    def show_ensemble_results(self, files=None, unc=True, unc_metric=None, metric_name='dice_score'):\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        df = self.df_ens\n",
    "        if files is not None: df = df.reset_index().set_index('file', drop=False).loc[files]\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = []\n",
    "            imgs.append(_read_img(r.image_path)[:])\n",
    "            if metric_name in r.index: \n",
    "                try: msk = self.ds.labels[r.file][:]\n",
    "                except: msk = _read_msk(r.mask_path, n_classes=self.n_classes, instance_labels=self.instance_labels)\n",
    "                imgs.append(msk)\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            imgs.append(np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8'))\n",
    "            if unc: imgs.append(zarr.load(r.uncertainty_path))\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, metric_name=metric_name, unc_metric=unc_metric) \n",
    "            \n",
    "    def get_cellpose_results(self, export_dir=None):\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        cl = self.cellpose_export_class\n",
    "        assert cl<self.n_classes, f'{cl} not avaialable from {self.n_classes} classes'\n",
    "        \n",
    "        smxs, preds = [], []\n",
    "        for _, r in self.df_ens.iterrows():\n",
    "            softmax = zarr.load(r.softmax_path)\n",
    "            smxs.append(softmax)\n",
    "            preds.append(np.argmax(softmax, axis=-1).astype('uint8'))\n",
    "            \n",
    "        probs = [x[...,cl] for x in smxs]\n",
    "        masks = [x==cl for x in preds]\n",
    "        cp_masks = run_cellpose(probs, masks,\n",
    "                                model_type=self.cellpose_model, \n",
    "                                diameter=self.cellpose_diameter, \n",
    "                                min_size=self.min_pixel_export, \n",
    "                                gpu=torch.cuda.is_available())\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            cp_path = export_dir/'cellpose_masks'\n",
    "            cp_path.mkdir(parents=True, exist_ok=True)\n",
    "            for idx, r in self.df_ens.iterrows():\n",
    "                tifffile.imwrite(cp_path/f'{r.file}_class{cl}.tif', cp_masks[idx], compress=6)    \n",
    "                \n",
    "        self.cellpose_masks = cp_masks\n",
    "        return cp_masks\n",
    "    \n",
    "    def score_cellpose_results(self, mask_dir=None, label_fn=None):\n",
    "        assert self.cellpose_masks is not None, 'Run get_cellpose_results() first'\n",
    "        if mask_dir is not None and label_fn is None:\n",
    "            label_fn = get_label_fn(self.df_ens.image_path[0], self.path/mask_dir)\n",
    "        for i, r in self.df_ens.iterrows():\n",
    "            if label_fn is not None:\n",
    "                msk_path = self.label_fn(r.image_path)\n",
    "                msk = _read_msk(msk_path, n_classes=self.n_classes, instance_labels=self.instance_labels)\n",
    "                self.df_ens.loc[i, 'mask_path'] = msk_path\n",
    "            else:\n",
    "                msk = self.ds.labels[r.file][:]\n",
    "            _, msk = cv2.connectedComponents(msk, connectivity=4)\n",
    "            pred = self.cellpose_masks[i]\n",
    "            ap, tp, fp, fn = get_instance_segmentation_metrics(msk, pred, is_binary=False, min_pixel=self.min_pixel_export)\n",
    "            self.df_ens.loc[i, 'mean_average_precision'] = ap.mean()\n",
    "            self.df_ens.loc[i, 'average_precision_at_iou_50'] = ap[0]\n",
    "        return self.df_ens\n",
    "      \n",
    "    def show_cellpose_results(self, files=None, unc=True, unc_metric=None, metric_name='mean_average_precision'):\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        df = self.df_ens.reset_index()\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = []\n",
    "            imgs.append(_read_img(r.image_path)[:])\n",
    "            if metric_name in r.index: \n",
    "                try:\n",
    "                    mask = self.ds.labels[idx][:]\n",
    "                except: \n",
    "                    mask = _read_msk(r.mask_path, n_classes=self.n_classes, instance_labels=self.instance_labels)\n",
    "                _, comps = cv2.connectedComponents((mask==self.cellpose_export_class).astype('uint8'), connectivity=4)\n",
    "                imgs.append(label2rgb(comps, bg_label=0))\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            imgs.append(label2rgb(self.cellpose_masks[r['index']], bg_label=0))\n",
    "            if unc: imgs.append(zarr.load(r.uncertainty_path))\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, metric_name=metric_name, unc_metric=unc_metric) \n",
    "                \n",
    "    def lr_find(self, files=None, **kwargs):\n",
    "        files = files or self.files\n",
    "        dls = self._get_dls(files)\n",
    "        model = self._create_model()\n",
    "        learn = Learner(dls, model, metrics=self.metrics, wd=self.weight_decay, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim])\n",
    "        if self.mixed_precision_training: learn.to_fp16()\n",
    "        sug_lrs = learn.lr_find(**kwargs)\n",
    "        return sug_lrs, learn.recorder  \n",
    "    \n",
    "    def export_imagej_rois(self, output_folder='ROI_sets', **kwargs):\n",
    "        assert self.df_ens is not None, \"Please run prediction first.\"\n",
    "        \n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "        for idx, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            mask = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            uncertainty = zarr.load(r.uncertainty_path)\n",
    "            export_roi_set(mask, uncertainty, name=r.file, path=output_folder, ascending=False, **kwargs)\n",
    "        \n",
    "    def export_cellpose_rois(self, output_folder='cellpose_ROI_sets', **kwargs):\n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "        for idx, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            mask = self.cellpose_masks[idx]\n",
    "            uncertainty = zarr.load(r.uncertainty_path)\n",
    "            export_roi_set(mask, uncertainty, instance_labels=True, name=r.file, path=output_folder, ascending=False, **kwargs)\n",
    "           \n",
    "    #def clear_tmp(self):\n",
    "    #    try: \n",
    "    #        shutil.rmtree('/tmp/*', ignore_errors=True)\n",
    "    #        shutil.rmtree(self.path/'.tmp')\n",
    "    #        print(f'Deleted temporary files from {self.path/\".tmp\"}')\n",
    "    #    except: print(f'No temporary files to delete at {self.path/\".tmp\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "add_docs(EnsembleLearner, \"Meta class to train and predict model ensembles with `n` models\",\n",
    "         fit=\"Fit model number `i`\",\n",
    "         fit_ensemble=\"Fit `i` models and `skip` existing\",\n",
    "         get_valid_results=\"Validate models on validation data and save results\",\n",
    "         show_valid_results=\"Plot results of all or `file` validation images\",\n",
    "         get_ensemble_results=\"Get models and ensemble results\", \n",
    "         score_ensemble_results=\"Compare ensemble results to given segmentation masks.\",\n",
    "         show_ensemble_results=\"Show result of ensemble or `model_no`\",\n",
    "         load_ensemble=\"Get models saved at `path`\",\n",
    "         get_cellpose_results='Get instance segmentation results using the cellpose integration',\n",
    "         score_cellpose_results=\"Compare cellpose nstance segmentation results to given masks.\",\n",
    "         show_cellpose_results='Show instance segmentation results from cellpose predictions.',\n",
    "         get_loss=\"Get loss function from loss name (config)\",\n",
    "         set_n=\"Change to `n` models per ensemble\",\n",
    "         lr_find=\"Wrapper for learning rate finder\",\n",
    "         export_imagej_rois='Export ImageJ ROI Sets to `ouput_folder`',\n",
    "         export_cellpose_rois='Export cellpose predictions to ImageJ ROI Sets in `ouput_folder`',\n",
    "         #clear_tmp=\"Clear directory with temporary files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"EnsembleLearner\" class=\"doc_header\"><code>class</code> <code>EnsembleLearner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>EnsembleLearner</code>(**`image_dir`**=*`'images'`*, **`mask_dir`**=*`None`*, **`config`**=*`None`*, **`path`**=*`None`*, **`ensemble_path`**=*`None`*, **`preproc_dir`**=*`None`*, **`label_fn`**=*`None`*, **`metrics`**=*`None`*, **`cbs`**=*`None`*, **`ds_kwargs`**=*`{}`*, **`dl_kwargs`**=*`{}`*, **`model_kwargs`**=*`{}`*, **`stats`**=*`None`*, **`files`**=*`None`*) :: `GetAttr`\n",
       "\n",
       "Meta class to train and predict model ensembles with `n` models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EnsembleLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df2",
   "language": "python",
   "name": "df2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
