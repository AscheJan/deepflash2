{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Ground Truth Estimation\n",
    "> Derive reference segmentations from segmentations of multiple experts. \n",
    "\n",
    "![](https://img.shields.io/badge/INPUT-expert%20segmentations-blue) \n",
    "![](https://img.shields.io/badge/OUTPUT-ground%20truth%20segmentations-success) \n",
    "![](https://img.shields.io/badge/OUTPUT-expert%20performance%20scores-success) \n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matjesg/deepflash2/blob/master/deepflash2_GUI.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Expert Segmentations\n",
    "\n",
    "**Required Steps:**\n",
    "1. *Select parent folder* containing sub-folders with segmentation masks, one folder per expert\n",
    "1. Click *Load Data*\n",
    "\n",
    "<video src=\"https://user-images.githubusercontent.com/13711052/139746674-4dbd2df4-d780-4ce3-8f77-f7f79a0b4eb9.mov\" controls width=\"100%\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Details**:  *deepflash2* fuses\n",
    "\n",
    "- binary segmentations of an image, that is, there must be a single foreground value that represents positively classified pixels\n",
    "    - Segmentation pixel values: background-class: 0; foreground-class: 1 or 255\n",
    "- instance segmentations of an image (instances represent positively classified pixels)\n",
    "    - Segmentation pixel values: background-class: 0; foreground-instances: 1,2,...,I\n",
    "\n",
    "Examplary input folder structure:\n",
    ">\n",
    "```\n",
    "expert_segmentations  -> one parent folder\n",
    "│                     \n",
    "│───expert1           -> one folder per expert\n",
    "│   │   mask1.png     -> segmentation masks\n",
    "│   │   mask2.png\n",
    "│   \n",
    "└───expert2\n",
    "    │   mask1.png\n",
    "    │   mask2.png\n",
    "```\n",
    "\n",
    "All common image formats (tif, png, etc.) are supported. See [imageio docs](https://imageio.readthedocs.io/en/stable/formats/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Ground Truth Estimation\n",
    "\n",
    "**Required Steps:**\n",
    "1. Click *Run* for STAPLE or Majority Voting\n",
    "\n",
    "<video src=\"https://user-images.githubusercontent.com/13711052/139746719-6cabfc99-fbbe-4fd3-a495-3984c75507d2.mov\" controls width=\"100%\"></video>\n",
    "\n",
    "- **Simultaneous truth and performance level estimation (STAPLE).** The STAPLE algorithm considers a collection of segmentations and computes a probabilistic estimate of the true segmentation and a measure of the performance level represented by each segmentation. _Source: Warfield, Simon K., Kelly H. Zou, and William M. Wells. \"Simultaneous truth and performance level estimation (STAPLE): an algorithm for the validation of image segmentation.\" IEEE transactions on medical imaging 23.7 (2004): 903-921_\n",
    "- **Majority Voting.** Use majority voting to obtain the reference segmentation. Note that this filter does not resolve ties. In case of ties it will assign the indicated *MV undecided* label to the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Expert Performance Scores\n",
    "\n",
    "**Required Steps:**\n",
    "1. Results Table: Click *Open* and *Update*\n",
    "    - Filter the and sort the results\n",
    "    - Download the results \n",
    "\n",
    "<video src=\"https://user-images.githubusercontent.com/13711052/139746788-3df4f730-da4a-4117-9633-18e7832a24d2.mov\" controls width=\"100%\"></video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
