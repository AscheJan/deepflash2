{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to deepflash2.losses,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> Implements custom loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from fastai.torch_core import TensorImage, TensorMask\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Softmax Cross Entropy Loss\n",
    "\n",
    "as described by Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70.\n",
    "\n",
    "\n",
    "- `axis` for softmax calculations. Defaulted at 1 (channel dimension).\n",
    "- `reduction` will be used when we call `Learner.get_preds`\n",
    "- `activation` function will be applied on the raw output logits of the model when calling `Learner.get_preds` or `Learner.predict`\n",
    "- `decodes` function converts the output of the model to a format similar to the target (here binary masks). This is used in `Learner.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class WeightedSoftmaxCrossEntropy(torch.nn.Module):\n",
    "    \"Weighted Softmax Cross Entropy loss functions\"\n",
    "    def __init__(self, *args, axis=-1, reduction = 'mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, inputs, targets, weights):\n",
    "\n",
    "        # Weighted soft-max cross-entropy loss\n",
    "        loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        loss = loss * weights\n",
    "        if  self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def decodes(self, x): return x.argmax(dim=self.axis)\n",
    "    def activation(self, x): return F.softmax(x, dim=self.axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a segmentation task, we want to take the softmax over the channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = WeightedSoftmaxCrossEntropy(axis=1)\n",
    "output = TensorImage(torch.randn(4, 5, 356, 356, requires_grad=True))\n",
    "targets = TensorMask(torch.ones(4, 356, 356).long())\n",
    "weights = torch.randn(4, 356, 356)\n",
    "loss = tst(output, targets, weights)\n",
    "\n",
    "test_eq(tst.activation(output), F.softmax(output, dim=1))\n",
    "test_eq(tst.decodes(output), output.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
