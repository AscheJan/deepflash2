{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Training\n",
    "\n",
    "> Notebook to train deep learning models or ensembles for segmentation of fluorescent labels in microscopy images.\n",
    "\n",
    "This notebook is optmizied to be executed on [Google Colab](https://colab.research.google.com).\n",
    "\n",
    "* Press the the *play* butten to execute the cells. It will show up between \\[     \\] on the left side of the code cells. \n",
    "* Run the cells consecutively. Skip cells that do not apply for your case.\n",
    "* Use Firefox or Google Chrome if you want to upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@title Set up environment\n",
    "#@markdown Please run this cell to get started.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "    from google.colab import files, drive\n",
    "except ImportError:\n",
    "    pass\n",
    "try:\n",
    "    import deepflash2\n",
    "except ImportError:\n",
    "    !pip install -q deepflash2\n",
    "import zipfile\n",
    "import shutil\n",
    "import imageio\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Provide Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Required data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "__Structure__\n",
    "\n",
    "- __One folder for training images__\n",
    "- __One folder for segmentation masks__\n",
    "\n",
    "_Examplary structure:_\n",
    "\n",
    "* [folder] images\n",
    "  * [file] 0001.tif\n",
    "  * [file] 0002.tif\n",
    "* [folder] masks\n",
    "  * [file] 0001_mask.png\n",
    "  * [file] 0002_mask.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "__Naming__\n",
    "\n",
    "- Images names must have unique ID\n",
    "    - _ID: 0001 -> 0001.tif; ID: img_1 --> img_1.png, ..._ \n",
    "- Masks must start with ID + a mask suffix\n",
    "    - _0001 -> 0001_mask.png (mask_suffix = \"_mask.png\")_\n",
    "    - _0001 -> 0001.png (mask_suffix = \".png\")_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Working on _Google Colab_ (recommended)\n",
    "\n",
    "This section allows you to upload a *zip* folder or connect to your _Google Drive_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Upload _zip_ file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- The *zip* file must contain all images and segmentations and correct folder structure. \n",
    "- See [here](https://www.hellotech.com/guide/for/how-to-zip-a-file-mac-windows-pc) how to _zip_ files on Windows or Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to upload a *zip* file\n",
    "path = Path('data')\n",
    "try:\n",
    "    u_dict = files.upload()\n",
    "    for key in u_dict.keys():\n",
    "        unzip(path, key)\n",
    "    print('Path contains the following files and folders: \\n', L(os.listdir(path)))\n",
    "except:\n",
    "    print(\"Warning: File upload only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Connect to _Google Drive_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- The folder in your drive must contain all segmentations and correct folder structure. \n",
    "- See [here](https://support.google.com/drive/answer/2375091?co=GENIE.Platform%3DDesktop&hl=en) how to organize your files in _Google Drive_.\n",
    "- See this [stackoverflow post](https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory) for browsing files with the file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide the path to the folder on your _Google Drive_\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    path = \"/content/drive/My Drive/data\" #@param {type:\"string\"}\n",
    "    path = Path(path)\n",
    "    print('Path contains the following files and folders: \\n', L(os.listdir(path)))\n",
    "    #@markdown Example: \"/content/drive/My Drive/data\"\n",
    "except:\n",
    "    print(\"Warning: Connecting to Google Drive only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Local Installation\n",
    "\n",
    "If you're working on your local machine or server, provide a path to the correct folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide path (either relative to notebook or absolute) and run cell\n",
    "path = \"data\" #@param {type:\"string\"}\n",
    "path = Path(path)\n",
    "print('Path contains the following files and folders: \\n', L(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Try with sample data\n",
    "\n",
    "If you don't have any data available yet, try our sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to use sample files\n",
    "path = Path('sample_data_cFOS')\n",
    "url = \"https://github.com/matjesg/deepflash2/releases/download/model_library/wue1_cFOS_small.zip\"\n",
    "urllib.request.urlretrieve(url, 'sample_data_cFOS.zip')\n",
    "unzip(path, 'sample_data_cFOS.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Check and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide your parameters according to your provided data\n",
    "image_folder = \"images\" #@param {type:\"string\"}\n",
    "mask_folder = \"masks\" #@param {type:\"string\"}\n",
    "mask_suffix = \"_mask.png\" #@param {type:\"string\"}\n",
    "#@markdown Check if you are providing instance labels (class-aware and instance-aware)\n",
    "instance_labels = False #@param {type:\"boolean\"}\n",
    "\n",
    "f_names = get_image_files(path/image_folder)\n",
    "label_fn = lambda o: path/mask_folder/f'{o.stem}{mask_suffix}'\n",
    "#Check if corresponding masks exist\n",
    "mask_check = [os.path.isfile(label_fn(x)) for x in f_names]\n",
    "if len(f_names)==sum(mask_check) and len(f_names)>0:\n",
    "    print(f'Found {len(f_names)} images and {sum(mask_check)} masks in \"{path}\".')\n",
    "else:\n",
    "    print(f'IMAGE/MASK MISMATCH! Found {len(f_names)} images and {sum(mask_check)} masks in \"{path}\".')\n",
    "    print('Please check the steps above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Set [mask weights](https://matjesg.github.io/deepflash2/data.html#Weight-Calculation) parameters for training.\n",
    "- Default values should work for most of the data. \n",
    "- However, this choice can significantly change the model performance later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to set parameters and load data\n",
    "border_weight_sigma=6 #@param {type:\"number\"}\n",
    "foreground_dist_sigma=1 #@param {type:\"number\"}\n",
    "border_weight_factor=50 #@param {type:\"number\"}\n",
    "foreground_background_ratio=0.1 #@param {type:\"number\"}\n",
    "\n",
    "mw_dict = {'bws': border_weight_sigma,\n",
    "           'fds': foreground_dist_sigma, \n",
    "           'bwf': border_weight_factor,\n",
    "           'fbr' : foreground_background_ratio}\n",
    "\n",
    "#@markdown Number of classes: e.g., 2 for binary segmentation (foreground and background class)\n",
    "n_classes = 2 #@param {type:\"integer\"}\n",
    "ds = RandomTileDataset(f_names, label_fn, n_classes=n_classes, instance_labels=instance_labels, **mw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to show data. { run: \"auto\" }\n",
    "#@markdown Use the slider to control the number of displayed images\n",
    "first_n = 3 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "ds.show_data(max_n = first_n, figsize=(15,15), overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- Select one of the available [model architectures](https://matjesg.github.io/deepflash2/models.html#U-Net-architectures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown { run: \"auto\" }\n",
    "model_arch = 'unet_deepflash2' #@param [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- Select [pretraind](https://matjesg.github.io/deepflash2/) model weights\n",
    "    - See here for data description\n",
    "    - Select 'new' to use an untrained model (no pretrained weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "pretrained_weights = \"new\" #@param [\"new\", \"cFOS\", \"Parv\"]\n",
    "pre = False if pretrained_weights==\"new\" else True\n",
    "n_channels = ds.get_data(max_n=1)[0].shape[-1]\n",
    "model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=pre, n_classes=ds.c, in_channels=n_channels)\n",
    "if pretrained_weights==\"new\": apply_init(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Setting training paramers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *mixed_precision_training*: enables [Mixed precision training](https://docs.fast.ai/callback.fp16#A-little-bit-of-theory)\n",
    "    - decreases memory usage and speed-up training\n",
    "    - may effect model accuracy\n",
    "- *batch_size*: the number of samples that will be propagated through the network during one iteration\n",
    "    - 4 works best in our experiements\n",
    "    - 4-8 works good for [mixed precision training](https://docs.fast.ai/callback.fp16#A-little-bit-of-theory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to setup model for training.\n",
    "mixed_precision_training = False #@param {type:\"boolean\"}\n",
    "batch_size = 4 #@param {type:\"slider\", min:2, max:8, step:2}\n",
    "cbs = [SaveModelCallback(monitor='iou'), ElasticDeformCallback]\n",
    "metrics = [Dice_f1(), Iou()]\n",
    "loss_fn = WeightedSoftmaxCrossEntropy(axis=1)\n",
    "dls = DataLoaders.from_dsets(ds,ds, bs=batch_size)\n",
    "if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "learn = Learner(dls, model, metrics = metrics, wd=0.001, loss_func=loss_fn, cbs=cbs)\n",
    "if mixed_precision_training: learn.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- **Learning rate**: controls how quickly or slowly a neural network model learns. <br>\n",
    "We need to set the __maximum learning rate__ `max_lr` when traing with the **[One-Cycle-Policy](https://fastai1.fast.ai/callbacks.one_cycle.html#The-1cycle-policy)**. Using the **Learning Rate Finder** below, a good value for `max_lr` is somthing in the range of:\n",
    "    - one tenth of the minimum before the divergence (_Minimum/10_)\n",
    "    - when the slope is the steepest (_steepest point_) \n",
    "    - In our experiments, we found that a **maximum learning rate of 5e-4** (e.g., 0.0005) yielded the best results across experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to a find suitable learning rate\n",
    "lr_min,lr_steep = learn.lr_find()\n",
    "print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *n_models*: Number of models to train.\n",
    "    - If you're experimenting with parameters, try only one model first.\n",
    "    - Depending on the data, ensembles should comprise 3-5 models.\n",
    "    - Effects train-validation-split:\n",
    "        - `n_models = 1` leads to a train-validation-split of 0.75/0.25\n",
    "        - `n_models > 1` (model ensembles) to _[k-fold cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)_\n",
    "- *epochs*: One epoch is when an entire (augemented) dataset is passed through the model for training.\n",
    "    - Epochs need to be adusted depending on the size and number of images\n",
    "    - We found that choosing the number of epochs such that the network parameters are update about 1000 times (iterations) leads to satiesfying results in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@title Set training paramers { run: \"auto\" }\n",
    "#@markdown Set `max_lr` according to the learning rate finder.\n",
    "max_lr = 5e-4 #@param {type:\"number\"}\n",
    "#@markdown \n",
    "n_models = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
    "epochs = 30 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "print(\"Suggested epochs for 1000 iterations:\", calc_iterations(len(ds), batch_size, n_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to train model(s).<br/> **THIS CAN TAKE A FEW HOURS FOR MULTIPLE MODELS!**\n",
    "kf = KFold(n_splits=max(n_models,2))\n",
    "model_path = path/'models'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "res, res_mc = {}, {}\n",
    "fold = 0\n",
    "for train_idx, val_idx in kf.split(f_names):\n",
    "    fold += 1\n",
    "    name = f'model{fold}'\n",
    "    print('Train', name)\n",
    "    if n_models==1:\n",
    "        files_train, files_val = train_test_split(f_names)\n",
    "    else:\n",
    "        files_train, files_val = f_names[train_idx], f_names[val_idx]\n",
    "    print(f'Validation Images: {files_val}')    \n",
    "    train_ds = RandomTileDataset(files_train, label_fn, **mw_dict)\n",
    "    valid_ds = TileDataset(files_val, label_fn, **mw_dict)\n",
    "    \n",
    "    dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=batch_size)\n",
    "    dls_valid = DataLoaders.from_dsets(valid_ds, batch_size=batch_size ,shuffle=False, drop_last=False)\n",
    "    model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=pre, n_classes=ds.c, in_channels=n_channels)\n",
    "    if pretrained_weights==\"new\": apply_init(model)\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda(), dls_valid.cuda()\n",
    "        \n",
    "    learn = Learner(dls, model, metrics = metrics, wd=0.001, loss_func=loss_fn, cbs=cbs)\n",
    "    if mixed_precision_training: learn.to_fp16()\n",
    "    learn.fit_one_cycle(epochs, max_lr)\n",
    "    # save_model(model_path/f'{name}.pth', learn.model, opt=None)\n",
    "    torch.save(learn.model.state_dict(), model_path/f'{name}.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    smxs, segs, _ = learn.predict_tiles(dl=dls_valid.train)    \n",
    "    smxs_mc, segs_mc, std = learn.predict_tiles(dl=dls_valid.train, mc_dropout=True, n_times=10)\n",
    "    \n",
    "    for i, file in enumerate(files_val):\n",
    "        res[(name, file)] = smxs[i], segs[i]\n",
    "        res_mc[(name, file)] = smxs_mc[i], segs_mc[i], std[i]\n",
    "    \n",
    "    if n_models==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Validate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here you can validate your models. To avoid information leakage, only predictions on the respective models' validation set are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Create folders to save the resuls. They will be created at your provided 'path'.\n",
    "pred_dir = 'val_preds' #@param {type:\"string\"}\n",
    "pred_path = path/pred_dir/'ensemble'\n",
    "pred_path.mkdir(parents=True, exist_ok=True)\n",
    "uncertainty_dir = 'val_uncertainties' #@param {type:\"string\"}\n",
    "uncertainty_path = path/uncertainty_dir/'ensemble'\n",
    "uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "result_path = path/'results'\n",
    "result_path.mkdir(exist_ok=True)\n",
    "\n",
    "#@markdown Define `filetype` to save the predictions and uncertainties. All common filetypes are supported.\n",
    "filetype = 'png' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Show and save results\n",
    "res_list = []\n",
    "for model_number in range(1,n_models+1):\n",
    "    model_name = f'model{model_number}'\n",
    "    val_files = [f for mod , f in res.keys() if mod == model_name]\n",
    "    print(f'Validating {model_name}')\n",
    "    pred_path = path/pred_dir/model_name\n",
    "    pred_path.mkdir(parents=True, exist_ok=True)\n",
    "    uncertainty_path = path/uncertainty_dir/model_name\n",
    "    uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "    for file in val_files:\n",
    "        img = ds.get_data(file)[0]\n",
    "        msk = ds.get_data(file, mask=True)[0]\n",
    "        pred = res[(model_name,file)][1]\n",
    "        pred_std = res_mc[(model_name,file)][2][...,0]\n",
    "        df_tmp = pd.Series({'file' : file.name,\n",
    "                            'model' : model_name,\n",
    "                            'iou': iou(msk, pred),\n",
    "                            'entropy': mean_entropy(pred_std)})\n",
    "        plot_results(img, msk, pred, pred_std, df=df_tmp)\n",
    "        res_list.append(df_tmp)\n",
    "        imageio.imsave(pred_path/f'{file.stem}_pred.{filetype}', pred.astype(np.uint8) if np.max(pred)>1 else pred.astype(np.uint8)*255)\n",
    "        imageio.imsave(uncertainty_path/f'{file.stem}_uncertainty.{filetype}', pred_std.astype(np.uint8)*255)\n",
    "df_res = pd.DataFrame(res_list)\n",
    "df_res.to_csv(result_path/f'val_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Download Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- The models will always be the _last_ version trained in Section _Model Training_\n",
    "- To download validation predictions and uncertainties, you first need to execute Section _Validate models_.\n",
    "\n",
    "_Note: If you're connected to *Google Drive*, the models are automatically saved to your drive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@title Download models { run: \"auto\" }\n",
    "model_number = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "model_path = path/'models'/f'model{model_number}.pth'\n",
    "try:\n",
    "    files.download(model_path)\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    print(f\"Models are saved at {model_path.parent}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Download validation predicitions { run: \"auto\" }\n",
    "out_name = 'val_predictions'\n",
    "shutil.make_archive(path/out_name, 'zip', path/pred_dir)\n",
    "try:\n",
    "    files.download(path/f'{out_name}.zip')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Download validation uncertainties\n",
    "out_name = 'val_uncertainties'\n",
    "shutil.make_archive(path/out_name, 'zip', path/uncertainty_dir)\n",
    "try:\n",
    "    files.download(path/f'{out_name}.zip')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@markdown Download result analysis '.csv' files\n",
    "try:\n",
    "    files.download(result_path/f'val_results.csv')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
