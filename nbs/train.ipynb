{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLGLpdTsS5j4"
   },
   "source": [
    "# Training\n",
    "\n",
    "> Notebook to train deep learning models or ensembles for segmentation of fluorescent labels in microscopy images.\n",
    "\n",
    "This notebook is optmizied to be executed on [Google Colab](https://colab.research.google.com).\n",
    "\n",
    "* Press the the *play* butten to execute the cells. It will show up between \\[     \\] on the left side of the code cells. \n",
    "* Run the cells consecutively. Skip cells that do not apply for your case.\n",
    "* Use Firefox or Google Chrome if you want to upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "UCPo3P9Mc_c0"
   },
   "outputs": [],
   "source": [
    "#@title Set up environment\n",
    "#@markdown Please run this cell to get started.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "    from google.colab import files, drive\n",
    "except ImportError:\n",
    "    pass\n",
    "try:\n",
    "    import deepflash2\n",
    "except ImportError:\n",
    "    !pip install -q deepflash2\n",
    "import zipfile\n",
    "import imageio\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9wlAXK_Jyi-"
   },
   "source": [
    "## Provide Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clWB59N8Zk8s"
   },
   "source": [
    "### Required data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3WZ1VCcS5j-"
   },
   "source": [
    "__Structure__\n",
    "\n",
    "- __One folder for training images__\n",
    "- __One folder for segmentation masks__\n",
    "\n",
    "_Examplary structure:_\n",
    "\n",
    "* [folder] images\n",
    "  * [file] 0001.tif\n",
    "  * [file] 0002.tif\n",
    "* [folder] masks\n",
    "  * [file] 0001_mask.png\n",
    "  * [file] 0002_mask.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BygggFpbS5j-"
   },
   "source": [
    "__Naming__\n",
    "\n",
    "- Images names must have unique ID\n",
    "    - _ID: 0001 -> 0001.tif; ID: img_1 --> img_1.png, ..._ \n",
    "- Masks must start with ID + a mask suffix\n",
    "    - _0001 -> 0001_mask.png (mask_suffix = \"_mask.png\")_\n",
    "    - _0001 -> 0001.png (mask_suffix = \".png\")_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6N2l7iwKS5kC"
   },
   "source": [
    "### Colab (recommended)\n",
    "\n",
    "Working on _Google Colab_, this section allows you to upload a *zip* folder or connect to your _Google Drive_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVp4DPKhS5kD"
   },
   "source": [
    "#### Upload _zip_ file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D79dVnZCS5kE"
   },
   "source": [
    "- The *zip* file must contain all images and segmentations and correct folder structure. \n",
    "- See [here](https://www.hellotech.com/guide/for/how-to-zip-a-file-mac-windows-pc) how to _zip_ files on Windows or Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "sRy0RczvS5kE"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to upload a *zip* file\n",
    "path = Path('data')\n",
    "try:\n",
    "    u_dict = files.upload()\n",
    "    for key in u_dict.keys():\n",
    "        zip_ref = zipfile.ZipFile(key, 'r')\n",
    "        zip_ref.extractall(path)\n",
    "        zip_ref.close()\n",
    "except:\n",
    "    print(\"Warning: File upload only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzcbrplVS5kI"
   },
   "source": [
    "#### Connect to _Google Drive_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91EFXlyoS5kJ"
   },
   "source": [
    "- The folder in your drive must contain all segmentations and correct folder structure. \n",
    "- See [here](https://support.google.com/drive/answer/2375091?co=GENIE.Platform%3DDesktop&hl=en) how to organize your files in _Google Drive_.\n",
    "- See this [stackoverflow post](https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory) for browsing files with the file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "O6lfPNKpS5kJ"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide the path to the folder on your _Google Drive_\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    path = \"/content/drive/My Drive/data\" #@param {type:\"string\"}\n",
    "    path = Path(path)\n",
    "    #@markdown Example: \"/content/drive/My Drive/data\"\n",
    "except:\n",
    "    print(\"Warning: Connecting to Google Drive only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AGszSKbS5kN"
   },
   "source": [
    "### Local Installation\n",
    "\n",
    "If you're working on your local machine or server, provide a path to the correct folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "ESNlJm2kS5kO"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide path (either relative to notebook or absolute) and run cell\n",
    "path = \"my_data\" #@param {type:\"string\"}\n",
    "path = Path(path)\n",
    "#@markdown Example: \"expert_segmentations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XMQn_yjoS5kR"
   },
   "source": [
    "### Try with sample data\n",
    "\n",
    "If you don't have any data available yet, try our sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "wHQ42LVoS5kS"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to use sample files\n",
    "path = Path('sample_data_train')\n",
    "url = \"https://github.com/matjesg/deepflash2/releases/download/model_library/wue1_cFOS_small.zip\"\n",
    "urllib.request.urlretrieve(url, 'sample_data.zip');\n",
    "zip_ref = zipfile.ZipFile('sample_data.zip', 'r')\n",
    "zip_ref.extractall(path)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjwAPPQGS5kV"
   },
   "source": [
    "## Check and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "QQbfeBWrS5j_"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide your parameters according to your provided data\n",
    "image_folder = \"images\" #@param {type:\"string\"}\n",
    "mask_folder = \"masks\" #@param {type:\"string\"}\n",
    "mask_suffix = \"_cFOS.png\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_J52V56X4Aq"
   },
   "source": [
    "Set [mask weights](https://matjesg.github.io/deepflash2/data.html#Weight-Calculation) parameters for training.\n",
    "- Default values should work for most of the data. \n",
    "- However, this choice can significantly change the model performance later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "JdZ6ydGkXQJG"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to set mask weight parameters\n",
    "border_weight_sigma=6 #@param {type:\"number\"}\n",
    "foreground_dist_sigma=1 #@param {type:\"number\"}\n",
    "border_weight_factor=10 #@param {type:\"number\"}\n",
    "foreground_background_ratio=0.1 #@param {type:\"number\"}\n",
    "\n",
    "mw_dict = {'bws': border_weight_sigma,\n",
    "           'fds': foreground_dist_sigma, \n",
    "           'bwf': border_weight_factor,\n",
    "           'fbr' : foreground_background_ratio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "TlLkfS6NS5kW"
   },
   "outputs": [],
   "source": [
    "#@markdown **Check and load data**\n",
    "files = get_image_files(path/image_folder)\n",
    "label_fn = lambda o: path/mask_folder/f'{o.stem}{mask_suffix}'\n",
    "#Check if corresponding masks exist\n",
    "mask_check = [os.path.isfile(label_fn(x)) for x in files]\n",
    "if len(files)==sum(mask_check):\n",
    "    print(f'Found {len(files)} images and {sum(mask_check)} masks on path {path}.')\n",
    "    #@markdown Number of classes: e.g., 2 for binary segmentation (foreground and background class)\n",
    "    n_classes = 2 #@param {type:\"integer\"}\n",
    "    #@markdown Check if you are providing instance labels (class-aware and instance-aware)\n",
    "    instance_labels = False #@param {type:\"boolean\"}\n",
    "    ds = RandomTileDataset(files, label_fn, n_classes=n_classes, instance_labels=instance_labels)\n",
    "else:\n",
    "    print(f'IMAGE/MASK MISMATCH! Found {len(files)} images and {sum(mask_check)} masks on path {path}.')\n",
    "    print('Please check the steps above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "2GB0qe2SS5kZ"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to show data. { run: \"auto\" }\n",
    "#@markdown Use the slider to control the number of displayed images\n",
    "first_n = 6 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "ds.show_data(first_n, figsize=(15,15), overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_LKDIG1J6IG"
   },
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-23VM-VOU58h"
   },
   "source": [
    "Select model [model architecture](https://matjesg.github.io/deepflash2/models.html#U-Net-architectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "HLLvxwI-MWJ5"
   },
   "outputs": [],
   "source": [
    "#@markdown { run: \"auto\" }\n",
    "model_arch = 'unet_deepflash2' #@param [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iukNXADdaK--"
   },
   "source": [
    "Select [pretraind](https://matjesg.github.io/deepflash2/) model weights\n",
    "- See here for data description\n",
    "- Select 'new' to use an untrained model (no pretrained weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "odOH2JfmWYy5"
   },
   "outputs": [],
   "source": [
    "pretrained_weights = \"new\" #@param [\"new\", \"cFOS\", \"Parv\"]\n",
    "pre = False if pretrained_weights==\"new\" else True\n",
    "n_channels = ds.get_data(max_n=1)[0].shape[-1]\n",
    "model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=pre, n_classes=ds.c, in_channels=n_channels)\n",
    "if pretrained_weights==\"new\": apply_init(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiTNnpaXS5kh"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "J5VwPuAcS5ki"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to setup model for training.\n",
    "cbs = [SaveModelCallback(monitor='iou'), ElasticDeformCallback]\n",
    "metrics = [Dice_f1(), Iou()]\n",
    "loss_fn = WeightedSoftmaxCrossEntropy(axis=1)\n",
    "dls = DataLoaders.from_dsets(ds,ds, bs=4)\n",
    "if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "learn = Learner(dls, model, metrics = metrics, wd=0.001, loss_func=loss_fn, cbs=cbs)#.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBmlaZ1La6fO"
   },
   "source": [
    "### Setting training paramers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deFHf5y_S5kl"
   },
   "source": [
    "**Finding a good learning rate**\n",
    "\n",
    "According to the [fastai docs](https://docs.fast.ai/callback.schedule#LRFinder), a good value for the learning rates is then either :\n",
    "\n",
    "- one tenth of the minimum before the divergence\n",
    "- when the slope is the steepest\n",
    "\n",
    "In our experiments, we found that a **maximum learning rate of 5e-4** (e.g., 0.0005) yielded the best results across experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "OjkbRta8S5kl"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to a find suitable learning rate\n",
    "lr_min,lr_steep = learn.lr_find()\n",
    "print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "7Op0Kf5FS5ko"
   },
   "outputs": [],
   "source": [
    "#@title Set training paramers { run: \"auto\" }\n",
    "#@markdown Set `max_lr` according to the learning rate finder.\n",
    "max_lr = 5e-4 #@param {type:\"number\"}\n",
    "#@markdown Number of models to train. If you're experimenting with parameters, try only one model first.\n",
    "n_models = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
    "#@markdown One epoch is when an entire (augemented) dataset is passed through the model for training.\n",
    "#@markdown We found that about 30 epochs is sufficient to train a model with 36 images. \n",
    "#@markdown Select more epochs for smaller datasets.\n",
    "epochs = 30 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j61fhLNXdaKr"
   },
   "source": [
    "### Train models\n",
    "- Using a train-test-split of 0.75/0.25 for one model\n",
    "- Using _k-fold cross validation_ for model ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "TzbD9ht_S5kr"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to train model(s).<br/> **THIS CAN TAKE A FEW HOURS FOR MULTIPLE MODELS!**\n",
    "kf = KFold(n_splits=max(n_models,2))\n",
    "model_path = path/'models'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "res, res_mc = {}, {}\n",
    "fold = 0\n",
    "for train_idx, val_idx in kf.split(files):\n",
    "    fold += 1\n",
    "    name = f'model{fold}'\n",
    "    print('Train', name)\n",
    "    if n_models==2:\n",
    "        files_train, files_val = train_test_split(files)\n",
    "    else:\n",
    "        files_train, files_val = files[train_idx], files[val_idx]\n",
    "        \n",
    "    train_ds = RandomTileDataset(files_train, label_fn)\n",
    "    valid_ds = TileDataset(files_val, label_fn)\n",
    "    \n",
    "    dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=batch_size)\n",
    "    dls_valid = DataLoaders.from_dsets(valid_ds, batch_size=batch_size ,shuffle=False, drop_last=False)\n",
    "    model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=pre, n_classes=ds.c, in_channels=n_channels)\n",
    "    if pretrained_weights==\"new\": apply_init(model)\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda(), dls_valid.cuda()\n",
    "        \n",
    "    learn = Learner(dls, model, metrics = metrics, wd=0.001, loss_func=loss_fn, cbs=cbs)\n",
    "    learn.fit_one_cycle(epochs, max_lr)\n",
    "    save_model(model_path/f'{name}.pth', learn.model, opt=None)\n",
    "    \n",
    "    smxs, segs, _ = learn.predict_tiles(dl=dls_valid.train)    \n",
    "    smxs_mc, segs_mc, std = learn.predict_tiles(dl=dls_valid.train, mc_dropout=True, n_times=10)\n",
    "    \n",
    "    for i, file in enumerate(files_val):\n",
    "        res[(name, file)] = smxs[i], segs[i]\n",
    "        res_mc[(name, file)] = smxs_mc[i], segs_mc[i], std[i]\n",
    "    \n",
    "    if n_models==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NflzHRpDS5ky"
   },
   "source": [
    "## Validate models and ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8thTXrQWemf6"
   },
   "source": [
    "Here you can validate your results. \n",
    "If you choose to only train one model (`n_models = 1`), ensemble and model results will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "vedhyuN1gHpF"
   },
   "outputs": [],
   "source": [
    "#@markdown Create folders to save the resuls. They will be created at your provided 'path'.\n",
    "pred_dir = 'val_preds' #@param {type:\"string\"}\n",
    "pred_path = path/pred_dir/'ensemble'\n",
    "pred_path.mkdir(parents=True, exist_ok=True)\n",
    "uncertainty_dir = 'val_uncertainties' #@param {type:\"string\"}\n",
    "uncertainty_path = path/uncertainty_dir/'ensemble'\n",
    "uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#@markdown Define `filetype` to save the predictions and uncertainties. All common filetypes are supported.\n",
    "filetype = 'png' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "l03-5jkuS5k0"
   },
   "outputs": [],
   "source": [
    "#@markdown Show and save ensemble results\n",
    "val_files = set([f for _, f in res.keys()])\n",
    "res_list = []\n",
    "for file in val_files:\n",
    "    img = ds.get_data(file)[0]\n",
    "    msk = ds.get_data(file, mask=True)[0]\n",
    "    pred = ensemble_results(res, file)\n",
    "    pred_std = ensemble_results(res_mc, file, idx=2)\n",
    "    df_tmp = pd.Series({'file' : file.name, 'iou': iou(msk, pred) ,'entropy': mean_entropy(pred_std)})\n",
    "    plot_results(img, msk, pred, pred_std, df=df_tmp)\n",
    "    res_list.append(df_tmp)\n",
    "    imageio.imsave(pred_path/f'{file.name}_pred.{filetype}', pred.astype(np.uint8) if np.max(pred)>1 else pred.astype(np.uint8)*255)\n",
    "    imageio.imsave(uncertainty_path/f'{file.name}_uncertainty.{filetype}', pred_std.astype(np.uint8)*255)\n",
    "df_res = pd.DataFrame(res_list)\n",
    "df_res.to_csv(path/'val_ensemble_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "cJMiFDu9S5k3"
   },
   "outputs": [],
   "source": [
    "#@markdown Show and save (single) model results { run: \"auto\" }\n",
    "model_number = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
    "model_name = f'model{model_number}'\n",
    "val_files = [f for mod , f in res.keys() if mod == model_name]\n",
    "pred_path = path/pred_dir/model_name\n",
    "uncertainty_path = path/uncertainty_dir/model_name\n",
    "uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "res_list = []\n",
    "for file in val_files:\n",
    "    img = ds.get_data(file)[0]\n",
    "    msk = ds.get_data(file, mask=True)[0]\n",
    "    pred = res[(model_name,file)][1]\n",
    "    pred_std = res_mc[(model_name,file)][2][...,0]\n",
    "    df_tmp = pd.Series({'file' : file.name, 'iou': iou(msk, pred) ,'entropy': mean_entropy(pred_std)})\n",
    "    plot_results(img, msk, pred, pred_std, df=df_tmp)\n",
    "    res_list.append(df_tmp)\n",
    "    imageio.imsave(pred_path/f'{file.name}_pred.{filetype}', pred.astype(np.uint8) if np.max(pred)>1 else pred.astype(np.uint8)*255)\n",
    "    imageio.imsave(uncertainty_path/f'{file.name}_uncertainty.{filetype}', pred_std.astype(np.uint8)*255)\n",
    "df_res = pd.DataFrame(res_list)\n",
    "df_res.to_csv(path/f'val_{model_name}_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GaOYNFfS5k6"
   },
   "source": [
    "## Download Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2DgHeLjS5k7"
   },
   "source": [
    "- The models will always be the _last_ version trained in Section _Model Training_\n",
    "- To download validation predictions and uncertainties, you first need to execute Section _Validate models and ensembles_.\n",
    "\n",
    "_Note: If you're connected to *Google Drive*, the models are automatically saved to your drive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "-CiMb-mRS5k7"
   },
   "outputs": [],
   "source": [
    "#@title Download models { run: \"auto\" }\n",
    "model_number = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "model_path = path/'models'/f'model{model_number}.pth'\n",
    "try:\n",
    "    files.download(model_path)\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    print(f\"Models are saved at {model_path.parent}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "R35PVNmZS5k_"
   },
   "outputs": [],
   "source": [
    "#@markdown Download validation predicitions { run: \"auto\" }\n",
    "zipObj = zipfile.ZipFile('val_predictions.zip', 'w')\n",
    "for f in get_image_files(path/pred_dir):\n",
    "      zipObj.write(f)\n",
    "zipObj.close()\n",
    "try:\n",
    "    files.download(model_path)\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "JSvZW6ByS5lD"
   },
   "outputs": [],
   "source": [
    "#@markdown Download validation uncertainties\n",
    "zipObj = zipfile.ZipFile('val_uncertainties.zip', 'w')\n",
    "for f in get_image_files(path/uncertainty_dir):\n",
    "      zipObj.write(f)\n",
    "zipObj.close()\n",
    "try:\n",
    "    files.download(model_path)\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "2xxJ65H3S5lH"
   },
   "outputs": [],
   "source": [
    "#@markdown Download result analysis '.csv' files\n",
    "zipObj = zipfile.ZipFile('val_results.zip', 'w')\n",
    "for f in get_files(path, extensions='.csv'):\n",
    "      zipObj.write(f)\n",
    "zipObj.close()\n",
    "try:\n",
    "    files.download(model_path)\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
