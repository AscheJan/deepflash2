{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to deepflash2.utils,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "\n",
    "> Utility functions for deepflash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import jaccard\n",
    "from scipy.stats import entropy\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from skimage.morphology import watershed\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def unzip(path, zip_file):\n",
    "    \"Unzip and structure archive\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zf:\n",
    "        f_names = [x for x in zf.namelist() if '__MACOSX' not in x and not x.endswith('/')]\n",
    "        new_root = np.max([len(Path(f).parts) for f in f_names])-2\n",
    "        for f in f_names:\n",
    "            f_path = path / Path(*Path(f).parts[new_root:])\n",
    "            f_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            data = zf.read(f)\n",
    "            f_path.write_bytes(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def ensemble_results(res_dict, file, std=False):\n",
    "    \"Combines single model predictions.\"\n",
    "    idx = 2 if std else 0\n",
    "    a = [np.array(res_dict[(mod, f)][idx]) for mod, f in res_dict if f==file]\n",
    "    a = np.mean(a, axis=0)\n",
    "    if std:\n",
    "        a = a[...,0]\n",
    "    else:\n",
    "        a = np.argmax(a, axis=-1) \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def plot_results(*args, df, figsize=(20, 20), **kwargs):\n",
    "    \"Plot images, (masks), predictions and uncertainties side-by-side.\"\n",
    "    if len(args)==4:\n",
    "        img, msk, pred, pred_std = args\n",
    "    if len(args)==3:\n",
    "        img, pred, pred_std = args\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(args), figsize=figsize, **kwargs)\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_axis_off()\n",
    "    axs[0].set_title(f'File {df.file}')\n",
    "    if len(args)==4: \n",
    "        axs[1].imshow(msk)\n",
    "        axs[1].set_axis_off()\n",
    "        axs[1].set_title('Target')\n",
    "        axs[2].imshow(pred)\n",
    "        axs[2].set_axis_off()\n",
    "        axs[2].set_title(f'Prediction \\n IoU: {df.iou:.2f}')\n",
    "        axs[3].imshow(pred_std)\n",
    "        axs[3].set_axis_off()\n",
    "        axs[3].set_title(f'Uncertainty \\n Entropy: {df.entropy:.2f}')\n",
    "    if len(args)==3: \n",
    "        axs[1].imshow(pred)\n",
    "        axs[1].set_axis_off()\n",
    "        axs[1].set_title('Prediction')\n",
    "        axs[2].imshow(pred_std)\n",
    "        axs[2].set_axis_off()\n",
    "        axs[2].set_title(f'Uncertainty \\n Entropy: {df.entropy:.2f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixelwise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def iou(a,b,threshold=0.5):\n",
    "    '''Computes the Intersection-Over-Union metric.'''\n",
    "    a = np.array(a) > threshold\n",
    "    b = np.array(b) > threshold\n",
    "    overlap = a*b # Logical AND\n",
    "    union = a+b # Logical OR\n",
    "    return np.count_nonzero(overlap)/np.count_nonzero(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def mean_entropy(a):\n",
    "    '''Computes the mean entropy.'''\n",
    "    return entropy(a).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI-wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def label_mask(mask, threshold=0.5, min_pixel=15, do_watershed=True, exclude_border=False):\n",
    "    '''Analyze regions and return labels'''\n",
    "    if mask.ndim == 3:\n",
    "        mask = np.squeeze(mask, axis=2)\n",
    "\n",
    "    # apply threshold to mask\n",
    "    # bw = closing(mask > threshold, square(2))\n",
    "    bw = (mask > threshold).astype(int)\n",
    "\n",
    "    # label image regions\n",
    "    label_image = label(bw, connectivity=2) # Falk p.13, 8-“connectivity”.\n",
    "\n",
    "    # Watershed: Separates objects in image by generate the markers\n",
    "    # as local maxima of the distance to the background\n",
    "    if do_watershed:\n",
    "        distance = ndimage.distance_transform_edt(bw)\n",
    "        # Minimum number of pixels separating peaks in a region of `2 * min_distance + 1`\n",
    "        # (i.e. peaks are separated by at least `min_distance`)\n",
    "        min_distance = int(np.ceil(np.sqrt(min_pixel / np.pi)))\n",
    "        local_maxi = peak_local_max(distance, indices=False, exclude_border=False,\n",
    "                                    min_distance=min_distance, labels=label_image)\n",
    "        markers = label(local_maxi)\n",
    "        label_image = watershed(-distance, markers, mask=bw)\n",
    "\n",
    "    # remove artifacts connected to image border\n",
    "    if exclude_border:\n",
    "        label_image = clear_border(label_image)\n",
    "\n",
    "    # remove areas < min pixel\n",
    "    unique, counts = np.unique(label_image, return_counts=True)\n",
    "    label_image[np.isin(label_image, unique[counts<min_pixel])] = 0\n",
    "\n",
    "    # re-label image\n",
    "    label_image, _ , _ = relabel_sequential(label_image, offset=1)\n",
    "\n",
    "    return (label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def get_candidates(labels_a, labels_b):\n",
    "    '''Get candiate masks for ROI-wise analysis'''\n",
    "\n",
    "    label_stack = np.dstack((labels_a, labels_b))\n",
    "    cadidates = np.unique(label_stack.reshape(-1, label_stack.shape[2]), axis=0)\n",
    "    # Remove Zero Entries\n",
    "    cadidates = cadidates[np.prod(cadidates, axis=1) > 0]\n",
    "    return(cadidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def iou_mapping(labels_a, labels_b, min_roi_size=30):\n",
    "    '''Compare masks using ROI-wise analysis'''\n",
    "\n",
    "    candidates = get_candidates(labels_a, labels_b)\n",
    "\n",
    "    if candidates.size > 0:\n",
    "        # create a similarity matrix\n",
    "        dim_a = np.max(candidates[:,0])+1\n",
    "        dim_b = np.max(candidates[:,1])+1\n",
    "        similarity_matrix = np.zeros((dim_a, dim_b))\n",
    "\n",
    "        for x,y in candidates:\n",
    "            roi_a = (labels_a == x).astype(np.uint8).flatten()\n",
    "            roi_b = (labels_b == y).astype(np.uint8).flatten()\n",
    "            similarity_matrix[x,y] = 1-jaccard(roi_a, roi_b)\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(-similarity_matrix)\n",
    "\n",
    "        return(similarity_matrix[row_ind,col_ind],\n",
    "               row_ind, col_ind,\n",
    "               np.max(labels_a),\n",
    "               np.max(labels_b)\n",
    "               )\n",
    "    else:\n",
    "        return([],\n",
    "               np.nan, np.nan,\n",
    "               np.max(labels_a),\n",
    "               np.max(labels_b)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ground Truth Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAPLE: Simultaneous Truth and Performance Level Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def staple(segmentations, foregroundValue = 1, threshold = 0.5):\n",
    "    'STAPLE: Simultaneous Truth and Performance Level Estimation with simple ITK'\n",
    "\n",
    "    segmentations = [sitk.GetImageFromArray(x) for x in segmentations]\n",
    "    STAPLE_probabilities = sitk.STAPLE(segmentations)\n",
    "    STAPLE = STAPLE_probabilities > threshold\n",
    "    return sitk.GetArrayViewFromImage(STAPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def mvoting(segmentations, labelForUndecidedPixels = 0):\n",
    "    'Majority Voting from  simple ITK Label Voting'\n",
    "\n",
    "    segmentations = [sitk.GetImageFromArray(x) for x in segmentations]\n",
    "    mv_segmentation = sitk.LabelVoting(segmentations, labelForUndecidedPixels)\n",
    "    return sitk.GetArrayViewFromImage(mv_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
