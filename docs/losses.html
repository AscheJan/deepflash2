---

title: Losses


keywords: fastai
sidebar: home_sidebar

summary: "Implements custom loss functions."
description: "Implements custom loss functions."
nb_path: "nbs/05_losses.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_losses.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Weighted-Softmax-Cross-Entropy-Loss">Weighted Softmax Cross Entropy Loss<a class="anchor-link" href="#Weighted-Softmax-Cross-Entropy-Loss"> </a></h2><p>as described by Falk, Thorsten, et al. "U-Net: deep learning for cell counting, detection, and morphometry." Nature methods 16.1 (2019): 67-70.</p>
<ul>
<li><code>axis</code> for softmax calculations. Defaulted at 1 (channel dimension).</li>
<li><code>reduction</code> will be used when we call <code>Learner.get_preds</code></li>
<li><code>activation</code> function will be applied on the raw output logits of the model when calling <code>Learner.get_preds</code> or <code>Learner.predict</code></li>
<li><code>decodes</code> function converts the output of the model to a format similar to the target (here binary masks). This is used in <code>Learner.predict</code></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="WeightedSoftmaxCrossEntropy" class="doc_header"><code>class</code> <code>WeightedSoftmaxCrossEntropy</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/losses.py#L11" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>WeightedSoftmaxCrossEntropy</code>(<strong>*<code>args</code></strong>, <strong><code>axis</code></strong>=<em><code>-1</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Weighted Softmax Cross Entropy loss functions</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In a segmentation task, we want to take the softmax over the channel dimension</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tst</span> <span class="o">=</span> <span class="n">WeightedSoftmaxCrossEntropy</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">TensorImage</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">356</span><span class="p">,</span> <span class="mi">356</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">TensorMask</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">356</span><span class="p">,</span> <span class="mi">356</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">356</span><span class="p">,</span> <span class="mi">356</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tst</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">tst</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">tst</span><span class="o">.</span><span class="n">decodes</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorBase(-0.0024, grad_fn=&lt;AliasBackward&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

