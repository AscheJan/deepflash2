{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_gleason.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matjesg/deepflash2/blob/master/paper/challenge_data/preprocess_gleason.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing for the Gleason 2019 Challenge Dataset\n",
        "\n",
        "\n",
        "![Gleason Logo](https://rumc-gcorg-p-public.s3.amazonaws.com/i/2020/01/21/550cece0.png)\n",
        "\n",
        "**References:** \n",
        "\n",
        "- Nir G, Hor S, Karimi D, Fazli L, Skinnider BF, Tavassoli P, Turbin D, Villamil CF, Wang G, Wilson RS, Iczkowski KA. Automatic grading of prostate cancer in digitized histopathology images: Learning from multiple experts. Medical image analysis. 2018 Dec 1;50:167-80.\n",
        "\n",
        "- Karimi D, Nir G, Fazli L, Black PC, Goldenberg L, Salcudean SE. Deep Learning-Based Gleason Grading of Prostate Cancer From Histopathology Imagesâ€”Role of Multiscale Decision Aggregation and Data Augmentation. IEEE journal of biomedical and health informatics. 2019 Sep 30;24(5):1413-26.\n",
        "\n",
        "See https://gleason2019.grand-challenge.org/ for more information.\n"
      ],
      "metadata": {
        "id": "hOGFyya-3lIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Download and extract data"
      ],
      "metadata": {
        "id": "aar5O1iV4iG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data with labels\n",
        "!wget -O train.zip https://m209.syncusercontent.com/zip/00ba920b1d8700367e5a42f336a954de/Train%20Imgs.zip?linkcachekey=2312d2d50&pid=00ba920b1d8700367e5a42f336a954de&jid=56108426\n",
        "!mkdir train && unzip -qju train.zip -d train/images"
      ],
      "metadata": {
        "id": "VaYFRTDQVj1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expert segmentations\n",
        "!mkdir expert_segmentations\n",
        "\n",
        "!wget -O maps1.zip https://m209.syncusercontent.com/zip/74d1fd441a935c8566eba260a388c946/Maps1_T.zip?linkcachekey=7c1511b70&pid=74d1fd441a935c8566eba260a388c946&jid=1eab4912\n",
        "!unzip -qju maps1.zip -d expert_segmentations/expert1\n",
        "\n",
        "!wget -O maps2.zip https://m209.syncusercontent.com/zip/b8da9b621d450b16dd5a6e14520223b1/Maps2_T.zip?linkcachekey=40029c030&pid=b8da9b621d450b16dd5a6e14520223b1&jid=57518d06\n",
        "!unzip -qju maps2.zip -d expert_segmentations/expert2\n",
        "\n",
        "!wget -O maps3.zip https://m209.syncusercontent.com/zip/f2998fa4353fb6f41f1df491fd07de0c/Maps3_T.zip?linkcachekey=46047d8f0&pid=f2998fa4353fb6f41f1df491fd07de0c&jid=611d4658\n",
        "!unzip -qju maps3.zip -d expert_segmentations/expert3\n",
        "\n",
        "!wget -O maps4.zip https://m209.syncusercontent.com/zip/3e19f34db9df54c43ddaf528b9010d0d/Maps4_T.zip?linkcachekey=fb19fb780&pid=3e19f34db9df54c43ddaf528b9010d0d&jid=ba72b487\n",
        "!unzip -qju maps4.zip -d expert_segmentations/expert4\n",
        "\n",
        "!wget -O maps5.zip https://m209.syncusercontent.com/zip/ed46068e96fe2669fe3dfc20d933613f/Maps5_T.zip?linkcachekey=4ca5bebb0&pid=ed46068e96fe2669fe3dfc20d933613f&jid=432ea1a2\n",
        "!unzip -qju maps5.zip -d expert_segmentations/expert5\n",
        "\n",
        "!wget -O maps6.zip https://m209.syncusercontent.com/zip/fc98a2b5b5ba5735ab395be560aba46b/Maps6_T.zip?linkcachekey=ee2ab68f0&pid=fc98a2b5b5ba5735ab395be560aba46b&jid=d9167209\n",
        "!unzip -qju maps6.zip -d expert_segmentations/expert6"
      ],
      "metadata": {
        "id": "axEj4k8NpuZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Imports and functions"
      ],
      "metadata": {
        "id": "Kazr23WC4y-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deepflash2 preprocessing required\n",
        "!pip install -qq git+https://github.com/matjesg/deepflash2.git@master"
      ],
      "metadata": {
        "id": "9dcLbamf6qOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U SimpleITK"
      ],
      "metadata": {
        "id": "dthKI8orYAL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import SimpleITK as sitk\n",
        "import imageio\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from fastai.vision.all import *\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Hx4VNOVPYa82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_msk(msk_path, **kwargs):\n",
        "    msk = imageio.imread(msk_path)\n",
        "    # Replace classes for use in consecutive order\n",
        "    msk[msk==3] = 1\n",
        "    msk[msk==4] = 2\n",
        "    msk[msk==5] = 3\n",
        "    msk[msk==6] = 3 \n",
        "    assert msk.max()<=3\n",
        "    return msk\n",
        "\n",
        "def staple(segmentations):\n",
        "    'STAPLE: Simultaneous Truth and Performance Level Estimation with simple ITK'\n",
        "    sitk_segmentations = [sitk.GetImageFromArray(x) for x in segmentations]\n",
        "\n",
        "    STAPLE = sitk.MultiLabelSTAPLEImageFilter()\n",
        "    STAPLE.SetLabelForUndecidedPixels(255)\n",
        "    msk = STAPLE.Execute(sitk_segmentations)\n",
        "    msk = sitk.GetArrayFromImage(msk)\n",
        "    traces = []\n",
        "    for _ in range(len(segmentations)):\n",
        "        cm = np.array(STAPLE.GetConfusionMatrix(_))\n",
        "        if len(cm)==6: cm = cm.reshape((3,2))\n",
        "        elif len(cm)==12: cm = cm.reshape((4,3))\n",
        "        elif len(cm)==20: cm = cm.reshape((5,4))\n",
        "        elif len(cm)==30: cm = cm.reshape((6,5))\n",
        "        elif len(cm)==42: cm = cm.reshape((7,6))\n",
        "        elif len(cm)==54: cm = cm.reshape((8,7))\n",
        "        else: raise NotImplementedError\n",
        "        traces.append(np.trace(cm))\n",
        "    best_seg = np.argmax(traces)\n",
        "    \n",
        "    # Replace undecided pixels with values from 'best' segementation\n",
        "    msk[msk == 255] = segmentations[best_seg][msk == 255]\n",
        "    assert msk.max()<=3\n",
        "    return msk"
      ],
      "metadata": {
        "id": "YZHDuTR7X8PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ground truth estimation from expert masks\n",
        "\n",
        "We use STAPLE instead of majority voting here!\n",
        "\n",
        "Example:\n",
        "![](https://rumc-gcorg-p-public.s3.amazonaws.com/i/2020/01/21/f9f06df6.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "aP-Ny1kp4-Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Folders\n",
        "exp_dir = Path('expert_segmentations')\n",
        "out_dir = Path('train')/'masks_STAPLE'\n",
        "out_dir.mkdir()\n",
        "mask_fn = lambda exp,msk: exp_dir/exp/msk\n",
        "\n",
        "# Get expert and file names\n",
        "fnames = get_image_files(exp_dir)\n",
        "masks = {}\n",
        "experts = []\n",
        "for m in sorted(fnames):\n",
        "    exp = m.parent.name\n",
        "    if m.name in masks:\n",
        "        masks[m.name].append(exp)\n",
        "    else:\n",
        "        masks[m.name] = [exp]\n",
        "    experts.append(exp)\n",
        "experts = sorted(set(experts))"
      ],
      "metadata": {
        "id": "etHSrZpoa4df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m, exps in progress_bar(masks.items()):\n",
        "    masks = [read_msk(mask_fn(exp,m)) for exp in exps]\n",
        "    ref = staple(masks)\n",
        "    imageio.imsave(out_dir/m, ref)"
      ],
      "metadata": {
        "id": "x4gXz-s_cOOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Split into train and test set"
      ],
      "metadata": {
        "id": "Th1BA_VbB4Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "train_path = Path('train')\n",
        "test_path = Path('test')\n",
        "image_folder = 'images'\n",
        "mask_folder = 'masks_STAPLE'\n",
        "mask_suffix = '_classimg_nonconvex.png'\n",
        "\n",
        "# Functions for copying data\n",
        "cp_fn = lambda o: test_path/image_folder/p.name\n",
        "cp_fn_msk = lambda o: test_path/mask_folder/p.name\n",
        "label_fn = lambda o: train_path/mask_folder/f'{o.stem}{mask_suffix}'\n",
        "\n",
        "(test_path/image_folder).mkdir(exist_ok=True, parents=True)\n",
        "(test_path/mask_folder).mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "92WxCtWLKZ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f_names = get_image_files(train_path/image_folder)\n",
        "#_, val = train_test_split(f_names, train_size=0.8, shuffle=True, random_state=0)\n",
        "\n",
        "# Original split was not sorted, so fixing file names here\n",
        "val = [Path('train/images/slide001_core004.jpg'),\n",
        " Path('train/images/slide001_core005.jpg'),\n",
        " Path('train/images/slide001_core010.jpg'),\n",
        " Path('train/images/slide001_core011.jpg'),\n",
        " Path('train/images/slide001_core014.jpg'),\n",
        " Path('train/images/slide001_core030.jpg'),\n",
        " Path('train/images/slide001_core039.jpg'),\n",
        " Path('train/images/slide001_core059.jpg'),\n",
        " Path('train/images/slide001_core095.jpg'),\n",
        " Path('train/images/slide002_core041.jpg'),\n",
        " Path('train/images/slide002_core050.jpg'),\n",
        " Path('train/images/slide002_core062.jpg'),\n",
        " Path('train/images/slide002_core067.jpg'),\n",
        " Path('train/images/slide002_core074.jpg'),\n",
        " Path('train/images/slide002_core084.jpg'),\n",
        " Path('train/images/slide002_core096.jpg'),\n",
        " Path('train/images/slide003_core055.jpg'),\n",
        " Path('train/images/slide003_core067.jpg'),\n",
        " Path('train/images/slide003_core097.jpg'),\n",
        " Path('train/images/slide003_core114.jpg'),\n",
        " Path('train/images/slide003_core134.jpg'),\n",
        " Path('train/images/slide003_core135.jpg'),\n",
        " Path('train/images/slide003_core136.jpg'),\n",
        " Path('train/images/slide005_core017.jpg'),\n",
        " Path('train/images/slide005_core018.jpg'),\n",
        " Path('train/images/slide005_core021.jpg'),\n",
        " Path('train/images/slide005_core029.jpg'),\n",
        " Path('train/images/slide005_core038.jpg'),\n",
        " Path('train/images/slide005_core045.jpg'),\n",
        " Path('train/images/slide005_core051.jpg'),\n",
        " Path('train/images/slide005_core057.jpg'),\n",
        " Path('train/images/slide005_core064.jpg'),\n",
        " Path('train/images/slide005_core122.jpg'),\n",
        " Path('train/images/slide005_core147.jpg'),\n",
        " Path('train/images/slide006_core016.jpg'),\n",
        " Path('train/images/slide006_core023.jpg'),\n",
        " Path('train/images/slide006_core086.jpg'),\n",
        " Path('train/images/slide006_core102.jpg'),\n",
        " Path('train/images/slide006_core105.jpg'),\n",
        " Path('train/images/slide006_core108.jpg'),\n",
        " Path('train/images/slide006_core109.jpg'),\n",
        " Path('train/images/slide006_core110.jpg'),\n",
        " Path('train/images/slide006_core113.jpg'),\n",
        " Path('train/images/slide006_core114.jpg'),\n",
        " Path('train/images/slide006_core125.jpg'),\n",
        " Path('train/images/slide006_core142.jpg'),\n",
        " Path('train/images/slide007_core047.jpg'),\n",
        " Path('train/images/slide007_core055.jpg'),\n",
        " Path('train/images/slide007_core056.jpg')]"
      ],
      "metadata": {
        "id": "u9ZbUN5CeO2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in progress_bar(val):\n",
        "    shutil.move(str(p), str(cp_fn(p)))\n",
        "    msk_p = label_fn(p)\n",
        "    shutil.move(str(msk_p), str(cp_fn_msk(p)))"
      ],
      "metadata": {
        "id": "oNK1lAmoLFIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}