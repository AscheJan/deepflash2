{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnunet_benchmark_challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matjesg/deepflash2/blob/master/paper/challenge_data/nnunet_benchmark_external.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ0pRdHQGAPl"
      },
      "source": [
        "# deepflash2 - nnunet benchmark on external challenge datasets\n",
        "\n",
        "> This notebook reproduces the *nnunet* results of the deepflash2 [paper](https://arxiv.org/abs/2111.06693) for the external challenge datasets.\n",
        "\n",
        "- `conic`: CoNIC: Colon Nuclei Identification and Counting Challenge ([link](https://conic-challenge.grand-challenge.org/))\n",
        "- `gleason`: Gleason 2019 Challenge (Prostate cancer grading) ([link](https://gleason2019.grand-challenge.org/))\n",
        "- `monuseg`: MoNuSeg: Multi-organ Nucleus Segmentation Challenge ([link](https://monuseg.grand-challenge.org/))\n",
        "\n",
        "**Models**: The trained models are available on [Google Drive](https://drive.google.com/drive/folders/1r9AqP9qW9JThbMIvT0jhoA5mPxWEeIjs?usp=sharing). \n",
        "\n",
        "To use data and trained models, create a [shortcut](https://support.google.com/drive/answer/9700156?hl=en&co=GENIE.Platform%3DDesktop) of the data folder in your personal Google Drive.\n",
        "\n",
        "*References*:\n",
        "\n",
        "Griebel, M., Segebarth, D., Stein, N., Schukraft, N., Tovote, P., Blum, R., & Flath, C. M. (2021). Deep-learning in the bioimaging wild: Handling ambiguous data with deepflash2. arXiv preprint arXiv:2111.06693.\n",
        "\n",
        "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFQlTlPoKBM9"
      },
      "source": [
        "## Setup\n",
        "\n",
        "- Install dependecies\n",
        "- Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DK5ySSWKESd"
      },
      "source": [
        "# Restart runtime after installation\n",
        "!pip install nnunet imagecodecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbDoXA3PKNAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74ae11b-43c8-4b54-fcc4-c1a4710a4324"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import imageio\n",
        "import tifffile\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from skimage.color import label2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# According to the nnunet documentation: https://github.com/MIC-DKFZ/nnUNet/tree/master/documentation\n",
        "os.environ['nnUNet_raw_data_base'] =\"/content/nnUNet_raw\"\n",
        "os.environ['nnUNet_preprocessed']= \"/content/nnUNet_preprocessed\"\n",
        "os.environ['RESULTS_FOLDER']= \"/content/nnUNet_trained_models\"\n",
        "from nnunet.dataset_conversion.utils import generate_dataset_json\n",
        "from nnunet.paths import nnUNet_raw_data, preprocessing_output_dir\n",
        "from nnunet.utilities.file_conversions import convert_2d_image_to_nifti\n",
        "from batchgenerators.utilities.file_and_folder_operations import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNwYiX9RmiMX",
        "outputId": "9ded3207-360f-4ce4-b472-d91d8a94ebef"
      },
      "source": [
        "# Connect to drive\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "except:\n",
        "  print('Google Drive is not available.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ehFoOoJIox"
      },
      "source": [
        "## Settings\n",
        "\n",
        "\n",
        "\n",
        "Choose dataset from `conic`,  `gleason`, `monuseg`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LFII70JHOl"
      },
      "source": [
        "DATASET = 'conic'\n",
        "OUTPUT_DIR = \"/content/predictions\" # Save predictions here\n",
        "DATA_PATH = Path('/gdrive/MyDrive/deepflash2-paper/data')\n",
        "TRAINED_MODEL_FOLDER = '/gdrive/MyDrive/deepflash2-paper/nnUNet_trained_models_challenge_data'\n",
        "\n",
        "\n",
        "task_dict = {\n",
        "    'gleason': 130, \n",
        "    'conic': 131, \n",
        "    'monuseg' : 132\n",
        "}\n",
        "\n",
        "# Not all datasets are based on ground truth estimations from multiple experts\n",
        "mask_dir_dict = {\n",
        "    'conic':'masks',\n",
        "    'gleason':'masks_STAPLE',\n",
        "    'monuseg':'masks_preprocessed'\n",
        "}\n",
        "\n",
        "class_dict = {\n",
        "    'conic':{0:'background', 1: 'Epithelial', 2: 'Lymphocyte', 3: 'Plasma', 4:'Eosinophil', 5:'Neutrophil', 6:'Connective tissue'},\n",
        "    'gleason': {0: 'background', 1: 'grade3', 2: 'grade4', 3: 'grade5'},\n",
        "    'monuseg': {0: 'background', 1: 'nuclei'}\n",
        "}\n",
        "\n",
        "inst_seg_dict = {\n",
        "    'conic':True,\n",
        "    'gleason':False,\n",
        "    'monuseg':True\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbql-zGyF93s"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "adapted from [nnunet github](https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/dataset_conversion/Task120_Massachusetts_RoadSegm.py).\n",
        "\n",
        "Dataset conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ugKa2eQhq9"
      },
      "source": [
        "# this folder should have the training and testing subfolders\n",
        "base = DATA_PATH/DATASET\n",
        "\n",
        "# now start the conversion to nnU-Net:\n",
        "task_name = f\"Task{task_dict[DATASET]}_{DATASET}\"\n",
        "target_base = Path(os.environ['nnUNet_raw_data_base'])/\"nnUNet_raw_data\"/task_name\n",
        "target_imagesTr = target_base/\"imagesTr\"\n",
        "target_imagesTs = target_base/\"imagesTs\"\n",
        "target_labelsTs = target_base/\"labelsTs\"\n",
        "target_labelsTr = target_base/\"labelsTr\"\n",
        "\n",
        "maybe_mkdir_p(target_imagesTr)\n",
        "maybe_mkdir_p(target_labelsTs)\n",
        "maybe_mkdir_p(target_imagesTs)\n",
        "maybe_mkdir_p(target_labelsTr)\n",
        "\n",
        "# convert the training examples\n",
        "images_dir_tr = base/'train'/'images'\n",
        "labels_dir_tr = base/'train'/mask_dir_dict[DATASET]\n",
        "\n",
        "training_cases = [x for x in images_dir_tr.iterdir()]\n",
        "label_fn = lambda x: labels_dir_tr/f'{x.name[:-4]}_mask.png'\n",
        "\n",
        "for t in training_cases:\n",
        "    unique_name = t.name[:-4]\n",
        "    input_segmentation_file = label_fn(t)\n",
        "\n",
        "    output_image_file = target_imagesTr/unique_name  # do not specify a file ending! This will be done for you\n",
        "    output_seg_file = target_labelsTr/unique_name  # do not specify a file ending! This will be done for you\n",
        "\n",
        "    # this utility will convert 2d images that can be read by skimage.io.imread to nifti. You don't need to do anything.\n",
        "    # if this throws an error for your images, please just look at the code for this function and adapt it to your needs\n",
        "    convert_2d_image_to_nifti(t, output_image_file.as_posix(), is_seg=False)\n",
        "\n",
        "    # the labels are stored as 0: background, 255: road. We need to convert the 255 to 1 because nnU-Net expects\n",
        "    # the labels to be consecutive integers. This can be achieved with setting a transform\n",
        "    convert_2d_image_to_nifti(input_segmentation_file, output_seg_file.as_posix(), is_seg=True,\n",
        "                              transform=lambda x: (x == 255).astype(int))\n",
        "    \n",
        "# now do the same for the test set (no labels required)\n",
        "images_dir_ts = base/'test'/'images'\n",
        "testing_cases = [x for x in images_dir_ts.iterdir()]\n",
        "for ts in testing_cases:\n",
        "    unique_name = ts.name[:-4]\n",
        "    output_image_file = target_imagesTs/unique_name\n",
        "    convert_2d_image_to_nifti(ts, output_image_file.as_posix(), is_seg=False)\n",
        "\n",
        "# finally we can call the utility for generating a dataset.json\n",
        "generate_dataset_json(join(target_base, 'dataset.json'), target_imagesTr, target_imagesTs, \n",
        "                      ('noCT',)*num_channel_dict[DATASET],\n",
        "                      labels=class_dict[DATASET], dataset_name=task_name, license='')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy3WkVqAUOYv"
      },
      "source": [
        "nnunet preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgTzu8kQV150"
      },
      "source": [
        "!nnUNet_plan_and_preprocess -t {task_dict[DATASET]} -pl3d None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbjq2FTnYKd0"
      },
      "source": [
        "## Train models\n",
        "\n",
        "- This will take very long on Google Colab and not finish within the 12 hour limit for free GPU usage. \n",
        "- You can upgrade to Colab Pro or use the trained models from our paper (see next section)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_bXel66YKlo"
      },
      "source": [
        "for FOLD in range(5):\n",
        "  !nnUNet_train 2d nnUNetTrainerV2 {task_dict[DATASET]} {FOLD}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtyFQUY1aiit"
      },
      "source": [
        "# Run after training\n",
        "!nnUNet_find_best_configuration -t {task_dict[DATASET]}  -m 2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUmd0HEpH1R9"
      },
      "source": [
        "## Prediction on test set\n",
        "\n",
        "We will use the trained models from our paper!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxlTP9nwFnjX"
      },
      "source": [
        "os.environ['RESULTS_FOLDER']= TRAINED_MODEL_FOLDER\n",
        "\n",
        "test_image_dir = f\"{os.environ['nnUNet_raw_data_base']}/nnUNet_raw_data/{task_name}/imagesTs/\"\n",
        "prediction_dir = f\"{OUTPUT_DIR}/{task_name}\"\n",
        "cmd = f\"-i {test_image_dir} -o {prediction_dir} -t {task_name}\"\n",
        "\n",
        "!nnUNet_predict -tr nnUNetTrainerV2 -ctr nnUNetTrainerV2CascadeFullRes -m 2d -p nnUNetPlansv2.1 {cmd}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO2pIb7rfOXI"
      },
      "source": [
        "Convert to\n",
        "\n",
        "- Semantic segmentation masks (.png)\n",
        "- Instance segmentation masks (.tif) using the connected components algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbBULexYGfTz"
      },
      "source": [
        "prediction_path = Path(prediction_dir)\n",
        "files = [x for x in prediction_path.iterdir() if x.suffix=='.gz']\n",
        "\n",
        "for f in files:\n",
        "    print(f.stem)\n",
        "    idx = f.stem[:-4]\n",
        "    pred = np.array(nib.load(f).dataobj)\n",
        "    pred = np.fliplr(np.rot90(pred, 3))[...,0]\n",
        "\n",
        "    # Save semantic segmentation prediction\n",
        "    masks_path = prediction_path/'masks'\n",
        "    masks_path.mkdir(exist_ok=True)\n",
        "    if len(class_dict[DATASET])==2: \n",
        "        pred_out = pred*255\n",
        "    else: \n",
        "        pred_out = pred\n",
        "    imageio.imwrite(masks_path/f'{idx}.png', pred_out.astype('uint8'))\n",
        "\n",
        "    if inst_seg_dict[DATASET]:\n",
        "        # Save instance segmentation prediction\n",
        "        instance_masks_path = prediction_path/'instance_masks'\n",
        "        instance_masks_path.mkdir(exist_ok=True)\n",
        "        for c in class_dict[DATASET]:\n",
        "            if c==0: continue\n",
        "            predc = pred==c\n",
        "            _, label_msk = cv2.connectedComponents(predc.astype('uint8'), connectivity=4)\n",
        "            tifffile.imwrite(instance_masks_path/f'{idx}_class{c}.tif', label_msk.astype('int16'), compress=6)\n",
        "\n",
        "    # Plot\n",
        "    fig, axs = plt.subplots(ncols=1, figsize=(20,10))\n",
        "    axs.imshow(pred)\n",
        "    axs.set_title(f'Semantic segmentation {idx}')\n",
        "    #axs[1].imshow(label2rgb(label_msk, bg_label=0))\n",
        "    #axs[1].set_title(f'Instance segmentation {idx}')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8m9cyRqm9Tv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}