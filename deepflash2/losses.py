# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_losses.ipynb (unless otherwise specified).

__all__ = ['WeightedSoftmaxCrossEntropy']

# Cell
from fastai2.vision.all import *
#import torch
#import torch.nn.functional as F

# Cell
class WeightedSoftmaxCrossEntropy(torch.nn.Module):
    "Weighted Softmax Cross Entropy loss functions"
    def __init__(self, axis=-1, *args, reduction = 'mean'):
        super().__init__()
        self.reduction = reduction
        self.axis = axis

    def decodes(self, x):
        return x.argmax(dim=self.axis)

    def activation(self, x):
        return F.softmax(x, dim=self.axis)

    def forward(self, inputs, targ_weights):

        # Unpack targets and weights tuple
        targets = targ_weights[0]
        weights = targ_weights[1]

        # Weighted soft-max cross-entropy loss
        log_smx = F.log_softmax(inputs, dim=1)*targets
        # Broadcasting weights a axis 1 instead?
        loss_wce = -log_smx.min(dim=1).values*weights

        if  self.reduction == 'mean':
            return loss_wce.mean()

        elif self.reduction == 'sum':
            return loss_wce.sum()

        else:
            return loss_wce