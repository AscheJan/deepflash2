# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_data.ipynb (unless otherwise specified).

__all__ = ['DeformationField', 'DataPreProcessor', 'BaseTileDataset', 'RandomTileDataset', 'TileDataset']

# Cell
import os
import numpy as np
from pathlib import Path

from scipy import ndimage
from scipy.interpolate import Rbf
from scipy.interpolate import interp1d
from skimage import io

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from fastprogress.fastprogress import progress_bar
from fastcore.foundation import add_docs

# Cell
class DeformationField:
    "Creates a deformation field for data augmentation"
    def __init__(self, shape=(540, 540)):
        self.shape = shape
        self.deformationField = np.meshgrid(*[np.arange(d) - d / 2 for d in shape])[::-1]

    def rotate(self, theta=0, phi=0, psi=0):
        "Rotate deformation field"
        if len(self.shape) == 2:
            self.deformationField = [
                self.deformationField[0] * np.cos(theta)
                + self.deformationField[1] * np.sin(theta),
                -self.deformationField[0] * np.sin(theta)
                + self.deformationField[1] * np.cos(theta),
            ]
        else:
            self.deformationField = [
                self.deformationField[0],
                self.deformationField[1] * np.cos(theta)
                + self.deformationField[2] * np.sin(theta),
                -self.deformationField[1] * np.sin(theta)
                + self.deformationField[2] * np.cos(theta),
            ]
            self.deformationField = [
                self.deformationField[0] * np.cos(phi)
                + self.deformationField[2] * np.sin(phi),
                self.deformationField[1]
                - self.deformationField[0] * np.sin(phi)
                + self.deformationField[2] * np.cos(phi),
            ]
            self.deformationField = [
                self.deformationField[0],
                self.deformationField[1] * np.cos(psi)
                + self.deformationField[2] * np.sin(psi),
                -self.deformationField[1] * np.sin(psi)
                + self.deformationField[2] * np.cos(psi),
            ]

    def mirror(self, dims):
        "Mirror deformation fild at dims"
        for d in range(len(self.shape)):
            if dims[d]:
                self.deformationField[d] = -self.deformationField[d]

    def addRandomDeformation(self, grid=(150, 150), sigma=(10, 10)):
        "Add random deformation to the deformation field"
        seedGrid = np.meshgrid(
            *[np.arange(-g / 2, s + g / 2, g) for (g, s) in zip(grid, self.shape)]
        )
        seed = [np.random.normal(0, s, g.shape) for (g, s) in zip(seedGrid, sigma)]
        defFcn = [Rbf(*seedGrid, s, function="cubic") for s in seed]
        targetGrid = np.meshgrid(*map(np.arange, self.shape))
        deformation = [f(*targetGrid) for f in defFcn]
        self.deformationField = [
            f + df for (f, df) in zip(self.deformationField, deformation)
        ]

    def get(self, offset=(0, 0), pad=(0, 0)):
        "Get relevant slice from deformation field"
        sliceDef = tuple(slice(int(p / 2), int(-p / 2)) if p > 0 else None for p in pad)
        deform = [d[sliceDef] for d in self.deformationField]
        return [d + offs for (d, offs) in zip(deform, offset)]

    def apply(self, data, offset=(0, 0), pad=(0, 0), order=1):
        "Apply deformation field to image using interpolation"
        coords = [d.flatten() for d in self.get(offset, pad)]
        outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))
        if len(data.shape) == len(self.shape) + 1:
            tile = np.empty((*outshape, data.shape[-1]))
            for c in range(data.shape[-1]):
                tile[..., c] = ndimage.interpolation.map_coordinates(
                    data[..., c], coords, order=order, mode="reflect"
                ).reshape(outshape)
            return tile.astype(data.dtype)
        else:
            return (
                ndimage.interpolation.map_coordinates(
                    data, coords, order=order, mode="reflect")
                .reshape(outshape)
                .astype(data.dtype))

# Cell
class DataPreProcessor:
    def __init__(
        self,
        element_size_um=None,
        border_weight_sigma_px=6, #sigma_sep
        foreground_dist_sigma_px=0,#10?#sigma_bal
        border_weight_factor=50, #lambda
        foreground_background_ratio=.1, #v_bal
        **kwargs):

        self.element_size_um = element_size_um
        self.border_weight_sigma_px = border_weight_sigma_px
        self.foreground_dist_sigma_px = foreground_dist_sigma_px
        self.border_weight_factor = border_weight_factor
        self.foreground_background_ratio = foreground_background_ratio

    def generateSample(
        self, data, instancelabels=None, classlabels=None, ignore=None, weights=None
    ):

        #dataScaled = data["rawdata"].astype(float)
        #elSize = data["element_size_um"]
        if data.ndim == 2:
            data = np.expand_dims(data, axis=2)
        dataScaled = data.astype(float)
        nDims = len(dataScaled.shape) - 1
        instlabels = instancelabels
        clabels = classlabels
        ign = ignore
        wghts = weights

        # If weights need to be computed, and no instance labels are given,
        # generate them now
        if wghts is None and clabels is not None and instlabels is None:
            instlabels = np.zeros_like(clabels)
            classes = np.unique(clabels)[1:]
            nextInstance = 1
            for c in classes:
                comps, nInstances = ndimage.measurements.label(clabels == c)
                instlabels[comps > 0] = comps[comps > 0] + nextInstance
                # instlabels[comps > 0] = instances[comps > 0] + nextInstance #old
                nextInstance += nInstances

        # Rescale blobs to processing element size
        if self.element_size_um is not None and np.any(
            np.asarray(elSize) != np.asarray(self.element_size_um)
        ):
            print("Rescaling...")
            scales = tuple(s / t for (s, t) in zip(elSize, self.element_size_um))

            dataScaled = ndimage.zoom(dataScaled, (*scales, 1), order=1, mode="reflect")

            if instlabels is not None:
                instlabels = ndimage.zoom(instlabels, scales, order=0, mode="reflect")
            if clabels is not None:
                clabels = ndimage.zoom(clabels, scales, order=0, mode="reflect")
            if ign is not None:
                ign = ndimage.zoom(ign, scales, order=0, mode="reflect")
            if wghts is not None:
                wghts = ndimage.zoom(wghts, scales, order=1, mode="reflect")

        # Normalize values to [0,1] range
        # print("  Normalizing intensity range...")
        for c in range(dataScaled.shape[-1]):
            minValue = np.min(dataScaled[..., c])
            maxValue = np.max(dataScaled[..., c])
            dataScaled[..., c] = (dataScaled[..., c] - minValue) / (maxValue - minValue)

        # If no labels are given we are done and simply return the data array
        if instlabels is None and clabels is None:
            return dataScaled.astype(np.float32), None, None, None

        # If no classlabels are given treat the problem as binary segmentation
        # ==> Create a new array assigning class 1 (foreground) to each instance
        if clabels is None:
            clabels = instlabels > 0

        # If weights are given we only need to compute the sample pdf and we're
        # done
        if wghts is not None:
            pdf = (clabels > 0) + self.foreground_background_ratio * (clabels == 0)
            if ign is not None:
                pdf *= 1 - ign
            return (
                dataScaled.astype(np.float32),
                clabels.astype(np.int32),
                wghts.astype(np.float32),
                pdf.astype(np.float32),
            )

        # No weights given, so we need to compute them

        # Initialize label and weights arrays with background
        labels = np.zeros_like(clabels)
        wghts = self.foreground_background_ratio * np.ones_like(clabels)
        frgrd_dist = np.zeros_like(clabels, dtype='float32')
        # Get all foreground class labels
        classes = np.unique(clabels)[1:]

        for c in classes:

            # Extract all instance labels of class c
            instances = np.unique(instlabels * (clabels == c))[1:]

            # Generate background ridges between touching instances
            # of that class, avoid overlapping instances
            # print("  Generating ridges...")
            for instance in instances:
                objectMaskDil = ndimage.morphology.binary_dilation(
                    labels == c, structure=np.ones((3,) * nDims)
                )
                labels[(instlabels == instance) & (objectMaskDil == 0)] = c

            # Generate weights
            # print("Generating weights...")
            min1dist = 1e10 * np.ones(labels.shape)
            min2dist = 1e10 * np.ones(labels.shape)
            for instance in instances:
                dt = ndimage.morphology.distance_transform_edt(instlabels != instance)

                frgrd_dist += np.exp(-dt ** 2 / (2*self.foreground_dist_sigma_px ** 2))
                min2dist = np.minimum(min2dist, dt)
                newMin1 = np.minimum(min1dist, min2dist)
                newMin2 = np.maximum(min1dist, min2dist)
                min1dist = newMin1
                min2dist = newMin2
            wghts += self.border_weight_factor * np.exp(
                -(min1dist + min2dist) ** 2 / (2*self.border_weight_sigma_px ** 2)
            )

        # Set weight for distance to the closest foreground object
        wghts[labels == 0] += (1-self.foreground_background_ratio)*frgrd_dist[labels == 0]
        # Set foreground weights to 1
        wghts[labels > 0] = 1
        pdf = (labels > 0) + (labels == 0) * self.foreground_background_ratio

        # Set weight and sampling probability for ignored regions to 0
        if ign is not None:
            wghts[ign] = 0
            pdf[ign] = 0

        return (
            dataScaled.astype(np.float32),
            labels.astype(np.int32),
            wghts.astype(np.float32),
            pdf.astype(np.float32),
        )

# Cell
class BaseTileDataset(Dataset):
        def __init__(self, img_dir, mask_dir, path, file_ids=None,
                     n_classes=2, mask_suffix='.png', tile_shape=(540,540),
                     padding=(184,184), ignore=None, weights=None, **kwargs):

            self.img_dir = img_dir
            self.mask_dir = mask_dir
            self.path = path
            self.mask_suffix = mask_suffix
            self.tile_shape = tile_shape
            self.padding = padding
            self.c = n_classes

            # Get File IDs
            if file_ids is not None:
                self.img_names = [x for x in os.listdir(os.path.join(path, img_dir)) if Path(x).stem in file_ids]
                self.img_ids = file_ids

            else:
                self.img_names = [x for x in os.listdir(os.path.join(path, mask_dir))]
                self.img_ids = [Path(x).stem for x in self.img_names]
                print(self.img_ids)


            # Load images
            self.images = [io.imread(os.path.join(path, img_dir, x)) for x in self.img_names]

            # Load Masks
            self.masks = [io.imread(os.path.join(path, mask_dir, x)).astype('int')//255
                          for x in [s + mask_suffix for s in self.img_ids]]

        def plot_data(self):
            "Plots "

# Cell
from fastcore.utils import Tuple
from matplotlib.patches import Rectangle
from skimage.measure import label, regionprops
from skimage.morphology import closing, square
from skimage.color import label2rgb
import matplotlib.pyplot as plt
from copy import copy

class IMWImage(Tuple):
    def show(self, figsize=(15,15), **kwargs): 
        img,msk,weight = self
        
        # To numpy
        img = np.array(img)
        msk = np.array(msk)
        weight = np.array(weight)
        
        # One channel images
        if img.shape[-1]==1: img=img[...,0]
        if img.shape[1]==1: img=img[...,0,...]
            
        # Binary masks
        if msk.shape[0]==2:
            msk=msk[1,...]   
            
        #pdb.set_trace()
        pad = (np.array(img.shape)-np.array(msk.shape))//2
        
        # bbox
        bbox = Rectangle((pad[0]-1,pad[1]-1),img.shape[0]-2*pad[0]+1,img.shape[0]-2*pad[0]+1,
                 edgecolor='r',linewidth=1,facecolor='none')
        
        # Padding mask and weights
        msk = np.pad(msk, pad, 'constant', constant_values=(0))
        weight = np.pad(weight, pad, 'constant', constant_values=(0))
    
        fig, ax = plt.subplots(1,3,figsize=figsize) 
        # Plot img
        ax[0].imshow(img, cmap='binary_r')
        ax[0].set_title('Input Image')
        ax[0].set_axis_off()
        
        # Plot img and mask
        label_image = label(msk)
        img_l2o = label2rgb(label_image, image=img, bg_label=0, alpha=.8, image_alpha=1)
        ax[1].imshow(img_l2o)
        ax[1].add_patch(copy(bbox))
        ax[1].set_title('Image + Mask (#ROIs: {})'.format(label_image.max()))
        ax[1].set_axis_off()
        
        # Plot weights
        max_w = weight.max()
        vmax_w = max(1, max_w)
        ax[2].imshow(weight, vmax=vmax_w, cmap='binary_r')
        ax[2].add_patch(copy(bbox))
        ax[2].set_title('Weights (max value: {:.{p}f})'.format(max_w, p=3))
        ax[2].set_axis_off()
        
        #ax.set_axis_off()
        plt.tight_layout()
        plt.show()
from fastcore.dispatch import typedispatch  
import pdb
@typedispatch
def show_batch(x:IMWImage, y, samples, max_n=6, ncols=1, figsize=None, **kwargs):
    max_n = np.min((max_n, len(x[0])))
    if figsize is None: figsize = (ncols*12, max_n//ncols * 5)
    for i in range(max_n): IMWImage(x[0][i], x[1][0][i], x[1][1][i]).show(figsize=figsize, **kwargs)
        
class RandomTileDataset(Dataset):
    """Random Tile dataset."""

    def __init__(self, img_path, mask_path, root_dir,
                 file_ids=None,
                 n_classes=2,
                 mask_suffix='.png',
                 tile_shape=(540,540),
                 padding=(184,184),
                ignore=None,
                weights=None,
                 sample_mult=None,
                rotation_range_deg=(0, 360),
                flip=False,
                deformation_grid=(150, 150),
                deformation_magnitude=(10, 10),
                value_minimum_range=(0, 0),
                value_maximum_range=(1, 1),
                value_slope_range=(1, 1),
                **kwargs):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            tile_shape - The tile shape the network expects as input
            padding - The padding (input shape - output shape)
            classlabels - A list containing the corresponding class labels.
                          0 = ignore, 1 = background, 2-n foreground classes
                          If None, the problem will be treated as binary segmentation
            n_classes - The number of classes including background
            ignore - A list containing the corresponding ignore regions.
            weights - A list containing the corresponding weights.
            element_size_um - The target pixel size in micrometers
            batch_size - The number of tiles to generate per batch
            rotation_range_deg - (alpha_min, alpha_max): The range of rotation angles.
                                 A random rotation is drawn from a uniform distribution
                                 in the given range
            flip - If true, a coin flip decides whether a mirrored tile will be
                   generated
            deformation_grid - (dx, dy): The distance of neighboring grid points in
                               pixels for which random deformation vectors are drawn
            deformation_magnitude - (sx, sy): The standard deviations of the
                                    Gaussians, the components of the deformation
                                    vector are drawn from
            value_minimum_range - (v_min, v_max): Input intensity zero will be mapped
                                  to a random value in the given range
            value_maximum_range - (v_min, v_max): Input intensity one will be mapped
                                  to a random value within the given range
            value_slope_range - (s_min, s_max): The slope at control points is drawn
                                from a uniform distribution in the given range

        """
        self.img_path = img_path
        self.mask_path = mask_path
        self.mask_suffix = mask_suffix
        self.root_dir = root_dir
        self.tile_shape = tile_shape
        self.padding = padding
        self.n_classes = n_classes
        self.c = n_classes
        self.rotation_range_deg = rotation_range_deg
        self.flip = flip
        self.deformation_grid = deformation_grid
        self.deformation_magnitude = deformation_magnitude
        self.value_minimum_range = value_minimum_range
        self.value_maximum_range = value_maximum_range
        self.value_slope_range = value_slope_range

        # Get File IDs
        if file_ids is not None:
            self.img_names = [x for x in os.listdir(os.path.join(root_dir, img_path)) if Path(x).stem in file_ids]
            self.img_ids = file_ids

        else:
            self.img_names = [x for x in os.listdir(os.path.join(root_dir, img_path))]
            self.img_ids = [Path(x).stem for x in self.img_names]
            print(self.img_ids)


        # Load images
        self.images = [io.imread(os.path.join(root_dir, img_path, x)) for x in self.img_names]

        # Load Masks
        self.masks = [io.imread(os.path.join(root_dir, mask_path, x)).astype('int')//255
                      for x in [s + mask_suffix for s in self.img_ids]]

        self.preprocessor = DataPreProcessor(**kwargs)
        self.data = []
        self.labels = []
        self.weights = []
        self.pdf = []
        print("Processing training samples")

        for i in progress_bar(range(len(self.images))):

            (sampleData, sampleLabels, sampleWeights, samplePdf) = self.preprocessor.generateSample(
                self.images[i],
                #instancelabels[i] if instancelabels is not None else None,
                classlabels=self.masks[i], # if classlabels is not None else None,
                ignore=ignore[i] if ignore is not None else None,
                weights=weights[i] if weights is not None else None,
            )
            self.data.append(sampleData)
            self.labels.append(sampleLabels)
            self.weights.append(sampleWeights)
            self.pdf.append(samplePdf)

        self.n_channels = self.data[0].shape[2]

        # Sample mulutiplier:
        # Sampling random image tile from augmented image
        self.sample_mult = sample_mult
        if self.sample_mult is None:
            tile_shape = np.array(self.tile_shape)-np.array(self.padding)
            img_shape = np.array(self.images[0].shape[-2:])
            self.sample_mult = int(np.product(np.ceil(img_shape/tile_shape)))

        self.on_epoch_end()
    
    def show_data(self, max_n=6, ncols=1, figsize=None, **kwargs):
        max_n = np.min((max_n, len(self.data)))
        if figsize is None: figsize = (ncols*12, max_n//ncols * 5)
        for i in range(max_n): 
            IMWImage(self.data[i], self.masks[i], self.weights[i]).show()
            
    def __len__(self):
        return len(self.img_ids)*self.sample_mult

    def __getitem__(self, idx):
        idx = idx % len(self.img_ids)
        if torch.is_tensor(idx):
            idx = idx.tolist()

        cumulatedPdf = np.cumsum(self.pdf[idx] / np.sum(self.pdf[idx]))
        # Random center
        center = np.unravel_index(np.argmax(cumulatedPdf > np.random.random()), self.pdf[idx].shape)
        X = self.gammaFcn(self.deformationField.apply(self.data[idx], center).flatten()).reshape((*self.tile_shape, self.n_channels))
        X = np.moveaxis(X, -1, 0)
        Y = self.deformationField.apply(self.labels[idx], center, self.padding, 0)
        # To categorical
        Y = np.eye(self.n_classes)[Y]
        Y = np.moveaxis(Y, -1, 0)
        W = self.deformationField.apply(self.weights[idx], center, self.padding, 1)

        X = X.astype('float32')
        Y = Y.astype('uint8')
        W = W.astype('float32')

        return  IMWImage(X, (Y,W))

    def on_epoch_end(self, verbose=False):

        if verbose: print("Generating deformation field")
        self.deformationField = DeformationField(self.tile_shape)

        if self.rotation_range_deg[1] > self.rotation_range_deg[0]:
            self.deformationField.rotate(
                theta=np.pi * (np.random.random()
                            * (self.rotation_range_deg[1] - self.rotation_range_deg[0])
                            + self.rotation_range_deg[0])
                            / 180.0)

        if self.flip:
            self.deformationField.mirror(np.random.choice((True,False),2))

        if self.deformation_grid is not None:
            self.deformationField.addRandomDeformation(
                self.deformation_grid, self.deformation_magnitude)

        if verbose: print("Generating value augmentation function")
        minValue = (self.value_minimum_range[0]
            + (self.value_minimum_range[1] - self.value_minimum_range[0])
            * np.random.random())

        maxValue = (self.value_maximum_range[0]
            + (self.value_maximum_range[1] - self.value_maximum_range[0])
            * np.random.random())

        intermediateValue = 0.5 * (
            self.value_slope_range[0]
            + (self.value_slope_range[1] - self.value_slope_range[0])
            * np.random.random())

        self.gammaFcn = interp1d([0, 0.5, 1.0], [minValue, intermediateValue, maxValue], kind="quadratic")

# Cell
class TileDataset(Dataset):

    """
    data - A list of tuples of the form
           [{ rawdata: numpy.ndarray (HxWxC),
              element_size_um: [e_y, e_x] }, ...]
           containing the raw data ([0-1] normalized) and corresponding
           element sizes in micrometers
    instancelabels - A list containing the corresponding instance labels.
                     0 = background, 1-m instance labels
    tile_shape - The tile shape the network expects as input
    padding - The padding (input shape - output shape)
    classlabels - A list containing the corresponding class labels.
                   0 = ignore, 1 = background, 2-n foreground classes
                   If None, the problem will be treated as binary segmentation
    n_classes - The number of classes including background
    ignore - A list containing the corresponding ignore regions.
    weights - A list containing the corresponding weights.
    element_size_um - The target pixel size in micrometers
    border_weight_sigma_px - The border weight standard deviation in pixels
    border_weight_factor - The border weight factor to enforce instance
                           separation
    foreground_background_ratio - The ratio between foreground and background
                                  pixels
  """

    def __init__(
        self,
        img_path,
        root_dir,
        mask_path = None,
        file_ids=None,
        n_classes=2,
        mask_suffix='.png',
        tile_shape=(540,540),
        padding=(184,184),
        instancelabels=None,
        ignore=None,
        weights=None, **kwargs):

        self.img_path = img_path
        self.mask_path = mask_path
        self.mask_suffix = mask_suffix
        self.root_dir = root_dir
        self.tile_shape = tile_shape
        self.padding = padding
        self.n_classes = n_classes
        self.c = n_classes

        # Get File IDs
        if file_ids is not None:
            self.img_names = [x for x in os.listdir(os.path.join(root_dir, img_path)) if Path(x).stem in file_ids]
            self.img_ids = file_ids

        else:
            self.img_names = [x for x in os.listdir(os.path.join(root_dir, img_path))]
            self.img_ids = [Path(x).stem for x in self.img_names]
            print(self.img_ids)


        # Load images
        self.images = [io.imread(os.path.join(root_dir, img_path, x)) for x in self.img_names]

        # Load Masks
        if mask_path is not None:
            self.masks = [io.imread(os.path.join(root_dir, mask_path, x)).astype('int')//255
                          for x in [s + mask_suffix for s in self.img_ids]]

        pre = DataPreProcessor(**kwargs)
        tiler = DeformationField(tile_shape)
        self.hasLabels = instancelabels is not None or mask_path is not None
        self.data = []
        self.labels = [] if self.hasLabels else None
        self.weights = [] if self.hasLabels else None
        self.image_indices = []
        self.image_shapes = []
        self.in_slices = []
        self.out_slices = []
        self.output_shape = tuple(int(t - p) for (t, p) in zip(tile_shape, padding))


        print("Processing test samples")

        for i in progress_bar(range(len(self.images))):
            (sampleData, sampleLabels, sampleWeights, _) = pre.generateSample(
                self.images[i],
                instancelabels[i] if instancelabels is not None else None,
                classlabels=self.masks[i] if mask_path is not None else None,
                ignore=ignore[i] if ignore is not None else None,
                weights=weights[i] if weights is not None else None,
            )

            # Tiling
            data_shape = sampleData.shape[:-1]
            for ty in range(int(np.ceil(data_shape[0] / self.output_shape[0]))):
                for tx in range(int(np.ceil(data_shape[1] / self.output_shape[1]))):
                    centerPos = (
                        int((ty + 0.5) * self.output_shape[0]),
                        int((tx + 0.5) * self.output_shape[1]),
                    )
                    self.data.append(tiler.apply(sampleData, centerPos))
                    if self.hasLabels:
                        self.labels.append(
                            tiler.apply(sampleLabels, centerPos, padding, order=0)
                        )
                        self.weights.append(
                            tiler.apply(sampleWeights, centerPos, padding, order=1)
                        )
                    self.image_indices.append(i)
                    self.image_shapes.append(data_shape)
                    sliceDef = tuple(
                        slice(tIdx * o, min((tIdx + 1) * o, s))
                        for (tIdx, o, s) in zip((ty, tx), self.output_shape, data_shape)
                    )
                    self.out_slices.append(sliceDef)
                    sliceDef = tuple(
                        slice(0, min((tIdx + 1) * o, s) - tIdx * o)
                        for (tIdx, o, s) in zip((ty, tx), self.output_shape, data_shape)
                    )
                    self.in_slices.append(sliceDef)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        X = np.moveaxis(self.data[idx] , -1, 0).astype('float32')
        Y = np.eye(self.n_classes, dtype='uint8')[self.labels[idx]] if self.hasLabels else None
        Y = np.moveaxis(Y, -1, 0)
        W = self.weights[idx].astype('float32')  if self.hasLabels else None

        X = torch.from_numpy(X).float().cuda()
        Y = torch.from_numpy(Y).cuda()
        W = torch.from_numpy(W).float().cuda()

        return  (X,(Y,W))


    def reconstruct_from_tiles(self, tiles):
        "Reconstruct masks or predicitions from tiles"
        ll = []
        for idx in range(len(self)):
            outIdx = self.image_indices[idx]
            outShape = self.image_shapes[idx]
            outSlice = self.out_slices[idx]
            inSlice = self.in_slices[idx]
            if len(ll) < outIdx + 1:
                if len(tiles.shape)>3:
                    ll.append(np.empty((*outShape, self.n_classes)))
                else:
                    ll.append(np.empty(outShape))
            ll[outIdx][outSlice] = tiles[idx][inSlice]

        return ll